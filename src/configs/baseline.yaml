# LFCC + LCNN + P2SGradLoss configuration
# Based on ASVspoof2019 paper architecture

defaults:
  - model: lcnn
  - transforms: melspec
  - loss_function: sigmoid
  - optimizer: adam
  - lr_scheduler: step
  - trainer: default
  - metrics: default
  - writer: cometml
  - datasets: asvspoof2019
  - dataloader: default
  - dataloader/eval_override
  - _self_

# Training configuration
trainer:
  epochs: 100  # Increased number of epochs
  eval_period: 2
  save_period: 5  # Save model every 5 epochs
  log_step: 100
  monitor: min eer
  early_stop: 20  # Increased early stopping
  max_grad_norm: 1.0  # Add gradient clipping for stability
  seed: 42

# Data configuration
dataloader:
  batch_size: 8
  num_workers: 2
  pin_memory: True
  drop_last: True

# Model configuration
model:
  dropout_rate: 0.75  # As in original paper

# Optimizer configuration
optimizer:
  lr: 3e-4  # Original learning rate from paper
  weight_decay: 1e-4

# Learning rate scheduler
lr_scheduler:
  step_size: 10
  gamma: 0.5

# Data path configuration
data_path: ${oc.env:DATA_PATH,data}

# Transforms configuration (Mel-spectrogram)
transforms:
  instance_transforms:
    data_object:
      _target_: src.transforms.stft.MelSpectrogram
      sample_rate: 16000
      n_fft: 512
      hop_length: 160
      win_length: 320
      n_mels: 80
      f_min: 0.0
      f_max: 8000.0
      power: 2.0
      with_emphasis: True
      with_delta: False
      in_db: True 