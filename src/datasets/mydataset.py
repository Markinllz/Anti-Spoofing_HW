import numpy as np
import torch
import torchaudio
from tqdm.auto import tqdm

from src.datasets.base_dataset import BaseDataset
from src.utils.io_utils import ROOT_PATH, read_json, write_json
from pathlib import Path


class AudioSpoofingDataset(BaseDataset):
    """
    Dataset class for ASVspoof2019 audio anti-spoofing challenge.
    """

    def __init__(
        self, name="train", label_path=None, audio_path=None, out_path=None, 
        instance_transforms=None, max_samples=None, *args, **kwargs
    ):
        """
        Args:
            name (str): partition name (train, val, test)
            label_path (str): path to the protocol file
            audio_path (str): path to the directory with .flac files
            out_path (str): where to save index.json
            instance_transforms (dict): transforms to apply to instances
            max_samples (int): maximum number of samples for debugging (None for all)
        """
        self.name = name
        self.label_path = label_path
        self.audio_path = audio_path
        self.out_path = out_path
        self.max_samples = max_samples
        
        # Create index if it doesn't exist
        if Path(out_path).exists():
            index = read_json(out_path)
        else:
            index = self._create_index(label_path, audio_path, out_path)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        if max_samples is not None:
            index = index[:max_samples]

        super().__init__(index, instance_transforms=instance_transforms, *args, **kwargs)

    def __getitem__(self, idx):
        """
        Get item by index.

        Args:
            idx (int): index of the item.

        Returns:
            dict: item data with 'data_object' and 'labels' keys.
        """
        item = self.index[idx]
        
        # Load audio file
        audio_path = item["path"]
        label = item["label"]
        
        try:
            # Load audio using torchaudio
            waveform, sample_rate = torchaudio.load(audio_path)
            
            # Convert to mono if stereo
            if waveform.shape[0] > 1:
                waveform = torch.mean(waveform, dim=0, keepdim=True)
            
            # Create item with correct keys
            item_data = {
                "data_object": waveform,
                "labels": label
            }
            
            # Apply instance transforms
            if self.instance_transforms is not None:
                item_data = self._apply_instance_transforms(item_data)
            
            return item_data
            
        except Exception as e:
            # Return zero tensor as fallback - —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–æ 4 —Å–µ–∫—É–Ω–¥
            fallback_waveform = torch.zeros(1, 64000)  # 4 seconds of silence at 16kHz
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ {audio_path}: {e}")
            return {
                "data_object": fallback_waveform,
                "labels": label
            }

    def _create_index(self, label_path, audio_path, out_path):
        """
        Args:
        label_path (str or Path): path to the protocol file (e.g., train.trn.txt)
        audio_path (str or Path): path to the directory with .flac files
        out_path (str or Path): where to save index.json

        Returns:
            index (list[dict]): list of dictionaries, each with "path" and "label" fields
        """
        index = []
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ
        with open(label_path, "r") as f:
            total_lines = sum(1 for _ in f)
        
        bonafide_count = 0
        spoof_count = 0

        with open(label_path, "r") as f:
            for line_num, line in enumerate(tqdm(f, total=total_lines, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫")):
                parts = line.strip().split()
                file_id = parts[1]
                class_name = parts[-1]
                label = 0 if class_name == "bonafide" else 1  # Fixed typo
                path = str(Path(audio_path) / f"{file_id}.flac")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
                if not Path(path).exists():
                    continue
                
                index.append(
                    {
                        "path" : path,
                        "label" : label
                    }
                )
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                if label == 0:
                    bonafide_count += 1
                else:
                    spoof_count += 1
        
        write_json(index, out_path)
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–∞—Ç–∞—Å–µ—Ç–∞
        total_samples = len(index)
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ '{self.name}':")
        print(f"   üìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total_samples}")
        print(f"   ‚úÖ Bonafide (–∫–ª–∞—Å—Å 0): {bonafide_count} ({100*bonafide_count/total_samples:.1f}%)")
        print(f"   ‚ùå Spoof (–∫–ª–∞—Å—Å 1): {spoof_count} ({100*spoof_count/total_samples:.1f}%)")
        print(f"   ‚öñÔ∏è –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ spoof/bonafide: {spoof_count/bonafide_count:.2f}")

        return index
