diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
index c5597d0..75af4b3 100644
--- a/checkpoints/training-experiment/config.yaml
+++ b/checkpoints/training-experiment/config.yaml
@@ -56,12 +56,30 @@ transforms:
     n_fft: 1024
     hop_length: 512
     win_length: 1024
-  batch_transforms: null
+  batch_transforms:
+    train:
+      data_object:
+        _target_: torch.nn.Sequential
+        _args_:
+        - _target_: src.transforms.normalize.Normalize
+          mean:
+          - 0.0
+          std:
+          - 1.0
+    inference:
+      data_object:
+        _target_: torch.nn.Sequential
+        _args_:
+        - _target_: src.transforms.normalize.Normalize
+          mean:
+          - 0.0
+          std:
+          - 1.0
 writer:
   _target_: src.logger.cometml.CometMLWriter
   project_name: anti-spoofing
   workspace: null
-  run_id: utkesn2x
+  run_id: ts0gp052
   run_name: training-experiment
   mode: online
   loss_names:
diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
index 1629df9..4e48bcf 100644
--- a/checkpoints/training-experiment/git_commit.txt
+++ b/checkpoints/training-experiment/git_commit.txt
@@ -1 +1 @@
-a01b6b6e5b38bba1618e4cc0990aeaa1cd9b49e3
+0e04a3adc980152fdfdd5a33441b94b650140ad8
diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
index 55f8f61..e69de29 100644
--- a/checkpoints/training-experiment/git_diff.patch
+++ b/checkpoints/training-experiment/git_diff.patch
@@ -1,6042 +0,0 @@
-diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
-index 3cf1d33..c5597d0 100644
---- a/checkpoints/training-experiment/config.yaml
-+++ b/checkpoints/training-experiment/config.yaml
-@@ -56,30 +56,12 @@ transforms:
-     n_fft: 1024
-     hop_length: 512
-     win_length: 1024
--  batch_transforms:
--    train:
--      data_object:
--        _target_: torch.nn.Sequential
--        _args_:
--        - _target_: src.transforms.normalize.Normalize
--          mean:
--          - 0.0
--          std:
--          - 1.0
--    inference:
--      data_object:
--        _target_: torch.nn.Sequential
--        _args_:
--        - _target_: src.transforms.normalize.Normalize
--          mean:
--          - 0.0
--          std:
--          - 1.0
-+  batch_transforms: null
- writer:
-   _target_: src.logger.cometml.CometMLWriter
-   project_name: anti-spoofing
-   workspace: null
--  run_id: nqsnxyzf
-+  run_id: utkesn2x
-   run_name: training-experiment
-   mode: online
-   loss_names:
-diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
-index 4414b1a..1629df9 100644
---- a/checkpoints/training-experiment/git_commit.txt
-+++ b/checkpoints/training-experiment/git_commit.txt
-@@ -1 +1 @@
--eb7eddd715700b14a9ab2401d74687a66d57e3a7
-+a01b6b6e5b38bba1618e4cc0990aeaa1cd9b49e3
-diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
-index b2faf66..e69de29 100644
---- a/checkpoints/training-experiment/git_diff.patch
-+++ b/checkpoints/training-experiment/git_diff.patch
-@@ -1,5967 +0,0 @@
--diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
--index 3b8a319..3cf1d33 100644
----- a/checkpoints/training-experiment/config.yaml
--+++ b/checkpoints/training-experiment/config.yaml
--@@ -3,9 +3,7 @@ project_name: anti-spoofing
-- run_name: baseline-experiment
-- model:
--   _target_: src.model.model.LCNN
---  in_channels: 1
--   num_classes: 2
---  dropout_p: 0.3
-- optimizer:
--   _target_: torch.optim.Adam
--   lr: 0.001
--@@ -81,7 +79,7 @@ writer:
--   _target_: src.logger.cometml.CometMLWriter
--   project_name: anti-spoofing
--   workspace: null
---  run_id: f4xa9zkq
--+  run_id: nqsnxyzf
--   run_name: training-experiment
--   mode: online
--   loss_names:
--diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
--index c037239..4414b1a 100644
----- a/checkpoints/training-experiment/git_commit.txt
--+++ b/checkpoints/training-experiment/git_commit.txt
--@@ -1 +1 @@
---7c5d3eb562d7332313b4686c1bb511bb5017fcd8
--+eb7eddd715700b14a9ab2401d74687a66d57e3a7
--diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
--index cef6d7c..e69de29 100644
----- a/checkpoints/training-experiment/git_diff.patch
--+++ b/checkpoints/training-experiment/git_diff.patch
--@@ -1,5892 +0,0 @@
---diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
---index 5db7cd5..3b8a319 100644
------ a/checkpoints/training-experiment/config.yaml
---+++ b/checkpoints/training-experiment/config.yaml
---@@ -81,7 +81,7 @@ writer:
---   _target_: src.logger.cometml.CometMLWriter
---   project_name: anti-spoofing
---   workspace: null
----  run_id: yb3v9d2o
---+  run_id: f4xa9zkq
---   run_name: training-experiment
---   mode: online
---   loss_names:
---diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
---index 0f1c783..c037239 100644
------ a/checkpoints/training-experiment/git_commit.txt
---+++ b/checkpoints/training-experiment/git_commit.txt
---@@ -1 +1 @@
----4fe20f80ed4eb85bcdf9b7ce5ed09fd0e9add960
---+7c5d3eb562d7332313b4686c1bb511bb5017fcd8
---diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
---index d0254e5..e69de29 100644
------ a/checkpoints/training-experiment/git_diff.patch
---+++ b/checkpoints/training-experiment/git_diff.patch
---@@ -1,5867 +0,0 @@
----diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
----index ef54f64..5db7cd5 100644
------- a/checkpoints/training-experiment/config.yaml
----+++ b/checkpoints/training-experiment/config.yaml
----@@ -81,7 +81,7 @@ writer:
----   _target_: src.logger.cometml.CometMLWriter
----   project_name: anti-spoofing
----   workspace: null
-----  run_id: iclj2rnz
----+  run_id: yb3v9d2o
----   run_name: training-experiment
----   mode: online
----   loss_names:
----diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
----index 8e2cf6b..0f1c783 100644
------- a/checkpoints/training-experiment/git_commit.txt
----+++ b/checkpoints/training-experiment/git_commit.txt
----@@ -1 +1 @@
-----bcae19d4a636ee82f9e1d511b00aefa30659a778
----+4fe20f80ed4eb85bcdf9b7ce5ed09fd0e9add960
----diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
----index cd79149..e69de29 100644
------- a/checkpoints/training-experiment/git_diff.patch
----+++ b/checkpoints/training-experiment/git_diff.patch
----@@ -1,5382 +0,0 @@
-----diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
-----index 3c497ad..ef54f64 100644
-------- a/checkpoints/training-experiment/config.yaml
-----+++ b/checkpoints/training-experiment/config.yaml
-----@@ -81,7 +81,7 @@ writer:
-----   _target_: src.logger.cometml.CometMLWriter
-----   project_name: anti-spoofing
-----   workspace: null
------  run_id: v1dyvkfa
-----+  run_id: iclj2rnz
-----   run_name: training-experiment
-----   mode: online
-----   loss_names:
-----diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
-----index 165b62c..8e2cf6b 100644
-------- a/checkpoints/training-experiment/git_commit.txt
-----+++ b/checkpoints/training-experiment/git_commit.txt
-----@@ -1 +1 @@
------c20e974732a6ccdc523dd9e05876fe4dce43faaa
-----+bcae19d4a636ee82f9e1d511b00aefa30659a778
-----diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
-----index a99d21c..e69de29 100644
-------- a/checkpoints/training-experiment/git_diff.patch
-----+++ b/checkpoints/training-experiment/git_diff.patch
-----@@ -1,5357 +0,0 @@
------diff --git a/checkpoints/inference-test/config.yaml b/checkpoints/inference-test/config.yaml
------index 2f2b128..aec7cc4 100644
--------- a/checkpoints/inference-test/config.yaml
------+++ b/checkpoints/inference-test/config.yaml
------@@ -81,7 +81,7 @@ writer:
------   _target_: src.logger.cometml.CometMLWriter
------   project_name: anti-spoofing
------   workspace: null
-------  run_id: j9yzgmw7
------+  run_id: kitttsun
------   run_name: inference-test
------   mode: online
------   loss_names:
------@@ -97,11 +97,12 @@ trainer:
------   val_period: 1
------   skip_oom: true
------   max_grad_norm: 0.5
-------  log_step: 50
------+  log_step: 1
------   save_dir: checkpoints
------   device_tensors:
------   - data_object
------   - labels
------   monitor: min val_eer
-------  early_stop: 20
------+  early_stop: 200
------   override: true
------+debug_mode: true
------diff --git a/checkpoints/inference-test/git_commit.txt b/checkpoints/inference-test/git_commit.txt
------index abf19c1..165b62c 100644
--------- a/checkpoints/inference-test/git_commit.txt
------+++ b/checkpoints/inference-test/git_commit.txt
------@@ -1 +1 @@
-------1893ddb730be2c6661117bf39596d81a90087a8f
------+c20e974732a6ccdc523dd9e05876fe4dce43faaa
------diff --git a/checkpoints/inference-test/git_diff.patch b/checkpoints/inference-test/git_diff.patch
------index 00d44c3..555d2c6 100644
--------- a/checkpoints/inference-test/git_diff.patch
------+++ b/checkpoints/inference-test/git_diff.patch
------@@ -1,1031 +1,2311 @@
------ diff --git a/checkpoints/inference-test/config.yaml b/checkpoints/inference-test/config.yaml
-------index 61adced..2f2b128 100644
------+index 2f2b128..aec7cc4 100644
------ --- a/checkpoints/inference-test/config.yaml
------ +++ b/checkpoints/inference-test/config.yaml
------ @@ -81,7 +81,7 @@ writer:
------    _target_: src.logger.cometml.CometMLWriter
------    project_name: anti-spoofing
------    workspace: null
--------  run_id: 8gzucarc
-------+  run_id: j9yzgmw7
------+-  run_id: j9yzgmw7
------++  run_id: kitttsun
------    run_name: inference-test
------    mode: online
------    loss_names:
------+@@ -97,11 +97,12 @@ trainer:
------+   val_period: 1
------+   skip_oom: true
------+   max_grad_norm: 0.5
------+-  log_step: 50
------++  log_step: 1
------+   save_dir: checkpoints
------+   device_tensors:
------+   - data_object
------+   - labels
------+   monitor: min val_eer
------+-  early_stop: 20
------++  early_stop: 200
------+   override: true
------++debug_mode: true
------ diff --git a/checkpoints/inference-test/git_commit.txt b/checkpoints/inference-test/git_commit.txt
-------index 24ff1b6..abf19c1 100644
------+index abf19c1..165b62c 100644
------ --- a/checkpoints/inference-test/git_commit.txt
------ +++ b/checkpoints/inference-test/git_commit.txt
------ @@ -1 +1 @@
--------2234c3a2bbb1302441afc29a25fec84e32271ba1
-------+1893ddb730be2c6661117bf39596d81a90087a8f
------+-1893ddb730be2c6661117bf39596d81a90087a8f
------++c20e974732a6ccdc523dd9e05876fe4dce43faaa
------ diff --git a/checkpoints/inference-test/git_diff.patch b/checkpoints/inference-test/git_diff.patch
-------index bbf7cb1..e69de29 100644
------+index 00d44c3..e69de29 100644
------ --- a/checkpoints/inference-test/git_diff.patch
------ +++ b/checkpoints/inference-test/git_diff.patch
-------@@ -1,2205 +0,0 @@
------+@@ -1,2373 +0,0 @@
------ -diff --git a/checkpoints/inference-test/config.yaml b/checkpoints/inference-test/config.yaml
--------index 67acd14..61adced 100644
------+-index 61adced..2f2b128 100644
------ ---- a/checkpoints/inference-test/config.yaml
------ -+++ b/checkpoints/inference-test/config.yaml
--------@@ -8,16 +8,14 @@ model:
--------   dropout_p: 0.3
-------- optimizer:
--------   _target_: torch.optim.Adam
---------  lr: 1.0e-05
--------+  lr: 0.001
--------   weight_decay: 0.0001
-------- lr_scheduler:
--------   _target_: torch.optim.lr_scheduler.StepLR
---------  step_size: 10
---------  gamma: 0.1
--------+  step_size: 20
--------+  gamma: 0.5
-------- loss_function:
---------  _target_: src.loss.Asoftmax.AsoftMax
---------  margin: 2
---------  scale: 15
--------+  _target_: src.loss.crossentropy.CrossEntropyLoss
-------- metrics:
--------   train:
--------   - _target_: src.metrics.eer.EERMetric
--------@@ -56,7 +54,10 @@ transforms:
--------   instance_transforms:
--------     data_object: ${transforms.stft}
--------   stft:
---------    _target_: src.transforms.stft.AudioFrontend
--------+    _target_: src.transforms.stft.STFTTransform
--------+    n_fft: 1024
--------+    hop_length: 512
--------+    win_length: 1024
--------   batch_transforms:
--------     train:
--------       data_object:
--------@@ -80,7 +81,7 @@ writer:
------+-@@ -81,7 +81,7 @@ writer:
------ -   _target_: src.logger.cometml.CometMLWriter
------ -   project_name: anti-spoofing
------ -   workspace: null
---------  run_id: xzqp1djl
--------+  run_id: 8gzucarc
------+--  run_id: 8gzucarc
------+-+  run_id: j9yzgmw7
------ -   run_name: inference-test
------ -   mode: online
------ -   loss_names:
--------@@ -95,7 +96,7 @@ trainer:
--------   save_period: 10
--------   val_period: 1
--------   skip_oom: true
---------  max_grad_norm: 1.0
--------+  max_grad_norm: 0.5
--------   log_step: 50
--------   save_dir: checkpoints
--------   device_tensors:
------ -diff --git a/checkpoints/inference-test/git_commit.txt b/checkpoints/inference-test/git_commit.txt
--------index 1bf8e23..24ff1b6 100644
------+-index 24ff1b6..abf19c1 100644
------ ---- a/checkpoints/inference-test/git_commit.txt
------ -+++ b/checkpoints/inference-test/git_commit.txt
------ -@@ -1 +1 @@
---------f24def3dab4de63a438094983749d95d2202c3cf
--------+2234c3a2bbb1302441afc29a25fec84e32271ba1
------+--2234c3a2bbb1302441afc29a25fec84e32271ba1
------+-+1893ddb730be2c6661117bf39596d81a90087a8f
------ -diff --git a/checkpoints/inference-test/git_diff.patch b/checkpoints/inference-test/git_diff.patch
--------index 1bf2ab0..e69de29 100644
------+-index bbf7cb1..e69de29 100644
------ ---- a/checkpoints/inference-test/git_diff.patch
------ -+++ b/checkpoints/inference-test/git_diff.patch
--------@@ -1,185 +0,0 @@
---------diff --git a/src/configs/baseline.yaml b/src/configs/baseline.yaml
---------index 6c8ba46..1649280 100644
------------ a/src/configs/baseline.yaml
---------+++ b/src/configs/baseline.yaml
---------@@ -8,7 +8,7 @@ defaults:
---------   - datasets: asvspoof2019
---------   - dataloader: default
---------   - transforms: default
----------  - writer: wandb
---------+  - writer: cometml
---------   - trainer: default
--------- 
--------- data_path: ${oc.env:DATA_PATH,data}
------+-@@ -1,2205 +0,0 @@
------+--diff --git a/checkpoints/inference-test/config.yaml b/checkpoints/inference-test/config.yaml
------+--index 67acd14..61adced 100644
------+----- a/checkpoints/inference-test/config.yaml
------+--+++ b/checkpoints/inference-test/config.yaml
------+--@@ -8,16 +8,14 @@ model:
------+--   dropout_p: 0.3
------+-- optimizer:
------+--   _target_: torch.optim.Adam
------+---  lr: 1.0e-05
------+--+  lr: 0.001
------+--   weight_decay: 0.0001
------+-- lr_scheduler:
------+--   _target_: torch.optim.lr_scheduler.StepLR
------+---  step_size: 10
------+---  gamma: 0.1
------+--+  step_size: 20
------+--+  gamma: 0.5
------+-- loss_function:
------+---  _target_: src.loss.Asoftmax.AsoftMax
------+---  margin: 2
------+---  scale: 15
------+--+  _target_: src.loss.crossentropy.CrossEntropyLoss
------+-- metrics:
------+--   train:
------+--   - _target_: src.metrics.eer.EERMetric
------+--@@ -56,7 +54,10 @@ transforms:
------+--   instance_transforms:
------+--     data_object: ${transforms.stft}
------+--   stft:
------+---    _target_: src.transforms.stft.AudioFrontend
------+--+    _target_: src.transforms.stft.STFTTransform
------+--+    n_fft: 1024
------+--+    hop_length: 512
------+--+    win_length: 1024
------+--   batch_transforms:
------+--     train:
------+--       data_object:
------+--@@ -80,7 +81,7 @@ writer:
------+--   _target_: src.logger.cometml.CometMLWriter
------+--   project_name: anti-spoofing
------+--   workspace: null
------+---  run_id: xzqp1djl
------+--+  run_id: 8gzucarc
------+--   run_name: inference-test
------+--   mode: online
------+--   loss_names:
------+--@@ -95,7 +96,7 @@ trainer:
------+--   save_period: 10
------+--   val_period: 1
------+--   skip_oom: true
------+---  max_grad_norm: 1.0
------+--+  max_grad_norm: 0.5
------+--   log_step: 50
------+--   save_dir: checkpoints
------+--   device_tensors:
------+--diff --git a/checkpoints/inference-test/git_commit.txt b/checkpoints/inference-test/git_commit.txt
------+--index 1bf8e23..24ff1b6 100644
------+----- a/checkpoints/inference-test/git_commit.txt
------+--+++ b/checkpoints/inference-test/git_commit.txt
------+--@@ -1 +1 @@
------+---f24def3dab4de63a438094983749d95d2202c3cf
------+--+2234c3a2bbb1302441afc29a25fec84e32271ba1
------+--diff --git a/checkpoints/inference-test/git_diff.patch b/checkpoints/inference-test/git_diff.patch
------+--index 1bf2ab0..e69de29 100644
------+----- a/checkpoints/inference-test/git_diff.patch
------+--+++ b/checkpoints/inference-test/git_diff.patch
------+--@@ -1,185 +0,0 @@
------+---diff --git a/src/configs/baseline.yaml b/src/configs/baseline.yaml
------+---index 6c8ba46..1649280 100644
------+------ a/src/configs/baseline.yaml
------+---+++ b/src/configs/baseline.yaml
------+---@@ -8,7 +8,7 @@ defaults:
------+---   - datasets: asvspoof2019
------+---   - dataloader: default
------+---   - transforms: default
------+----  - writer: wandb
------+---+  - writer: cometml
------+---   - trainer: default
------+--- 
------+--- data_path: ${oc.env:DATA_PATH,data}
------+---diff --git a/src/configs/dataloader/default.yaml b/src/configs/dataloader/default.yaml
------+---index 86758af..902e80f 100644
------+------ a/src/configs/dataloader/default.yaml
------+---+++ b/src/configs/dataloader/default.yaml
------+---@@ -1,4 +1,4 @@
------+--- _target_: torch.utils.data.DataLoader
------+----batch_size: 32
------+---+batch_size: 16
------+--- num_workers: 4
------+--- pin_memory: true 
------+---\ No newline at end of file
------+---diff --git a/src/configs/loss_function/asoftmax.yaml b/src/configs/loss_function/asoftmax.yaml
------+---index fe087a7..a96439b 100644
------+------ a/src/configs/loss_function/asoftmax.yaml
------+---+++ b/src/configs/loss_function/asoftmax.yaml
------+---@@ -1,3 +1,3 @@
------+--- _target_: src.loss.Asoftmax.AsoftMax
------+----margin: 4
------+----scale: 30 
------+---\ No newline at end of file
------+---+margin: 2
------+---+scale: 15 
------+---\ No newline at end of file
------+---diff --git a/src/configs/optimizer/adam.yaml b/src/configs/optimizer/adam.yaml
------+---index 9af2fd8..3b50a71 100644
------+------ a/src/configs/optimizer/adam.yaml
------+---+++ b/src/configs/optimizer/adam.yaml
------+---@@ -1,3 +1,3 @@
------+--- _target_: torch.optim.Adam
------+----lr: 0.0001
------+---+lr: 0.00001
------+--- weight_decay: 0.0001 
------+---\ No newline at end of file
------+---diff --git a/src/loss/Asoftmax.py b/src/loss/Asoftmax.py
------+---index 25a74e3..6c4ee07 100644
------+------ a/src/loss/Asoftmax.py
------+---+++ b/src/loss/Asoftmax.py
------+---@@ -20,26 +20,29 @@ class AsoftMax(nn.Module):
------+---         Returns:
------+---             losses (dict): dictionary loss
------+---         """
------+----       
------+---+        
------+---+        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º logits
------+---         logits_norm = F.normalize(logits, p=2, dim=1)
------+----        prev_cos = torch.clamp(logits_norm, -1.0 + 1e-6, 1.0 - 1e-6)
------+---         
------+----        angle = torch.acos(prev_cos)
------+----        cos_m = prev_cos.clone()
------+---+        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å —É–≥–ª–∞
------+---+        cos_theta = torch.clamp(logits_norm, -1.0 + 1e-6, 1.0 - 1e-6)
------+---         
------+---+        # –í—ã—á–∏—Å–ª—è–µ–º —É–≥–æ–ª
------+---+        theta = torch.acos(cos_theta)
------+---         
------+----        mask = torch.zeros_like(prev_cos)
------+---+        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞
------+---+        mask = torch.zeros_like(cos_theta)
------+---         mask.scatter_(1, labels.unsqueeze(1), 1)
------+---         
------+----       
------+----        cos_m = torch.where(mask == 1, 
------+----                                 torch.cos(self.margin * angle), 
------+----                                 prev_cos)
------+---+        # –ü—Ä–∏–º–µ–Ω—è–µ–º margin —Ç–æ–ª—å–∫–æ –∫ —Ü–µ–ª–µ–≤–æ–º—É –∫–ª–∞—Å—Å—É
------+---+        cos_theta_m = torch.where(mask == 1, 
------+---+                                 torch.cos(self.margin * theta), 
------+---+                                 cos_theta)
------+---         
------+----       
------+----        cos_m = cos_m * self.scale
------+---+        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º
------+---+        cos_theta_m = cos_theta_m * self.scale
------+---         
------+----   
------+----        loss = F.cross_entropy(cos_m, labels)
------+---+        # –í—ã—á–∏—Å–ª—è–µ–º loss
------+---+        loss = F.cross_entropy(cos_theta_m, labels)
------+---         
------+---         return {"loss": loss}
------+---\ No newline at end of file
------+---diff --git a/src/metrics/eer.py b/src/metrics/eer.py
------+---index 61d466e..7e34321 100644
------+------ a/src/metrics/eer.py
------+---+++ b/src/metrics/eer.py
------+---@@ -1,4 +1,5 @@
------+--- import numpy as np
------+---+import torch
------+--- from abc import abstractmethod
------+--- 
------+--- class BaseMetric:
------+---@@ -17,8 +18,8 @@ class EERMetric(BaseMetric):
------+---     """
------+---     Equal Error Rate (EER) metric.
------+---     –û–∂–∏–¥–∞–µ—Ç –≤ batch –¥–≤–∞ –ø–æ–ª—è:
------+----        - 'scores': numpy array –∏–ª–∏ torch tensor —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏ —Å–∫–æ—Ä–∏–Ω–≥–∞–º–∏
------+----        - 'labels': numpy array –∏–ª–∏ torch tensor —Å –º–µ—Ç–∫–∞–º–∏ (1 ‚Äî bona fide, 0 ‚Äî spoof)
------+---+        - 'logits': torch tensor —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏ logits
------+---+        - 'labels': torch tensor —Å –º–µ—Ç–∫–∞–º–∏ (1 ‚Äî bona fide, 0 ‚Äî spoof)
------+---     """
------+--- 
------+---     def __init__(self, name="eer"):
------+---@@ -50,6 +51,9 @@ class EERMetric(BaseMetric):
------+---         bona_scores = scores[labels == 1]
------+---         spoof_scores = scores[labels == 0]
------+--- 
------+---+        if len(bona_scores) == 0 or len(spoof_scores) == 0:
------+---+            return 0.0
------+---+
------+---         eer, _ = self.compute_eer(bona_scores, spoof_scores)
------+---         return eer
------+--- 
------+---diff --git a/src/model/model.py b/src/model/model.py
------+---index 6d0bf94..28a4ce4 100644
------+------ a/src/model/model.py
------+---+++ b/src/model/model.py
------+---@@ -66,13 +66,29 @@ class LCNN(nn.Module):
------+--- 
------+---         self.MaxPool28 = nn.MaxPool2d(kernel_size=2, stride=2)
------+--- 
------+----
------+---         self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
------+---         self.fc29 = nn.Linear(32, 160)
------+---         self.dropout29 = nn.Dropout(dropout_p)
------+---         self.mfm30 = mfm_block(160)
------+---         self.BatchNorm31 = nn.BatchNorm1d(80)
------+---         self.fc32 = nn.Linear(80, num_classes)
------+---+        
------+---+        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
------+---+        self._initialize_weights()
------+---+
------+---+    def _initialize_weights(self):
------+---+        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
------+---+        for m in self.modules():
------+---+            if isinstance(m, nn.Conv2d):
------+---+                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
------+---+                if m.bias is not None:
------+---+                    nn.init.constant_(m.bias, 0)
------+---+            elif isinstance(m, nn.BatchNorm2d):
------+---+                nn.init.constant_(m.weight, 1)
------+---+                nn.init.constant_(m.bias, 0)
------+---+            elif isinstance(m, nn.Linear):
------+---+                nn.init.normal_(m.weight, 0, 0.01)
------+---+                nn.init.constant_(m.bias, 0)
------+--- 
------+---     def forward(self, data_object, **kwargs):
------+---         x = data_object
------+---diff --git a/src/trainer/trainer.py b/src/trainer/trainer.py
------+---index 1b806fb..3313fea 100644
------+------ a/src/trainer/trainer.py
------+---+++ b/src/trainer/trainer.py
------+---@@ -47,17 +47,17 @@ class Trainer(BaseTrainer):
------+---             if self.lr_scheduler is not None:
------+---                 self.lr_scheduler.step()
------+--- 
------+----        
------+---+        # –û–±–Ω–æ–≤–ª—è–µ–º loss –º–µ—Ç—Ä–∏–∫–∏
------+---         for loss_name in self.config.writer.loss_names:
------+---             metrics.update(loss_name, batch[loss_name].item())
------+--- 
------+----      
------+---+        # –û–±–Ω–æ–≤–ª—è–µ–º EER –º–µ—Ç—Ä–∏–∫—É
------+---         if "logits" in batch:
------+---             scores = torch.softmax(batch["logits"], dim=1)[:, 1]
------+---             labels = batch["labels"]
------+---             metrics.update_eer(scores, labels)
------+--- 
------+----       
------+---+        # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
------+---         for met in metric_funcs:
------+---             if met.name != "eer":
------+---                 try:
------+--diff --git a/requirements.txt b/requirements.txt
------+--index 8aab454..1dc9376 100644
------+----- a/requirements.txt
------+--+++ b/requirements.txt
------+--@@ -1,37 +1,24 @@
------+---# –û—Å–Ω–æ–≤–Ω—ã–µ PyTorch –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
------+-- torch==2.2.0
------+-- torchvision==0.17.0
------+-- torchaudio==2.2.0
------+-- torchmetrics==1.7.4
------+---
------+---# –ù–∞—É—á–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
------+-- numpy==1.26.4
------+-- pandas==2.3.1
------+-- matplotlib==3.9.4
------+-- scipy
------+---
------+---# –ê—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞
------+-- soundfile==0.13.1
------+-- librosa
------+---
------+---# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
------+-- wandb==0.21.0
------+-- comet-ml==3.50.0
------+-- hydra-core==1.3.2
------+-- omegaconf==2.3.0
------+---
------+---# –£—Ç–∏–ª–∏—Ç—ã
------+-- tqdm==4.67.1
------+-- psutil==7.0.0
------+-- requests==2.32.4
------+-- pyyaml==6.0.2
------+---
------+---# –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞
------+-- black
------+-- isort
------+-- pre-commit
------+-- flake8
------+---
------+---# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è ML
------+-- scikit-learn
------+-- seaborn
------+--\ No newline at end of file
------ --diff --git a/src/configs/dataloader/default.yaml b/src/configs/dataloader/default.yaml
---------index 86758af..902e80f 100644
------+--index 80fbc65..902e80f 100644
------ ----- a/src/configs/dataloader/default.yaml
------ --+++ b/src/configs/dataloader/default.yaml
------ --@@ -1,4 +1,4 @@
------ -- _target_: torch.utils.data.DataLoader
----------batch_size: 32
------+---batch_size: 8
------ --+batch_size: 16
------ -- num_workers: 4
------ -- pin_memory: true 
------ --\ No newline at end of file
---------diff --git a/src/configs/loss_function/asoftmax.yaml b/src/configs/loss_function/asoftmax.yaml
---------index fe087a7..a96439b 100644
------------ a/src/configs/loss_function/asoftmax.yaml
---------+++ b/src/configs/loss_function/asoftmax.yaml
------+--diff --git a/src/configs/lr_scheduler/step.yaml b/src/configs/lr_scheduler/step.yaml
------+--index bd12a00..3c208ac 100644
------+----- a/src/configs/lr_scheduler/step.yaml
------+--+++ b/src/configs/lr_scheduler/step.yaml
------ --@@ -1,3 +1,3 @@
--------- _target_: src.loss.Asoftmax.AsoftMax
----------margin: 4
----------scale: 30 
------+-- _target_: torch.optim.lr_scheduler.StepLR
------+---step_size: 10
------+---gamma: 0.1 
------ --\ No newline at end of file
---------+margin: 2
---------+scale: 15 
------+--+step_size: 20
------+--+gamma: 0.5 
------ --\ No newline at end of file
------ --diff --git a/src/configs/optimizer/adam.yaml b/src/configs/optimizer/adam.yaml
---------index 9af2fd8..3b50a71 100644
------+--index 9af2fd8..1310b87 100644
------ ----- a/src/configs/optimizer/adam.yaml
------ --+++ b/src/configs/optimizer/adam.yaml
------ --@@ -1,3 +1,3 @@
------ -- _target_: torch.optim.Adam
------ ---lr: 0.0001
---------+lr: 0.00001
------+--+lr: 0.001
------ -- weight_decay: 0.0001 
------ --\ No newline at end of file
---------diff --git a/src/loss/Asoftmax.py b/src/loss/Asoftmax.py
---------index 25a74e3..6c4ee07 100644
------------ a/src/loss/Asoftmax.py
---------+++ b/src/loss/Asoftmax.py
---------@@ -20,26 +20,29 @@ class AsoftMax(nn.Module):
------+--diff --git a/src/configs/transforms/default.yaml b/src/configs/transforms/default.yaml
------+--index 4aea72d..32f1775 100644
------+----- a/src/configs/transforms/default.yaml
------+--+++ b/src/configs/transforms/default.yaml
------+--@@ -2,7 +2,10 @@ instance_transforms:
------+--   data_object: ${transforms.stft}
------+-- 
------+-- stft:
------+---  _target_: src.transforms.stft.AudioFrontend
------+--+  _target_: src.transforms.stft.STFTTransform
------+--+  n_fft: 1024
------+--+  hop_length: 512
------+--+  win_length: 1024
------+-- 
------+-- batch_transforms:
------+--   train:
------+--diff --git a/src/datasets/base_dataset.py b/src/datasets/base_dataset.py
------+--index bf51c70..e75525d 100644
------+----- a/src/datasets/base_dataset.py
------+--+++ b/src/datasets/base_dataset.py
------+--@@ -1,6 +1,6 @@
------+-- import logging
------+-- import random
------+---from typing import List
------+--+from typing import List, Dict, Any, Optional
------+-- 
------+-- import torch
------+-- import torchaudio
------+--@@ -11,66 +11,65 @@ logger = logging.getLogger(__name__)
------+-- 
------+-- class BaseDataset(Dataset):
------+--     """
------+---    Base class for the datasets.
------+---
------+---    Given a proper index (list[dict]), allows to process different datasets
------+---    for the same task in the identical manner. Therefore, to work with
------+---    several datasets, the user only have to define index in a nested class.
------+--+    Base class for all datasets.
------+--     """
------+-- 
------+--     def __init__(
------+---        self, index, limit=None, shuffle_index=False, instance_transforms=None
------+--+        self,
------+--+        index: List[Dict[str, Any]],
------+--+        instance_transforms: Optional[Dict[str, Any]] = None,
------+--+        *args,
------+--+        **kwargs,
------+--     ):
------+--         """
------+--         Args:
------+---            index (list[dict]): list, containing dict for each element of
------+---                the dataset. The dict has required metadata information,
------+---                such as label and object path.
------+---            limit (int | None): if not None, limit the total number of elements
------+---                in the dataset to 'limit' elements.
------+---            shuffle_index (bool): if True, shuffle the index. Uses python
------+---                random package with seed 42.
------+---            instance_transforms (dict[Callable] | None): transforms that
------+---                should be applied on the instance. Depend on the
------+---                tensor name.
------+---        """
------+---        self._assert_index_is_valid(index)
------+---
------+---        index = self._shuffle_and_limit_index(index, limit, shuffle_index)
------+---        self._index: List[dict] = index
------+---
------+--+            index (List[Dict[str, Any]]): list of dictionaries, each containing
------+--+                the data for one sample.
------+--+            instance_transforms (Optional[Dict[str, Any]]): transforms to apply
------+--+                to instances. Depend on the tensor name.
------+--+        """
------+--+        self.index = index
------+--         self.instance_transforms = instance_transforms
------+-- 
------+---    def __getitem__(self, ind):
------+---        """
------+---        Get element from the index, preprocess it, and combine it
------+---        into a dict.
------+--+    def __len__(self):
------+--+        return len(self.index)
------+-- 
------+---        Notice that the choice of key names is defined by the template user.
------+---        However, they should be consistent across dataset getitem, collate_fn,
------+---        loss_function forward method, and model forward method.
------+--+    def __getitem__(self, idx):
------+--+        """
------+--+        Get item by index.
------+-- 
------+--         Args:
------+---            ind (int): index in the self.index list.
------+--+            idx (int): index of the item.
------+--+
------ --         Returns:
---------             losses (dict): dictionary loss
------+---            instance_data (dict): dict, containing instance
------+---                (a single dataset element).
------+--+            dict: item data.
------ --         """
----------       
------+---        data_dict = self._index[ind]
------+---        data_path = data_dict["path"]
------+---        data_object = self.load_object(data_path)
------+---        data_label = data_dict["label"]
------+--+        item = self.index[idx]
------ --+        
---------+        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º logits
---------         logits_norm = F.normalize(logits, p=2, dim=1)
----------        prev_cos = torch.clamp(logits_norm, -1.0 + 1e-6, 1.0 - 1e-6)
---------         
----------        angle = torch.acos(prev_cos)
----------        cos_m = prev_cos.clone()
---------+        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å —É–≥–ª–∞
---------+        cos_theta = torch.clamp(logits_norm, -1.0 + 1e-6, 1.0 - 1e-6)
---------         
---------+        # –í—ã—á–∏—Å–ª—è–µ–º —É–≥–æ–ª
---------+        theta = torch.acos(cos_theta)
---------         
----------        mask = torch.zeros_like(prev_cos)
---------+        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è —Ü–µ–ª–µ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞
---------+        mask = torch.zeros_like(cos_theta)
---------         mask.scatter_(1, labels.unsqueeze(1), 1)
---------         
----------       
----------        cos_m = torch.where(mask == 1, 
----------                                 torch.cos(self.margin * angle), 
----------                                 prev_cos)
---------+        # –ü—Ä–∏–º–µ–Ω—è–µ–º margin —Ç–æ–ª—å–∫–æ –∫ —Ü–µ–ª–µ–≤–æ–º—É –∫–ª–∞—Å—Å—É
---------+        cos_theta_m = torch.where(mask == 1, 
---------+                                 torch.cos(self.margin * theta), 
---------+                                 cos_theta)
------+--+        # –ü—Ä–∏–º–µ–Ω—è–µ–º instance transforms
------+--+        if self.instance_transforms is not None:
------+--+            item = self._apply_instance_transforms(item)
------+--+        
------+--+        return item
------+-- 
------+---        instance_data = {"data_object": data_object, "labels": data_label}
------+---        instance_data = self.preprocess_data(instance_data)
------+--+    def _apply_instance_transforms(self, item: Dict[str, Any]) -> Dict[str, Any]:
------+--+        """
------+--+        Apply instance transforms to the item.
------+-- 
------+---        return instance_data
------+--+        Args:
------+--+            item (Dict[str, Any]): item data.
------+-- 
------+---    def __len__(self):
------+---        """
------+---        Get length of the dataset (length of the index).
------+--+        Returns:
------+--+            Dict[str, Any]: transformed item data.
------+--         """
------+---        return len(self._index)
------+--+        for transform_name, transform in self.instance_transforms.items():
------+--+            if transform_name in item:
------+--+                try:
------+--+                    item[transform_name] = transform(item[transform_name])
------+--+                except Exception as e:
------+--+                    raise
------+--+        
------+--+        return item
------+-- 
------+--     def load_object(self, path):
------+--         """
------+--@@ -126,74 +125,63 @@ class BaseDataset(Dataset):
------+--         the __init__ before shuffling and limiting.
------+-- 
------+--         Args:
------+---            index (list[dict]): list, containing dict for each element of
------+---                the dataset. The dict has required metadata information,
------+---                such as label and object path.
------+--+            index (list): list of records to filter.
------+--+
------+--         Returns:
------+---            index (list[dict]): list, containing dict for each element of
------+---                the dataset that satisfied the condition. The dict has
------+---                required metadata information, such as label and object path.
------+--+            list: filtered list of records.
------+--         """
------+---        # Filter logic
------+---        pass
------+--+        return index
------+-- 
------+--     @staticmethod
------+--     def _assert_index_is_valid(index):
------+--         """
------+---        Check the structure of the index and ensure it satisfies the desired
------+---        conditions.
------+--+        Assert that the index is valid.
------+-- 
------+--         Args:
------+---            index (list[dict]): list, containing dict for each element of
------+---                the dataset. The dict has required metadata information,
------+---                such as label and object path.
------+---        """
------+---        for entry in index:
------+---            assert "path" in entry, (
------+---                "Each dataset item should include field 'path'" " - path to audio file."
------+---            )
------+---            assert "label" in entry, (
------+---                "Each dataset item should include field 'label'"
------+---                " - object ground-truth label."
------+---            )
------+--+            index (list): list of records to validate.
------+--+        """
------+--+        assert isinstance(index, list), "Index should be a list"
------+--+        assert len(index) > 0, "Index should not be empty"
------+--+        for record in index:
------+--+            assert isinstance(record, dict), "Each record should be a dict"
------+--+            assert "path" in record, "Each record should have a 'path' field"
------+--+            assert "label" in record, "Each record should have a 'label' field"
------+-- 
------+--     @staticmethod
------+--     def _sort_index(index):
------+--         """
------+---        Sort index via some rules.
------+--+        Sort the index by some criterion.
------+-- 
------+--         This is not used in the example. The method should be called in
------+---        the __init__ before shuffling and limiting and after filtering.
------+--+        the __init__ before shuffling and limiting.
------+-- 
------+--         Args:
------+---            index (list[dict]): list, containing dict for each element of
------+---                the dataset. The dict has required metadata information,
------+---                such as label and object path.
------+--+            index (list): list of records to sort.
------+--+
------+--         Returns:
------+---            index (list[dict]): sorted list, containing dict for each element
------+---                of the dataset. The dict has required metadata information,
------+---                such as label and object path.
------+--+            list: sorted list of records.
------+--         """
------+---        return sorted(index, key=lambda x: x["KEY_FOR_SORTING"])
------+--+        return index
------+-- 
------+--     @staticmethod
------+--     def _shuffle_and_limit_index(index, limit, shuffle_index):
------+--         """
------+---        Shuffle elements in index and limit the total number of elements.
------+--+        Shuffle and limit the index.
------+--+
------+--+        This is not used in the example. The method should be called in
------+--+        the __init__ before shuffling and limiting.
------+-- 
------+--         Args:
------+---            index (list[dict]): list, containing dict for each element of
------+---                the dataset. The dict has required metadata information,
------+---                such as label and object path.
------+---            limit (int | None): if not None, limit the total number of elements
------+---                in the dataset to 'limit' elements.
------+---            shuffle_index (bool): if True, shuffle the index. Uses python
------+---                random package with seed 42.
------+--+            index (list): list of records to shuffle and limit.
------+--+            limit (int): maximum number of records to keep.
------+--+            shuffle_index (bool): whether to shuffle the index.
------+--+
------+--+        Returns:
------+--+            list: shuffled and limited list of records.
------+--         """
------+--         if shuffle_index:
------+--             random.seed(42)
------+--             random.shuffle(index)
------+---
------+--         if limit is not None:
------+--             index = index[:limit]
------+--         return index
------+--\ No newline at end of file
------+--diff --git a/src/datasets/collate.py b/src/datasets/collate.py
------+--index 4c2c81e..6cb3b10 100644
------+----- a/src/datasets/collate.py
------+--+++ b/src/datasets/collate.py
------+--@@ -19,6 +19,15 @@ def collate_fn(dataset_items: list[dict]):
------+-- 
------+--     # Pad audio sequences to the same length
------+--     audio_tensors = [elem["data_object"] for elem in dataset_items]
------+--+    
------+--+    # Handle different audio tensor shapes
------+--+    if len(audio_tensors) == 0:
------+--+        # Return empty batch
------+--+        result_batch["data_object"] = torch.empty(0)
------+--+        result_batch["labels"] = torch.empty(0, dtype=torch.long)
------+--+        return result_batch
------+--+    
------+--+    # Get max length for padding
------+--     max_length = max(audio.shape[-1] for audio in audio_tensors)
------+--     
------+--     padded_audio = []
------+--@@ -30,6 +39,6 @@ def collate_fn(dataset_items: list[dict]):
------+--         padded_audio.append(audio)
------+--     
------+--     result_batch["data_object"] = torch.stack(padded_audio)
------+---    result_batch["labels"] = torch.tensor([elem["labels"] for elem in dataset_items])
------+--+    result_batch["labels"] = torch.tensor([elem["labels"] for elem in dataset_items], dtype=torch.long)
------+-- 
------+--     return result_batch
------+--\ No newline at end of file
------+--diff --git a/src/datasets/data_utils.py b/src/datasets/data_utils.py
------+--index 8262ceb..63e8cce 100644
------+----- a/src/datasets/data_utils.py
------+--+++ b/src/datasets/data_utils.py
------+--@@ -36,6 +36,9 @@ def move_batch_transforms_to_device(batch_transforms, device):
------+--             tensor name.
------+--         device (str): device to use for batch transforms.
------+--     """
------+--+    if batch_transforms is None:
------+--+        return
------+--+        
------+--     for transform_type in batch_transforms.keys():
------+--         transforms = batch_transforms.get(transform_type)
------+--         if transforms is not None:
------+--@@ -60,6 +63,7 @@ def get_dataloaders(config, device):
------+--     """
------+--     # transforms or augmentations init
------+--     batch_transforms = instantiate(config.transforms.batch_transforms)
------+--+    
------+--     move_batch_transforms_to_device(batch_transforms, device)
------+-- 
------+--     # dataset partitions init
------+--diff --git a/src/datasets/mydataset.py b/src/datasets/mydataset.py
------+--index 02a09c3..94e7e12 100644
------+----- a/src/datasets/mydataset.py
------+--+++ b/src/datasets/mydataset.py
------+--@@ -1,5 +1,6 @@
------+-- import numpy as np
------+-- import torch
------+--+import torchaudio
------+-- from tqdm.auto import tqdm
------+-- 
------+-- from src.datasets.base_dataset import BaseDataset
------+--@@ -37,6 +38,50 @@ class AudioSpoofingDataset(BaseDataset):
------+-- 
------+--         super().__init__(index, instance_transforms=instance_transforms, *args, **kwargs)
------+-- 
------+--+    def __getitem__(self, idx):
------+--+        """
------+--+        Get item by index.
------+--+
------+--+        Args:
------+--+            idx (int): index of the item.
------+--+
------+--+        Returns:
------+--+            dict: item data with 'data_object' and 'labels' keys.
------+--+        """
------+--+        item = self.index[idx]
------+--+        
------+--+        # Load audio file
------+--+        audio_path = item["path"]
------+--+        label = item["label"]
------+--+        
------+--+        try:
------+--+            # Load audio using torchaudio
------+--+            waveform, sample_rate = torchaudio.load(audio_path)
------+--+            
------+--+            # Convert to mono if stereo
------+--+            if waveform.shape[0] > 1:
------+--+                waveform = torch.mean(waveform, dim=0, keepdim=True)
------+--+            
------+--+            # Create item with correct keys
------+--+            item_data = {
------+--+                "data_object": waveform,
------+--+                "labels": label
------+--+            }
------+--+            
------+--+            # Apply instance transforms
------+--+            if self.instance_transforms is not None:
------+--+                item_data = self._apply_instance_transforms(item_data)
------+--+            
------+--+            return item_data
------+--+            
------+--+        except Exception as e:
------+--+            # Return zero tensor as fallback
------+--+            fallback_waveform = torch.zeros(1, 16000)  # 1 second of silence at 16kHz
------+--+            return {
------+--+                "data_object": fallback_waveform,
------+--+                "labels": label
------+--+            }
------+--+
------+--     def _create_index(self, label_path, audio_path, out_path):
------+--         """
------+--         Args:
------+--@@ -47,25 +92,40 @@ class AudioSpoofingDataset(BaseDataset):
------+--         Returns:
------+--             index (list[dict]): list of dictionaries, each with "path" and "label" fields
------+--         """
------+---
------+--         index = []
------+--+        
------+--+        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ
------+--+        with open(label_path, "r") as f:
------+--+            total_lines = sum(1 for _ in f)
------+--+        
------+--+        bonafide_count = 0
------+--+        spoof_count = 0
------+-- 
------+--         with open(label_path, "r") as f:
------+---            for line in f:
------+--+            for line_num, line in enumerate(tqdm(f, total=total_lines, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫")):
------+--                 parts = line.strip().split()
------+--                 file_id = parts[1]
------+--                 class_name = parts[-1]
------+--                 label = 0 if class_name == "bonafide" else 1  # Fixed typo
------+--                 path = str(Path(audio_path) / f"{file_id}.flac")
------+--+                
------+--+                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
------+--+                if not Path(path).exists():
------+--+                    continue
------+--+                
------+--                 index.append(
------+--                     {
------+--                         "path" : path,
------+--                         "label" : label
------+--                     }
------+--                 )
------+---        print("Separate to path and labels complete")
------+--+                
------+--+                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
------+--+                if label == 0:
------+--+                    bonafide_count += 1
------+--+                else:
------+--+                    spoof_count += 1
------+--+        
------+--         write_json(index, out_path)
------+-- 
------+---        print(f"Created {len(index)} entries in {out_path}")
------+---
------+--         return index
------+--diff --git a/src/loss/crossentropy.py b/src/loss/crossentropy.py
------+--index d8ad43e..677200c 100644
------+----- a/src/loss/crossentropy.py
------+--+++ b/src/loss/crossentropy.py
------+--@@ -1,28 +1,80 @@
------+-- import torch
------+---from torch import nn
------+---import torch.nn.functional as F
------+--+import torch.nn as nn
------+--+from typing import Dict, Any
------+--+
------+-- 
------+-- class CrossEntropyLoss(nn.Module):
------+--     """
------+---    –ü—Ä–æ—Å—Ç–æ–π CrossEntropy loss –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
------+--+    Cross Entropy Loss for audio anti-spoofing.
------+--     """
------+-- 
------+---    def __init__(self):
------+---        super().__init__()
------+--+    def __init__(self, **kwargs):
------+--+        """
------+--+        Args:
------+--+            **kwargs: additional arguments
------+--+        """
------+--+        super(CrossEntropyLoss, self).__init__()
------+--+        
------+--+        print("üéØ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CrossEntropyLoss...")
------+--+        
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
------+--+        for key, value in kwargs.items():
------+--+            print(f"   üìä {key}: {value}")
------+--+        
------+--+        self.criterion = nn.CrossEntropyLoss()
------+--+        print("‚úÖ CrossEntropyLoss –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
------+-- 
------+---    def forward(self, logits: torch.Tensor, labels: torch.Tensor, **kwargs):
------+--+    def forward(self, **batch) -> Dict[str, torch.Tensor]:
------+--         """
------+---        CrossEntropy loss compute
------+--+        Compute cross entropy loss.
------ --         
----------       
----------        cos_m = cos_m * self.scale
---------+        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º
---------+        cos_theta_m = cos_theta_m * self.scale
------+--         Args:
------+---            logits (Tensor): model output predictions (batch_size, num_classes)
------+---            labels (Tensor): ground truth labels (batch_size,)
------+---            **kwargs: –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã (–∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è)
------+--+            **batch: input batch containing logits and labels
------+--+            
------+--         Returns:
------+---            losses (dict): dictionary loss
------+--+            Dict[str, torch.Tensor]: loss dictionary
------+--         """
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
------+--+            print(f"   üíî CrossEntropyLoss forward: –≤—Ö–æ–¥–Ω—ã–µ –∫–ª—é—á–∏ {list(batch.keys())}")
------+--+            for key, value in batch.items():
------+--+                if isinstance(value, torch.Tensor):
------+--+                    print(f"      {key}: shape={value.shape}, dtype={value.dtype}")
------+--+        
------+--+        # –ü–æ–ª—É—á–∞–µ–º logits –∏ labels
------+--+        logits = batch['logits']
------+--+        labels = batch['labels']
------ --         
----------   
----------        loss = F.cross_entropy(cos_m, labels)
---------+        # –í—ã—á–∏—Å–ª—è–µ–º loss
---------+        loss = F.cross_entropy(cos_theta_m, labels)
------+---        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π CrossEntropy loss –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
------+---        loss = F.cross_entropy(logits, labels)
------+--+        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã
------+--+        if logits.dim() == 1:
------+--+            logits = logits.unsqueeze(0)
------+--+        if labels.dim() == 0:
------+--+            labels = labels.unsqueeze(0)
------ --         
---------         return {"loss": loss}
---------\ No newline at end of file
------+---        return {"loss": loss}
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã
------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
------+--+            print(f"   üìä Logits: shape={logits.shape}, range=[{logits.min().item():.4f}, {logits.max().item():.4f}]")
------+--+            print(f"   üìä Labels: shape={labels.shape}, unique={torch.unique(labels).tolist()}")
------+--+        
------+--+        # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ—Ç–µ—Ä—é
------+--+        loss = self.criterion(logits, labels)
------+--+        
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
------+--+            print(f"   üíî Loss: {loss.item():.4f}")
------+--+        
------+--+        return {
------+--+            'loss': loss
------+--+        }
------+--+
------+--+    def set_debug_mode(self, debug_forward=False):
------+--+        """
------+--+        –í–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è forward pass.
------+--+        
------+--+        Args:
------+--+            debug_forward (bool): –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å forward pass
------+--+        """
------+--+        self._debug_forward = debug_forward
------+--+        if debug_forward:
------+--+            print(f"üêõ –†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –≤–∫–ª—é—á–µ–Ω –¥–ª—è {self.__class__.__name__}")
------+--+            print(f"   üíî Debug forward: {debug_forward}")
------ --diff --git a/src/metrics/eer.py b/src/metrics/eer.py
---------index 61d466e..7e34321 100644
------+--index de45458..a9be4a6 100644
------ ----- a/src/metrics/eer.py
------ --+++ b/src/metrics/eer.py
---------@@ -1,4 +1,5 @@
--------- import numpy as np
---------+import torch
--------- from abc import abstractmethod
------+--@@ -1,88 +1,138 @@
------+---import numpy as np
------+-- import torch
------+---from abc import abstractmethod
------+---
------+---class BaseMetric:
------+---    """
------+---    Base class for all metrics
------+---    """
------+--+import numpy as np
------+--+from typing import Dict, Any
------ -- 
--------- class BaseMetric:
---------@@ -17,8 +18,8 @@ class EERMetric(BaseMetric):
------+---    def __init__(self, name=None, *args, **kwargs):
------+---        self.name = name if name is not None else type(self).__name__
------+--+from src.metrics.base_metric import BaseMetric
------+-- 
------+---    @abstractmethod
------+---    def __call__(self, **batch):
------+---        raise NotImplementedError()
------+-- 
------+-- class EERMetric(BaseMetric):
------ --     """
---------     Equal Error Rate (EER) metric.
---------     –û–∂–∏–¥–∞–µ—Ç –≤ batch –¥–≤–∞ –ø–æ–ª—è:
----------        - 'scores': numpy array –∏–ª–∏ torch tensor —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏ —Å–∫–æ—Ä–∏–Ω–≥–∞–º–∏
----------        - 'labels': numpy array –∏–ª–∏ torch tensor —Å –º–µ—Ç–∫–∞–º–∏ (1 ‚Äî bona fide, 0 ‚Äî spoof)
---------+        - 'logits': torch tensor —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏ logits
---------+        - 'labels': torch tensor —Å –º–µ—Ç–∫–∞–º–∏ (1 ‚Äî bona fide, 0 ‚Äî spoof)
------+---    Equal Error Rate (EER) metric.
------+---    –û–∂–∏–¥–∞–µ—Ç –≤ batch –¥–≤–∞ –ø–æ–ª—è:
------+---        - 'logits': torch tensor —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏ logits
------+---        - 'labels': torch tensor —Å –º–µ—Ç–∫–∞–º–∏ (1 ‚Äî bona fide, 0 ‚Äî spoof)
------+--+    Equal Error Rate (EER) metric for audio anti-spoofing.
------ --     """
------ -- 
---------     def __init__(self, name="eer"):
---------@@ -50,6 +51,9 @@ class EERMetric(BaseMetric):
---------         bona_scores = scores[labels == 1]
---------         spoof_scores = scores[labels == 0]
------+---    def __init__(self, name="eer"):
------+---        super().__init__(name=name)
------+---
------+---    def __call__(self, **batch):
------+---    
------+---        logits = batch["logits"]
------+---        labels = batch["labels"]
------+---
------+--+    def __init__(self, **kwargs):
------+--+        """
------+--+        Args:
------+--+            **kwargs: additional arguments
------+--+        """
------+--+        super(EERMetric, self).__init__()
------+--+        
------+--+        print("üìà –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è EERMetric...")
------+--         
------+---        if hasattr(logits, "detach"):
------+---            logits = logits.detach().cpu().numpy()
------+---        if hasattr(labels, "detach"):
------+---            labels = labels.detach().cpu().numpy()
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
------+--+        for key, value in kwargs.items():
------+--+            print(f"   üìä {key}: {value}")
------+--+        
------+--+        self.name = "eer"
------+--+        print("‚úÖ EERMetric –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
------ -- 
---------+        if len(bona_scores) == 0 or len(spoof_scores) == 0:
---------+            return 0.0
---------+
---------         eer, _ = self.compute_eer(bona_scores, spoof_scores)
------+--+    def forward(self, **batch) -> float:
------+--+        """
------+--+        Compute EER metric.
------+--         
------+---        import torch.nn.functional as F
------+---        if hasattr(logits, "detach"):
------+--+        Args:
------+--+            **batch: input batch containing scores and labels
------+--             
------+---            scores = F.softmax(logits, dim=-1)[:, 1]
------+---        else:
------+---            
------+---            logits_tensor = torch.from_numpy(logits)
------+---            scores_tensor = F.softmax(logits_tensor, dim=-1)
------+---            scores = scores_tensor[:, 1].numpy()
------+---
------+--+        Returns:
------+--+            float: EER value
------+--+        """
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
------+--+            print(f"   üìà EERMetric forward: –≤—Ö–æ–¥–Ω—ã–µ –∫–ª—é—á–∏ {list(batch.keys())}")
------+--+            for key, value in batch.items():
------+--+                if isinstance(value, torch.Tensor):
------+--+                    print(f"      {key}: shape={value.shape}, dtype={value.dtype}")
------+--         
------+---        bona_scores = scores[labels == 1]
------+---        spoof_scores = scores[labels == 0]
------+---
------+---        if len(bona_scores) == 0 or len(spoof_scores) == 0:
------+--+        # –ü–æ–ª—É—á–∞–µ–º scores –∏ labels
------+--+        if 'scores' in batch:
------+--+            scores = batch['scores']
------+--+        elif 'logits' in batch:
------+--+            # –ï—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å logits, –±–µ—Ä–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—Ç–æ—Ä–æ–≥–æ –∫–ª–∞—Å—Å–∞ (spoof)
------+--+            logits = batch['logits']
------+--+            scores = torch.softmax(logits, dim=1)[:, 1]
------+--+        else:
------+--+            print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã scores –∏–ª–∏ logits –≤ –±–∞—Ç—á–µ")
------+--             return 0.0
------+---
------+---        eer, _ = self.compute_eer(bona_scores, spoof_scores)
------+--+        
------+--+        labels = batch['labels']
------+--+        
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã
------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
------+--+            print(f"   üìä Scores: shape={scores.shape}, range=[{scores.min().item():.4f}, {scores.max().item():.4f}]")
------+--+            print(f"   üìä Labels: shape={labels.shape}, unique={torch.unique(labels).tolist()}")
------+--+        
------+--+        # –í—ã—á–∏—Å–ª—è–µ–º EER
------+--+        eer = self._compute_eer(scores, labels)
------+--+        
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
------+--+            print(f"   üìà EER: {eer:.4f}")
------+--+        
------ --         return eer
------ -- 
------+---    @staticmethod
------+---    def compute_det_curve(target_scores, nontarget_scores):
------+---        n_scores = target_scores.size + nontarget_scores.size
------+---        all_scores = np.concatenate((target_scores, nontarget_scores))
------+---        labels = np.concatenate(
------+---            (np.ones(target_scores.size), np.zeros(nontarget_scores.size)))
------+---
------+---        indices = np.argsort(all_scores, kind='mergesort')
------+---        labels = labels[indices]
------+---
------+---        tar_trial_sums = np.cumsum(labels)
------+---        nontarget_trial_sums = nontarget_scores.size - \
------+---            (np.arange(1, n_scores + 1) - tar_trial_sums)
------+---
------+---        frr = np.concatenate(
------+---            (np.atleast_1d(0), tar_trial_sums / target_scores.size))
------+---        far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums /
------+---                              nontarget_scores.size))
------+---        thresholds = np.concatenate(
------+---            (np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))
------+---        return frr, far, thresholds
------+--+    def _compute_eer(self, scores: torch.Tensor, labels: torch.Tensor) -> float:
------+--+        """
------+--+        Compute Equal Error Rate.
------+--+        
------+--+        Args:
------+--+            scores (torch.Tensor): prediction scores
------+--+            labels (torch.Tensor): ground truth labels
------+--+            
------+--+        Returns:
------+--+            float: EER value
------+--+        """
------+--+        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy
------+--+        scores_np = scores.detach().cpu().numpy()
------+--+        labels_np = labels.detach().cpu().numpy()
------+--+        
------+--+        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
------+--+        thresholds = np.unique(scores_np)
------+--+        
------+--+        # –í—ã—á–∏—Å–ª—è–µ–º FAR –∏ FRR –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ä–æ–≥–∞
------+--+        far_values = []
------+--+        frr_values = []
------+--+        
------+--+        for threshold in thresholds:
------+--+            # FAR = FP / (FP + TN) = FP / (FP + TN)
------+--+            # FRR = FN / (FN + TP) = FN / (FN + TP)
------+--+            
------+--+            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: 1 –µ—Å–ª–∏ score >= threshold, –∏–Ω–∞—á–µ 0
------+--+            predictions = (scores_np >= threshold).astype(int)
------+--+            
------+--+            # –í—ã—á–∏—Å–ª—è–µ–º confusion matrix
------+--+            tp = np.sum((predictions == 1) & (labels_np == 1))
------+--+            tn = np.sum((predictions == 0) & (labels_np == 0))
------+--+            fp = np.sum((predictions == 1) & (labels_np == 0))
------+--+            fn = np.sum((predictions == 0) & (labels_np == 1))
------+--+            
------+--+            # –í—ã—á–∏—Å–ª—è–µ–º FAR –∏ FRR
------+--+            far = fp / (fp + tn) if (fp + tn) > 0 else 0
------+--+            frr = fn / (fn + tp) if (fn + tp) > 0 else 0
------+--+            
------+--+            far_values.append(far)
------+--+            frr_values.append(frr)
------+--+        
------+--+        # –ù–∞—Ö–æ–¥–∏–º —Ç–æ—á–∫—É, –≥–¥–µ FAR ‚âà FRR
------+--+        far_values = np.array(far_values)
------+--+        frr_values = np.array(frr_values)
------+--+        
------+--+        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å, –≥–¥–µ —Ä–∞–∑–Ω–æ—Å—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω–∞
------+--+        diff = np.abs(far_values - frr_values)
------+--+        min_idx = np.argmin(diff)
------+--+        
------+--+        # EER - —ç—Ç–æ —Å—Ä–µ–¥–Ω–µ–µ FAR –∏ FRR –≤ —ç—Ç–æ–π —Ç–æ—á–∫–µ
------+--+        eer = (far_values[min_idx] + frr_values[min_idx]) / 2
------+--+        
------+--+        return float(eer)
------+-- 
------+---    @classmethod
------+---    def compute_eer(cls, bona_scores, spoof_scores):
------+---        frr, far, thresholds = cls.compute_det_curve(bona_scores, spoof_scores)
------+---        abs_diffs = np.abs(frr - far)
------+---        min_index = np.argmin(abs_diffs)
------+---        eer = np.mean((frr[min_index], far[min_index]))
------+---        return eer, thresholds[min_index]
------+--\ No newline at end of file
------+--+    def set_debug_mode(self, debug_forward=False):
------+--+        """
------+--+        –í–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è forward pass.
------+--+        
------+--+        Args:
------+--+            debug_forward (bool): –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å forward pass
------+--+        """
------+--+        self._debug_forward = debug_forward
------+--+        if debug_forward:
------+--+            print(f"üêõ –†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –≤–∫–ª—é—á–µ–Ω –¥–ª—è {self.__class__.__name__}")
------+--+            print(f"   üìà Debug forward: {debug_forward}")
------+--\ No newline at end of file
------ --diff --git a/src/model/model.py b/src/model/model.py
---------index 6d0bf94..28a4ce4 100644
------+--index 28a4ce4..6ec39da 100644
------ ----- a/src/model/model.py
------ --+++ b/src/model/model.py
---------@@ -66,13 +66,29 @@ class LCNN(nn.Module):
------+--@@ -1,153 +1,113 @@
------+-- import torch
------+---from torch import nn
------+--+import torch.nn as nn
------+--+from typing import Dict, Any
------+-- 
------+---class mfm_block(nn.Module):
------+---    def __init__(self, channels):
------+---        super().__init__()
------+---        self.channels = channels
------+---
------+---    def forward(self, x):
------+---        partition = self.channels // 2
------+---        first_batch = x[:, :partition, ...]
------+---        second_batch = x[:, partition:, ...]
------+---        output = torch.maximum(first_batch, second_batch)
------+---        return output
------+-- 
------+-- class LCNN(nn.Module):
------+---    def __init__(self, in_channels=1, num_classes=2, dropout_p=0.3):
------+---        super().__init__()
------+---
------+---        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=5, stride=1, padding=2)
------+---        self.mfm2 = mfm_block(64)
------+---        self.dropout2 = nn.Dropout2d(dropout_p)
------+---        self.MaxPool3 = nn.MaxPool2d(kernel_size=2, stride=2)
------+---
------+---        self.conv4 = nn.Conv2d(32, 64, kernel_size=1, stride=1)
------+---        self.mfm5 = mfm_block(64)
------+---        self.dropout5 = nn.Dropout2d(dropout_p)
------+---        self.BatchNorm6 = nn.BatchNorm2d(32)
------+---
------+---        self.conv7 = nn.Conv2d(32, 96, kernel_size=3, stride=1, padding=1)
------+---        self.mfm8 = mfm_block(96)
------+---        self.dropout8 = nn.Dropout2d(dropout_p)
------+---
------+---        self.MaxPool9 = nn.MaxPool2d(kernel_size=2, stride=2)
------+---        self.BatchNorm10 = nn.BatchNorm2d(48)
------+---
------+---        self.conv11 = nn.Conv2d(48, 96, kernel_size=1, stride=1)
------+---        self.mfm12 = mfm_block(96)
------+---        self.dropout12 = nn.Dropout2d(dropout_p)
------+---        self.BatchNorm13 = nn.BatchNorm2d(48)
------+---
------+---        self.conv14 = nn.Conv2d(48, 128, kernel_size=3, stride=1, padding=1)
------+---        self.mfm15 = mfm_block(128)
------+---        self.dropout15 = nn.Dropout2d(dropout_p)
------+---
------+---        self.MaxPool16 = nn.MaxPool2d(kernel_size=2, stride=2)
------+---
------+---        self.conv17 = nn.Conv2d(64, 128, kernel_size=1, stride=1)
------+---        self.mfm18 = mfm_block(128)
------+---        self.dropout18 = nn.Dropout2d(dropout_p)
------+---        self.BatchNorm19 = nn.BatchNorm2d(64)
------+---
------+---        self.conv20 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
------+---        self.mfm21 = mfm_block(64)
------+---        self.dropout21 = nn.Dropout2d(dropout_p)
------+---        self.BatchNorm22 = nn.BatchNorm2d(32)
------+---
------+---        self.conv23 = nn.Conv2d(32, 64, kernel_size=1, stride=1)
------+---        self.mfm24 = mfm_block(64)
------+---        self.dropout24 = nn.Dropout2d(dropout_p)
------+---        self.BatchNorm25 = nn.BatchNorm2d(32)
------+---
------+---        self.conv26 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
------+---        self.mfm27 = mfm_block(64)
------+---        self.dropout27 = nn.Dropout2d(dropout_p)
------+---
------+---        self.MaxPool28 = nn.MaxPool2d(kernel_size=2, stride=2)
------+---
------+---        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
------+---        self.fc29 = nn.Linear(32, 160)
------+---        self.dropout29 = nn.Dropout(dropout_p)
------+---        self.mfm30 = mfm_block(160)
------+---        self.BatchNorm31 = nn.BatchNorm1d(80)
------+---        self.fc32 = nn.Linear(80, num_classes)
------+--+    """
------+--+    Light CNN model for audio anti-spoofing.
------+--+    """
------+--+
------+--+    def __init__(self, num_classes=2, **kwargs):
------+--+        """
------+--+        Args:
------+--+            num_classes (int): number of output classes
------+--+            **kwargs: additional arguments
------+--+        """
------+--+        super(LCNN, self).__init__()
------+--         
------+---        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
------+---        self._initialize_weights()
------+---
------+---    def _initialize_weights(self):
------+---        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
------+---        for m in self.modules():
------+---            if isinstance(m, nn.Conv2d):
------+---                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
------+---                if m.bias is not None:
------+---                    nn.init.constant_(m.bias, 0)
------+---            elif isinstance(m, nn.BatchNorm2d):
------+---                nn.init.constant_(m.weight, 1)
------+---                nn.init.constant_(m.bias, 0)
------+---            elif isinstance(m, nn.Linear):
------+---                nn.init.normal_(m.weight, 0, 0.01)
------+---                nn.init.constant_(m.bias, 0)
------+---
------+---    def forward(self, data_object, **kwargs):
------+---        x = data_object
------+---        x = self.conv1(x)
------+---        x = self.mfm2(x)
------+---        x = self.dropout2(x)
------+---        x = self.MaxPool3(x)
------+---
------+---        x = self.conv4(x)
------+---        x = self.mfm5(x)
------+---        x = self.dropout5(x)
------+---        x = self.BatchNorm6(x)
------+---
------+---        x = self.conv7(x)
------+---        x = self.mfm8(x)
------+---        x = self.dropout8(x)
------+---
------+---        x = self.MaxPool9(x)
------+---        x = self.BatchNorm10(x)
------+---
------+---        x = self.conv11(x)
------+---        x = self.mfm12(x)
------+---        x = self.dropout12(x)
------+---        x = self.BatchNorm13(x)
------+---
------+---        x = self.conv14(x)
------+---        x = self.mfm15(x)
------+---        x = self.dropout15(x)
------+---
------+---        x = self.MaxPool16(x)
------+---
------+---        x = self.conv17(x)
------+---        x = self.mfm18(x)
------+---        x = self.dropout18(x)
------+---        x = self.BatchNorm19(x)
------+---
------+---        x = self.conv20(x)
------+---        x = self.mfm21(x)
------+---        x = self.dropout21(x)
------+---        x = self.BatchNorm22(x)
------+---
------+---        x = self.conv23(x)
------+---        x = self.mfm24(x)
------+---        x = self.dropout24(x)
------+---        x = self.BatchNorm25(x)
------+---
------+---        x = self.conv26(x)
------+---        x = self.mfm27(x)
------+---        x = self.dropout27(x)
------+--+        self.num_classes = num_classes
------+--+        
------+--+        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
------+--+        self.features = nn.Sequential(
------+--+            # –ü–µ—Ä–≤—ã–π –±–ª–æ–∫
------+--+            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),
------+--+            nn.BatchNorm2d(64),
------+--+            nn.ReLU(inplace=True),
------+--+            nn.MaxPool2d(kernel_size=2, stride=2),
------+--+            
------+--+            # –í—Ç–æ—Ä–æ–π –±–ª–æ–∫
------+--+            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
------+--+            nn.BatchNorm2d(128),
------+--+            nn.ReLU(inplace=True),
------+--+            nn.MaxPool2d(kernel_size=2, stride=2),
------+--+            
------+--+            # –¢—Ä–µ—Ç–∏–π –±–ª–æ–∫
------+--+            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
------+--+            nn.BatchNorm2d(256),
------+--+            nn.ReLU(inplace=True),
------+--+            nn.MaxPool2d(kernel_size=2, stride=2),
------+--+            
------+--+            # –ß–µ—Ç–≤–µ—Ä—Ç—ã–π –±–ª–æ–∫
------+--+            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
------+--+            nn.BatchNorm2d(512),
------+--+            nn.ReLU(inplace=True),
------+--+            nn.MaxPool2d(kernel_size=2, stride=2),
------+--+        )
------+--+        
------+--+        # Global Average Pooling
------+--+        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))
------+--+        
------+--+        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
------+--+        self.classifier = nn.Sequential(
------+--+            nn.Dropout(0.5),
------+--+            nn.Linear(512, 256),
------+--+            nn.ReLU(inplace=True),
------+--+            nn.Dropout(0.5),
------+--+            nn.Linear(256, num_classes)
------+--+        )
------+--+
------+--+    def forward(self, **batch) -> Dict[str, torch.Tensor]:
------+--+        """
------+--+        Forward pass of the model.
------+--+        
------+--+        Args:
------+--+            **batch: input batch containing tensors
------+--+            
------+--+        Returns:
------+--+            Dict[str, torch.Tensor]: model outputs
------+--+        """
------+--+        # –ü–æ–ª—É—á–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
------+--+        if 'spectrogram' in batch:
------+--+            x = batch['spectrogram']
------+--+        elif 'data_object' in batch:
------+--+            x = batch['data_object']
------+--+        else:
------+--+            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ç–µ–Ω–∑–æ—Ä –∏–∑ –±–∞—Ç—á–∞
------+--+            x = next(iter(batch.values()))
------+--+        
------+--+        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ñ–æ—Ä–º—É
------+--+        if x.dim() == 3:
------+--+            x = x.unsqueeze(1)  # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–∞–ª
------+--+        elif x.dim() == 2:
------+--+            x = x.unsqueeze(0).unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º batch –∏ –∫–∞–Ω–∞–ª
------+--+        
------+--+        # –ü—Ä–æ—Ö–æ–¥–∏–º —á–µ—Ä–µ–∑ —Å–ª–æ–∏
------+--+        x = self.features(x)
------+--+        
------+--+        x = self.global_avg_pool(x)
------+--+        x = x.view(x.size(0), -1)
------+--+        
------+--+        x = self.classifier(x)
------+--+        
------+--+        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—ã—Ö–æ–¥—ã
------+--+        outputs = {
------+--+            'logits': x
------+--+        }
------+--+        
------+--+        return outputs
------+-- 
------+---        x = self.MaxPool28(x)
------+-- 
------+---        x = self.adaptive_pool(x)
------+---        x = x.view(x.size(0), -1)
------+---        x = self.fc29(x)
------+---        x = self.dropout29(x)
------+---        x = x.unsqueeze(-1).unsqueeze(-1)
------+---        x = self.mfm30(x)
------+---        x = x.squeeze(-1).squeeze(-1)
------+---        x = self.BatchNorm31(x)
------+---        logits = self.fc32(x)
------+---        return {"logits": logits}
------+--\ No newline at end of file
------+--+# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å hydra
------+--+def create_model(**kwargs) -> LCNN:
------+--+    """
------+--+    –°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ LCNN.
------+--+    
------+--+    Args:
------+--+        **kwargs: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
------+--+        
------+--+    Returns:
------+--+        LCNN: —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏
------+--+    """
------+--+    model = LCNN(**kwargs)
------+--+    return model
------+--\ No newline at end of file
------+--diff --git a/src/trainer/base_trainer.py b/src/trainer/base_trainer.py
------+--index e35ffba..0d4e7a1 100644
------+----- a/src/trainer/base_trainer.py
------+--+++ b/src/trainer/base_trainer.py
------+--@@ -148,250 +148,224 @@ class BaseTrainer:
------+--         """
------+--         try:
------+--             self._train_process()
------+---        except KeyboardInterrupt as e:
------+---            self.logger.info("Saving model on keyboard interrupt")
------+---            self._save_checkpoint(self._last_epoch, save_best=False)
------+---            raise e
------+--+        except KeyboardInterrupt:
------+--+            self._save_checkpoint(self._last_epoch, save_best=False, only_best=True)
------+--+            raise
------+--+        except Exception as e:
------+--+            raise
------+-- 
------+--     def _train_process(self):
------+--         """
------+---        Full training logic:
------+---
------+---        Training model for an epoch, evaluating it on non-train partitions,
------+---        and monitoring the performance improvement (for early stopping
------+---        and saving the best checkpoint).
------+--+        Full training logic.
------+--         """
------+--         not_improved_count = 0
------+--         for epoch in range(self.start_epoch, self.epochs + 1):
------+--             self._last_epoch = epoch
------+---            result = self._train_epoch(epoch)
------+---
------+---            # save logged information into logs dict
------+---            logs = {"epoch": epoch}
------+---            logs.update(result)
------+--+            self._train_epoch(epoch)
------+-- 
------+---            # print logged information to the screen
------+---            for key, value in logs.items():
------+---                self.logger.info(f"    {key:15s}: {value}")
------+--+            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞ val, test –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
------+--+            if "val" in self.evaluation_dataloaders:
------+--+                val_logs = {}
------+--+                dataloader = self.evaluation_dataloaders["val"]
------+--+                val_part_logs = self._evaluation_epoch(epoch, "val", dataloader)
------+--+                val_logs.update(val_part_logs)
------+-- 
------+---            # evaluate model performance according to configured metric,
------+---            # save best checkpoint as model_best
------+---            best, stop_process, not_improved_count = self._monitor_performance(
------+---                logs, not_improved_count
------+---            )
------+--+                # log best so far
------+--+                if self.mnt_mode != "off":
------+--+                    improved = self._monitor_performance(val_logs, not_improved_count)
------+--+                    if improved:
------+--+                        not_improved_count = 0
------+--+                    else:
------+--+                        not_improved_count += 1
------+-- 
------+---            if epoch % self.save_period == 0 or best:
------+---                self._save_checkpoint(epoch, save_best=best, only_best=True)
------+--+                if self.mnt_mode != "off" and not_improved_count > self.early_stop:
------+--+                    break
------+-- 
------+---            if stop_process:  # early_stop
------+---                break
------+--+            if epoch % self.save_period == 0:
------+--+                self._save_checkpoint(epoch, save_best=False)
------+-- 
------+--     def _train_epoch(self, epoch):
------+--         """
------+---        Training logic for an epoch, including logging and evaluation on
------+---        non-train partitions.
------+--+        Training logic for an epoch.
------+-- 
------+--         Args:
------+---            epoch (int): current training epoch.
------+---        Returns:
------+---            logs (dict): logs that contain the average loss and metric in
------+---                this epoch.
------+--+            epoch (int): Current epoch number.
------+--         """
------+---        self.is_train = True
------+--         self.model.train()
------+--         self.train_metrics.reset()
------+---        self.writer.set_step((epoch - 1) * self.epoch_len)
------+---        self.writer.add_scalar("epoch", epoch)
------+---        for batch_idx, batch in enumerate(
------+---            tqdm(self.train_dataloader, desc="train", total=self.epoch_len)
------+---        ):
------+--+        
------+--+        pbar = tqdm(self.train_dataloader, desc=f"Train Epoch {epoch}")
------+--+        for batch_idx, batch in enumerate(pbar):
------+--             try:
------+---                batch = self.process_batch(
------+---                    batch,
------+---                    metrics=self.train_metrics,
------+---                )
------+---            except torch.cuda.OutOfMemoryError as e:
------+---                if self.skip_oom:
------+---                    self.logger.warning("OOM on batch. Skipping batch.")
------+---                    torch.cuda.empty_cache()  # free some memory
------+--+                batch = self.process_batch(batch, self.train_metrics)
------+--+                self._log_batch(batch_idx, batch, "train")
------+--+                
------+--+                # –í—ã–≤–æ–¥–∏–º –ª–æ—Å—Å –≤ –∫–æ–Ω—Å–æ–ª—å –∫–∞–∂–¥—ã–µ 50 –±–∞—Ç—á–µ–π
------+--+                if batch_idx % 50 == 0:
------+--+                    loss_key = self.config.writer.loss_names[0]
------+--+                    current_loss = self.train_metrics.avg(loss_key)
------+--+                    print(f"[Batch {batch_idx}] Loss: {current_loss:.6f}")
------+--+                
------+--+                # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏
------+--+                if batch_idx == len(self.train_dataloader) // 2 and "val" in self.evaluation_dataloaders:
------+--+                    self._quick_validation(epoch, "val", self.evaluation_dataloaders["val"])
------+--+                    
------+--+            except RuntimeError as e:
------+--+                if "out of memory" in str(e) and self.skip_oom:
------+--+                    if hasattr(torch.cuda, 'empty_cache'):
------+--+                        torch.cuda.empty_cache()
------+--                     continue
------+--                 else:
------+--                     raise e
------+--+                    
------+--+        self._log_scalars(self.train_metrics)
------+--+
------+--+    def _quick_validation(self, epoch, part, dataloader):
------+--+        """
------+--+        –ë—ã—Å—Ç—Ä–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è EER –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏.
------+-- 
------+---            self.train_metrics.update("grad_norm", self._get_grad_norm())
------+---
------+---            # log current results
------+---            if batch_idx % self.log_step == 0:
------+---                self.writer.set_step((epoch - 1) * self.epoch_len + batch_idx)
------+---                self.logger.debug(
------+---                    "Train Epoch: {} {} Loss: {:.6f}".format(
------+---                        epoch, self._progress(batch_idx), batch["loss"].item()
------+---                    )
------+---                )
------+---                self.writer.add_scalar(
------+---                    "learning rate", self.lr_scheduler.get_last_lr()[0]
------+---                )
------+---                self._log_scalars(self.train_metrics)
------+---                self._log_batch(batch_idx, batch)
------+---                # we don't want to reset train metrics at the start of every epoch
------+---                # because we are interested in recent train metrics
------+---                last_train_metrics = self.train_metrics.result()
------+---                self.train_metrics.reset()
------+---            if batch_idx + 1 >= self.epoch_len:
------+---                break
------+---
------+---        logs = last_train_metrics
------+---
------+---        # Run val/test
------+---        for part, dataloader in self.evaluation_dataloaders.items():
------+---            val_logs = self._evaluation_epoch(epoch, part, dataloader)
------+---            logs.update(**{f"{part}_{name}": value for name, value in val_logs.items()})
------+---
------+---        return logs
------+--+        Args:
------+--+            epoch (int): Current epoch number.
------+--+            part (str): Name of the data part.
------+--+            dataloader (DataLoader): Dataloader for validation.
------+--+        """
------+--+        self.model.eval()
------+--+        temp_metrics = MetricTracker(
------+--+            *self.config.writer.loss_names,
------+--+            *[m.name for m in self.metrics["inference"]],
------+--+            writer=None,  # –ù–µ –ª–æ–≥–∏—Ä—É–µ–º –≤ writer –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
------+--+        )
------+--+        
------+--+        with torch.no_grad():
------+--+            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –±–∞—Ç—á–µ–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ—Ü–µ–Ω–∫–∏
------+--+            num_batches = min(10, len(dataloader))  # –ú–∞–∫—Å–∏–º—É–º 10 –±–∞—Ç—á–µ–π
------+--+            for batch_idx, batch in enumerate(dataloader):
------+--+                if batch_idx >= num_batches:
------+--+                    break
------+--+                    
------+--+                try:
------+--+                    batch = self.process_batch(batch, temp_metrics)
------+--+                except RuntimeError as e:
------+--+                    if "out of memory" in str(e) and self.skip_oom:
------+--+                        if hasattr(torch.cuda, 'empty_cache'):
------+--+                            torch.cuda.empty_cache()
------+--+                        continue
------+--+                    else:
------+--+                        raise e
------+-- 
------+--     def _evaluation_epoch(self, epoch, part, dataloader):
------+--         """
------+---        Evaluate model on the partition after training for an epoch.
------+--+        Validate after training an epoch.
------+-- 
------+--         Args:
------+---            epoch (int): current training epoch.
------+---            part (str): partition to evaluate on
------+---            dataloader (DataLoader): dataloader for the partition.
------+--+            epoch (int): Current epoch number.
------+--+            part (str): Name of the data part.
------+--+            dataloader (DataLoader): Dataloader for validation.
------+--+
------+--         Returns:
------+---            logs (dict): logs that contain the information about evaluation.
------+--+            dict: Dictionary with validation logs.
------+--         """
------+---        self.is_train = False
------+--         self.model.eval()
------+--         self.evaluation_metrics.reset()
------+--+        
------+--         with torch.no_grad():
------+---            for batch_idx, batch in tqdm(
------+---                enumerate(dataloader),
------+---                desc=part,
------+---                total=len(dataloader),
------+---            ):
------+---                batch = self.process_batch(
------+---                    batch,
------+---                    metrics=self.evaluation_metrics,
------+---                )
------+---            self.writer.set_step(epoch * self.epoch_len, part)
------+---            self._log_scalars(self.evaluation_metrics)
------+---            self._log_batch(
------+---                batch_idx, batch, part
------+---            )  # log only the last batch during inference
------+---
------+--+            pbar = tqdm(dataloader, desc=f"Validation {part} Epoch {epoch}")
------+--+            for batch_idx, batch in enumerate(pbar):
------+--+                try:
------+--+                    batch = self.process_batch(batch, self.evaluation_metrics)
------+--+                    self._log_batch(batch_idx, batch, part)
------+--+                        
------+--+                except RuntimeError as e:
------+--+                    if "out of memory" in str(e) and self.skip_oom:
------+--+                        if hasattr(torch.cuda, 'empty_cache'):
------+--+                            torch.cuda.empty_cache()
------+--+                        continue
------+--+                    else:
------+--+                        raise e
------+--+
------+--+        self._log_scalars(self.evaluation_metrics)
------+--         return self.evaluation_metrics.result()
------+-- 
------+--     def _monitor_performance(self, logs, not_improved_count):
------+--         """
------+---        Check if there is an improvement in the metrics. Used for early
------+---        stopping and saving the best checkpoint.
------+--+        Monitor the performance and save the best model.
------+-- 
------+--         Args:
------+---            logs (dict): logs after training and evaluating the model for
------+---                an epoch.
------+---            not_improved_count (int): the current number of epochs without
------+---                improvement.
------+--+            logs (dict): Dictionary with validation logs.
------+--+            not_improved_count (int): Number of epochs without improvement.
------+--+
------+--         Returns:
------+---            best (bool): if True, the monitored metric has improved.
------+---            stop_process (bool): if True, stop the process (early stopping).
------+---                The metric did not improve for too much epochs.
------+---            not_improved_count (int): updated number of epochs without
------+---                improvement.
------+---        """
------+---        best = False
------+---        stop_process = False
------+---        if self.mnt_mode != "off":
------+---            try:
------+---                # check whether model performance improved or not,
------+---                # according to specified metric(mnt_metric)
------+---                if self.mnt_mode == "min":
------+---                    improved = logs[self.mnt_metric] <= self.mnt_best
------+---                elif self.mnt_mode == "max":
------+---                    improved = logs[self.mnt_metric] >= self.mnt_best
------+---                else:
------+---                    improved = False
------+---            except KeyError:
------+---                self.logger.warning(
------+---                    f"Warning: Metric '{self.mnt_metric}' is not found. "
------+---                    "Model performance monitoring is disabled."
------+---                )
------+---                self.mnt_mode = "off"
------+---                improved = False
------+---
------+---            if improved:
------+---                self.mnt_best = logs[self.mnt_metric]
------+---                not_improved_count = 0
------+---                best = True
------+---            else:
------+---                not_improved_count += 1
------+---
------+---            if not_improved_count >= self.early_stop:
------+---                self.logger.info(
------+---                    "Validation performance didn't improve for {} epochs. "
------+---                    "Training stops.".format(self.early_stop)
------+---                )
------+---                stop_process = True
------+---        return best, stop_process, not_improved_count
------+--+            bool: True if the model improved.
------+--+        """
------+--+        if self.mnt_mode == "off":
------+--+            return False
------+--+
------+--+        try:
------+--+            current = logs[self.mnt_metric]
------+--+        except KeyError:
------+--+            return False
------+--+
------+--+        if self.mnt_mode == "min":
------+--+            improved = current < self.mnt_best
------+--+        else:
------+--+            improved = current > self.mnt_best
------+--+
------+--+        if improved:
------+--+            self.mnt_best = current
------+--+            self._save_checkpoint(self._last_epoch, save_best=True)
------+--+
------+--+        return improved
------+-- 
------+--     def move_batch_to_device(self, batch):
------+--         """
------+---        Move all necessary tensors to the device.
------+--+        Move batch to device.
------ -- 
---------         self.MaxPool28 = nn.MaxPool2d(kernel_size=2, stride=2)
------+--         Args:
------+---            batch (dict): dict-based batch containing the data from
------+---                the dataloader.
------+--+            batch (dict): Batch to move to device.
------+--+
------+--         Returns:
------+---            batch (dict): dict-based batch containing the data from
------+---                the dataloader with some of the tensors on the device.
------+--+            dict: Batch on device.
------+--         """
------+---        for tensor_for_device in self.cfg_trainer.device_tensors:
------+---            batch[tensor_for_device] = batch[tensor_for_device].to(self.device)
------+--+        for k, v in batch.items():
------+--+            if isinstance(v, torch.Tensor):
------+--+                batch[k] = v.to(self.device)
------+--         return batch
------ -- 
------+--     def transform_batch(self, batch):
------+--         """
------+---        Transforms elements in batch. Like instance transform inside the
------+---        BaseDataset class, but for the whole batch. Improves pipeline speed,
------+---        especially if used with a GPU.
------ ---
---------         self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
---------         self.fc29 = nn.Linear(32, 160)
---------         self.dropout29 = nn.Dropout(dropout_p)
---------         self.mfm30 = mfm_block(160)
---------         self.BatchNorm31 = nn.BatchNorm1d(80)
---------         self.fc32 = nn.Linear(80, num_classes)
---------+        
---------+        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
---------+        self._initialize_weights()
------+---        Each tensor in a batch undergoes its own transform defined by the key.
------+--+        Transform batch using batch transforms.
------+-- 
------+--         Args:
------+---            batch (dict): dict-based batch containing the data from
------+---                the dataloader.
------+--+            batch (dict): Batch to transform.
------ --+
---------+    def _initialize_weights(self):
---------+        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
---------+        for m in self.modules():
---------+            if isinstance(m, nn.Conv2d):
---------+                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
---------+                if m.bias is not None:
---------+                    nn.init.constant_(m.bias, 0)
---------+            elif isinstance(m, nn.BatchNorm2d):
---------+                nn.init.constant_(m.weight, 1)
---------+                nn.init.constant_(m.bias, 0)
---------+            elif isinstance(m, nn.Linear):
---------+                nn.init.normal_(m.weight, 0, 0.01)
---------+                nn.init.constant_(m.bias, 0)
--------- 
---------     def forward(self, data_object, **kwargs):
---------         x = data_object
------+--         Returns:
------+---            batch (dict): dict-based batch containing the data from
------+---                the dataloader (possibly transformed via batch transform).
------+---        """
------+---        # do batch transforms on device
------+---        transform_type = "train" if self.is_train else "inference"
------+---        transforms = self.batch_transforms.get(transform_type)
------+---        if transforms is not None:
------+---            for transform_name in transforms.keys():
------+---                batch[transform_name] = transforms[transform_name](
------+---                    batch[transform_name]
------+---                )
------+--+            dict: Transformed batch.
------+--+        """
------+--+        if self.batch_transforms is not None:
------+--+            for transform_name, transform in self.batch_transforms.items():
------+--+                if transform_name in batch:
------+--+                    batch[transform_name] = transform(batch[transform_name])
------+--         return batch
------+-- 
------+--     def _clip_grad_norm(self):
------+--         """
------+---        Clips the gradient norm by the value defined in
------+---        config.trainer.max_grad_norm
------+--+        Clip gradient norm.
------+--         """
------+---        if self.config["trainer"].get("max_grad_norm", None) is not None:
------+--+        if self.cfg_trainer.get("grad_clip_norm") is not None:
------+--             clip_grad_norm_(
------+---                self.model.parameters(), self.config["trainer"]["max_grad_norm"]
------+--+                self.model.parameters(), self.cfg_trainer.grad_clip_norm
------+--             )
------+-- 
------+--     @torch.no_grad()
------+--     def _get_grad_norm(self, norm_type=2):
------+--         """
------+---        Calculates the gradient norm for logging.
------+--+        Get gradient norm.
------+-- 
------+--         Args:
------+---            norm_type (float | str | None): the order of the norm.
------+--+            norm_type (int): Type of norm.
------+--+
------+--         Returns:
------+---            total_norm (float): the calculated norm.
------+--+            float: Gradient norm.
------+--         """
------+--         parameters = self.model.parameters()
------+--         if isinstance(parameters, torch.Tensor):
------+--@@ -401,17 +375,14 @@ class BaseTrainer:
------+--             torch.stack([torch.norm(p.grad.detach(), norm_type) for p in parameters]),
------+--             norm_type,
------+--         )
------+---        return total_norm.item()
------+--+        return total_norm
------+-- 
------+--     def _progress(self, batch_idx):
------+--         """
------+---        Calculates the percentage of processed batch within the epoch.
------+--+        Print progress.
------+-- 
------+--         Args:
------+---            batch_idx (int): the current batch index.
------+---        Returns:
------+---            progress (str): contains current step and percentage
------+---                within the epoch.
------+--+            batch_idx (int): Current batch index.
------+--         """
------+--         base = "[{}/{} ({:.0f}%)]"
------+--         if hasattr(self.train_dataloader, "n_samples"):
------+--@@ -425,129 +396,106 @@ class BaseTrainer:
------+--     @abstractmethod
------+--     def _log_batch(self, batch_idx, batch, mode="train"):
------+--         """
------+---        Abstract method. Should be defined in the nested Trainer Class.
------+---
------+--         Log data from batch. Calls self.writer.add_* to log data
------+--         to the experiment tracker.
------+-- 
------+--         Args:
------+---            batch_idx (int): index of the current batch.
------+---            batch (dict): dict-based batch after going through
------+---                the 'process_batch' function.
------+---            mode (str): train or inference. Defines which logging
------+---                rules to apply.
------+--+            batch_idx (int): Current batch index.
------+--+            batch (dict): Batch data.
------+--+            mode (str): Mode (train or validation).
------+--         """
------+---        return NotImplementedError()
------+--+        pass
------+-- 
------+--     def _log_scalars(self, metric_tracker: MetricTracker):
------+--         """
------+---        Wrapper around the writer 'add_scalar' to log all metrics.
------+--+        Log scalars to the experiment tracker.
------+-- 
------+--         Args:
------+---            metric_tracker (MetricTracker): calculated metrics.
------+--+            metric_tracker (MetricTracker): Metric tracker.
------+--         """
------+---        if self.writer is None:
------+---            return
------+---        for metric_name in metric_tracker.keys():
------+---            self.writer.add_scalar(f"{metric_name}", metric_tracker.avg(metric_name))
------+--+        for metric_name, metric_value in metric_tracker.result().items():
------+--+            self.writer.add_scalar(metric_name, metric_value)
------+-- 
------+--     def _save_checkpoint(self, epoch, save_best=False, only_best=False):
------+--         """
------+---        Save the checkpoints.
------+--+        Save checkpoint.
------+-- 
------+--         Args:
------+---            epoch (int): current epoch number.
------+---            save_best (bool): if True, rename the saved checkpoint to 'model_best.pth'.
------+---            only_best (bool): if True and the checkpoint is the best, save it only as
------+---                'model_best.pth'(do not duplicate the checkpoint as
------+---                checkpoint-epochEpochNumber.pth)
------+--+            epoch (int): Current epoch number.
------+--+            save_best (bool): Whether to save the best model.
------+--+            only_best (bool): Whether to save only the best model.
------+--         """
------+--         arch = type(self.model).__name__
------+--+
------+--         state = {
------+--             "arch": arch,
------+--             "epoch": epoch,
------+--             "state_dict": self.model.state_dict(),
------+--             "optimizer": self.optimizer.state_dict(),
------+---            "lr_scheduler": self.lr_scheduler.state_dict(),
------+--             "monitor_best": self.mnt_best,
------+--             "config": self.config,
------+--         }
------+---        filename = str(self.checkpoint_dir / f"checkpoint-epoch{epoch}.pth")
------+---        if not (only_best and save_best):
------+---            torch.save(state, filename)
------+---            if self.config.writer.log_checkpoints:
------+---                self.writer.add_checkpoint(filename, str(self.checkpoint_dir.parent))
------+---            self.logger.info(f"Saving checkpoint: {filename} ...")
------+--+
------+--+        if self.lr_scheduler is not None:
------+--+            state["lr_scheduler"] = self.lr_scheduler.state_dict()
------+--+
------+--+        filename = str(self.checkpoint_dir / "checkpoint-epoch{}.pth".format(epoch))
------+--+        if not (self.checkpoint_dir).exists():
------+--+            self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
------+--+
------+--         if save_best:
------+--             best_path = str(self.checkpoint_dir / "model_best.pth")
------+--             torch.save(state, best_path)
------+---            if self.config.writer.log_checkpoints:
------+---                self.writer.add_checkpoint(best_path, str(self.checkpoint_dir.parent))
------+---            self.logger.info("Saving current best: model_best.pth ...")
------+--+            del state["optimizer"], state["lr_scheduler"], state["config"]
------+--+            torch.save(state, best_path + ".tmp")
------+--+            import os
------+--+            os.replace(best_path + ".tmp", best_path)
------+--+        elif not only_best:
------+--+            torch.save(state, filename)
------+--+            del state["optimizer"], state["lr_scheduler"], state["config"]
------+--+            torch.save(state, filename + ".tmp")
------+--+            import os
------+--+            os.replace(filename + ".tmp", filename)
------+-- 
------+--     def _resume_checkpoint(self, resume_path):
------+--         """
------+---        Resume from a saved checkpoint (in case of server crash, etc.).
------+---        The function loads state dicts for everything, including model,
------+---        optimizers, etc.
------+---
------+---        Notice that the checkpoint should be located in the current experiment
------+---        saved directory (where all checkpoints are saved in '_save_checkpoint').
------+--+        Resume from saved checkpoint.
------+-- 
------+--         Args:
------+---            resume_path (str): Path to the checkpoint to be resumed.
------+--+            resume_path (str): Path to checkpoint.
------+--         """
------+--         resume_path = str(resume_path)
------+---        self.logger.info(f"Loading checkpoint: {resume_path} ...")
------+---        checkpoint = torch.load(resume_path, self.device)
------+--+        checkpoint = torch.load(resume_path, map_location=self.device)
------+--         self.start_epoch = checkpoint["epoch"] + 1
------+--         self.mnt_best = checkpoint["monitor_best"]
------+-- 
------+--         # load architecture params from checkpoint.
------+--         if checkpoint["config"]["model"] != self.config["model"]:
------+--             self.logger.warning(
------+---                "Warning: Architecture configuration given in the config file is different from that "
------+---                "of the checkpoint. This may yield an exception when state_dict is loaded."
------+--+                "Warning: Architecture configuration given in config file is different from that of checkpoint. "
------+--+                "This may create an exception while state_dict is being loaded."
------+--             )
------+--         self.model.load_state_dict(checkpoint["state_dict"])
------+-- 
------+--         # load optimizer state from checkpoint only when optimizer type is not changed.
------+---        if (
------+---            checkpoint["config"]["optimizer"] != self.config["optimizer"]
------+---            or checkpoint["config"]["lr_scheduler"] != self.config["lr_scheduler"]
------+---        ):
------+--+        if checkpoint["config"]["optimizer"] != self.config["optimizer"]:
------+--             self.logger.warning(
------+---                "Warning: Optimizer or lr_scheduler given in the config file is different "
------+---                "from that of the checkpoint. Optimizer and scheduler parameters "
------+---                "are not resumed."
------+--+                "Warning: Optimizer or lr_scheduler given in config file is different "
------+--+                "from that of checkpoint. Optimizer parameters not being resumed."
------+--             )
------+--         else:
------+--             self.optimizer.load_state_dict(checkpoint["optimizer"])
------+---            self.lr_scheduler.load_state_dict(checkpoint["lr_scheduler"])
------+-- 
------+---        self.logger.info(
------+---            f"Checkpoint loaded. Resume training from epoch {self.start_epoch}"
------+---        )
------+--+        if self.lr_scheduler is not None and "lr_scheduler" in checkpoint:
------+--+            self.lr_scheduler.load_state_dict(checkpoint["lr_scheduler"])
------+-- 
------+--     def _from_pretrained(self, pretrained_path):
------+--         """
------+---        Init model with weights from pretrained pth file.
------+---
------+---        Notice that 'pretrained_path' can be any path on the disk. It is not
------+---        necessary to locate it in the experiment saved dir. The function
------+---        initializes only the model.
------+--+        Load pretrained model.
------+-- 
------+--         Args:
------+---            pretrained_path (str): path to the model state dict.
------+--+            pretrained_path (str): Path to pretrained model.
------+--         """
------+--         pretrained_path = str(pretrained_path)
------+---        if hasattr(self, "logger"):  # to support both trainer and inferencer
------+---            self.logger.info(f"Loading model weights from: {pretrained_path} ...")
------+---        else:
------+---            print(f"Loading model weights from: {pretrained_path} ...")
------+---        checkpoint = torch.load(pretrained_path, self.device)
------+---
------+---        if checkpoint.get("state_dict") is not None:
------+---            self.model.load_state_dict(checkpoint["state_dict"])
------+---        else:
------+---            self.model.load_state_dict(checkpoint)
------+--\ No newline at end of file
------+--+        checkpoint = torch.load(pretrained_path, map_location=self.device)
------+--+        self.model.load_state_dict(checkpoint["state_dict"])
------+--\ No newline at end of file
------ --diff --git a/src/trainer/trainer.py b/src/trainer/trainer.py
---------index 1b806fb..3313fea 100644
------+--index 3313fea..f2b2faa 100644
------ ----- a/src/trainer/trainer.py
------ --+++ b/src/trainer/trainer.py
---------@@ -47,17 +47,17 @@ class Trainer(BaseTrainer):
---------             if self.lr_scheduler is not None:
---------                 self.lr_scheduler.step()
--------- 
----------        
---------+        # –û–±–Ω–æ–≤–ª—è–µ–º loss –º–µ—Ç—Ä–∏–∫–∏
---------         for loss_name in self.config.writer.loss_names:
---------             metrics.update(loss_name, batch[loss_name].item())
--------- 
----------      
---------+        # –û–±–Ω–æ–≤–ª—è–µ–º EER –º–µ—Ç—Ä–∏–∫—É
---------         if "logits" in batch:
---------             scores = torch.softmax(batch["logits"], dim=1)[:, 1]
---------             labels = batch["labels"]
---------             metrics.update_eer(scores, labels)
--------- 
----------       
---------+        # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
------+--@@ -61,9 +61,9 @@ class Trainer(BaseTrainer):
------ --         for met in metric_funcs:
------ --             if met.name != "eer":
------ --                 try:
--------diff --git a/requirements.txt b/requirements.txt
--------index 8aab454..1dc9376 100644
----------- a/requirements.txt
--------+++ b/requirements.txt
--------@@ -1,37 +1,24 @@
---------# –û—Å–Ω–æ–≤–Ω—ã–µ PyTorch –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
-------- torch==2.2.0
-------- torchvision==0.17.0
-------- torchaudio==2.2.0
-------- torchmetrics==1.7.4
---------
---------# –ù–∞—É—á–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
-------- numpy==1.26.4
-------- pandas==2.3.1
-------- matplotlib==3.9.4
-------- scipy
---------
---------# –ê—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞
-------- soundfile==0.13.1
-------- librosa
---------
---------# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
-------- wandb==0.21.0
-------- comet-ml==3.50.0
-------- hydra-core==1.3.2
-------- omegaconf==2.3.0
---------
---------# –£—Ç–∏–ª–∏—Ç—ã
-------- tqdm==4.67.1
-------- psutil==7.0.0
-------- requests==2.32.4
-------- pyyaml==6.0.2
---------
---------# –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞
-------- black
-------- isort
-------- pre-commit
-------- flake8
---------
---------# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è ML
-------- scikit-learn
-------- seaborn
--------\ No newline at end of file
--------diff --git a/src/configs/dataloader/default.yaml b/src/configs/dataloader/default.yaml
--------index 80fbc65..902e80f 100644
----------- a/src/configs/dataloader/default.yaml
--------+++ b/src/configs/dataloader/default.yaml
--------@@ -1,4 +1,4 @@
-------- _target_: torch.utils.data.DataLoader
---------batch_size: 8
--------+batch_size: 16
-------- num_workers: 4
-------- pin_memory: true 
--------\ No newline at end of file
--------diff --git a/src/configs/lr_scheduler/step.yaml b/src/configs/lr_scheduler/step.yaml
--------index bd12a00..3c208ac 100644
----------- a/src/configs/lr_scheduler/step.yaml
--------+++ b/src/configs/lr_scheduler/step.yaml
--------@@ -1,3 +1,3 @@
-------- _target_: torch.optim.lr_scheduler.StepLR
---------step_size: 10
---------gamma: 0.1 
--------\ No newline at end of file
--------+step_size: 20
--------+gamma: 0.5 
--------\ No newline at end of file
--------diff --git a/src/configs/optimizer/adam.yaml b/src/configs/optimizer/adam.yaml
--------index 9af2fd8..1310b87 100644
----------- a/src/configs/optimizer/adam.yaml
--------+++ b/src/configs/optimizer/adam.yaml
--------@@ -1,3 +1,3 @@
-------- _target_: torch.optim.Adam
---------lr: 0.0001
--------+lr: 0.001
-------- weight_decay: 0.0001 
--------\ No newline at end of file
--------diff --git a/src/configs/transforms/default.yaml b/src/configs/transforms/default.yaml
--------index 4aea72d..32f1775 100644
----------- a/src/configs/transforms/default.yaml
--------+++ b/src/configs/transforms/default.yaml
--------@@ -2,7 +2,10 @@ instance_transforms:
--------   data_object: ${transforms.stft}
-------- 
-------- stft:
---------  _target_: src.transforms.stft.AudioFrontend
--------+  _target_: src.transforms.stft.STFTTransform
--------+  n_fft: 1024
--------+  hop_length: 512
--------+  win_length: 1024
-------- 
-------- batch_transforms:
--------   train:
--------diff --git a/src/datasets/base_dataset.py b/src/datasets/base_dataset.py
--------index bf51c70..e75525d 100644
----------- a/src/datasets/base_dataset.py
--------+++ b/src/datasets/base_dataset.py
--------@@ -1,6 +1,6 @@
-------- import logging
-------- import random
---------from typing import List
--------+from typing import List, Dict, Any, Optional
-------- 
-------- import torch
-------- import torchaudio
--------@@ -11,66 +11,65 @@ logger = logging.getLogger(__name__)
-------- 
-------- class BaseDataset(Dataset):
--------     """
---------    Base class for the datasets.
---------
---------    Given a proper index (list[dict]), allows to process different datasets
---------    for the same task in the identical manner. Therefore, to work with
---------    several datasets, the user only have to define index in a nested class.
--------+    Base class for all datasets.
--------     """
-------- 
--------     def __init__(
---------        self, index, limit=None, shuffle_index=False, instance_transforms=None
--------+        self,
--------+        index: List[Dict[str, Any]],
--------+        instance_transforms: Optional[Dict[str, Any]] = None,
--------+        *args,
--------+        **kwargs,
--------     ):
--------         """
--------         Args:
---------            index (list[dict]): list, containing dict for each element of
---------                the dataset. The dict has required metadata information,
---------                such as label and object path.
---------            limit (int | None): if not None, limit the total number of elements
---------                in the dataset to 'limit' elements.
---------            shuffle_index (bool): if True, shuffle the index. Uses python
---------                random package with seed 42.
---------            instance_transforms (dict[Callable] | None): transforms that
---------                should be applied on the instance. Depend on the
---------                tensor name.
---------        """
---------        self._assert_index_is_valid(index)
---------
---------        index = self._shuffle_and_limit_index(index, limit, shuffle_index)
---------        self._index: List[dict] = index
---------
--------+            index (List[Dict[str, Any]]): list of dictionaries, each containing
--------+                the data for one sample.
--------+            instance_transforms (Optional[Dict[str, Any]]): transforms to apply
--------+                to instances. Depend on the tensor name.
--------+        """
--------+        self.index = index
--------         self.instance_transforms = instance_transforms
-------- 
---------    def __getitem__(self, ind):
---------        """
---------        Get element from the index, preprocess it, and combine it
---------        into a dict.
--------+    def __len__(self):
--------+        return len(self.index)
-------- 
---------        Notice that the choice of key names is defined by the template user.
---------        However, they should be consistent across dataset getitem, collate_fn,
---------        loss_function forward method, and model forward method.
--------+    def __getitem__(self, idx):
--------+        """
--------+        Get item by index.
-------- 
--------         Args:
---------            ind (int): index in the self.index list.
--------+            idx (int): index of the item.
--------+
--------         Returns:
---------            instance_data (dict): dict, containing instance
---------                (a single dataset element).
--------+            dict: item data.
--------         """
---------        data_dict = self._index[ind]
---------        data_path = data_dict["path"]
---------        data_object = self.load_object(data_path)
---------        data_label = data_dict["label"]
--------+        item = self.index[idx]
--------+        
--------+        # –ü—Ä–∏–º–µ–Ω—è–µ–º instance transforms
--------+        if self.instance_transforms is not None:
--------+            item = self._apply_instance_transforms(item)
--------+        
--------+        return item
-------- 
---------        instance_data = {"data_object": data_object, "labels": data_label}
---------        instance_data = self.preprocess_data(instance_data)
--------+    def _apply_instance_transforms(self, item: Dict[str, Any]) -> Dict[str, Any]:
--------+        """
--------+        Apply instance transforms to the item.
-------- 
---------        return instance_data
--------+        Args:
--------+            item (Dict[str, Any]): item data.
-------- 
---------    def __len__(self):
---------        """
---------        Get length of the dataset (length of the index).
--------+        Returns:
--------+            Dict[str, Any]: transformed item data.
--------         """
---------        return len(self._index)
--------+        for transform_name, transform in self.instance_transforms.items():
--------+            if transform_name in item:
--------+                try:
--------+                    item[transform_name] = transform(item[transform_name])
--------+                except Exception as e:
--------+                    raise
--------+        
--------+        return item
-------- 
--------     def load_object(self, path):
--------         """
--------@@ -126,74 +125,63 @@ class BaseDataset(Dataset):
--------         the __init__ before shuffling and limiting.
-------- 
--------         Args:
---------            index (list[dict]): list, containing dict for each element of
---------                the dataset. The dict has required metadata information,
---------                such as label and object path.
--------+            index (list): list of records to filter.
--------+
--------         Returns:
---------            index (list[dict]): list, containing dict for each element of
---------                the dataset that satisfied the condition. The dict has
---------                required metadata information, such as label and object path.
--------+            list: filtered list of records.
--------         """
---------        # Filter logic
---------        pass
--------+        return index
-------- 
--------     @staticmethod
--------     def _assert_index_is_valid(index):
--------         """
---------        Check the structure of the index and ensure it satisfies the desired
---------        conditions.
--------+        Assert that the index is valid.
-------- 
--------         Args:
---------            index (list[dict]): list, containing dict for each element of
---------                the dataset. The dict has required metadata information,
---------                such as label and object path.
---------        """
---------        for entry in index:
---------            assert "path" in entry, (
---------                "Each dataset item should include field 'path'" " - path to audio file."
---------            )
---------            assert "label" in entry, (
---------                "Each dataset item should include field 'label'"
---------                " - object ground-truth label."
---------            )
--------+            index (list): list of records to validate.
--------+        """
--------+        assert isinstance(index, list), "Index should be a list"
--------+        assert len(index) > 0, "Index should not be empty"
--------+        for record in index:
--------+            assert isinstance(record, dict), "Each record should be a dict"
--------+            assert "path" in record, "Each record should have a 'path' field"
--------+            assert "label" in record, "Each record should have a 'label' field"
-------- 
--------     @staticmethod
--------     def _sort_index(index):
--------         """
---------        Sort index via some rules.
--------+        Sort the index by some criterion.
-------- 
--------         This is not used in the example. The method should be called in
---------        the __init__ before shuffling and limiting and after filtering.
--------+        the __init__ before shuffling and limiting.
-------- 
--------         Args:
---------            index (list[dict]): list, containing dict for each element of
---------                the dataset. The dict has required metadata information,
---------                such as label and object path.
--------+            index (list): list of records to sort.
--------+
--------         Returns:
---------            index (list[dict]): sorted list, containing dict for each element
---------                of the dataset. The dict has required metadata information,
---------                such as label and object path.
--------+            list: sorted list of records.
--------         """
---------        return sorted(index, key=lambda x: x["KEY_FOR_SORTING"])
--------+        return index
-------- 
--------     @staticmethod
--------     def _shuffle_and_limit_index(index, limit, shuffle_index):
--------         """
---------        Shuffle elements in index and limit the total number of elements.
--------+        Shuffle and limit the index.
--------+
--------+        This is not used in the example. The method should be called in
--------+        the __init__ before shuffling and limiting.
-------- 
--------         Args:
---------            index (list[dict]): list, containing dict for each element of
---------                the dataset. The dict has required metadata information,
---------                such as label and object path.
---------            limit (int | None): if not None, limit the total number of elements
---------                in the dataset to 'limit' elements.
---------            shuffle_index (bool): if True, shuffle the index. Uses python
---------                random package with seed 42.
--------+            index (list): list of records to shuffle and limit.
--------+            limit (int): maximum number of records to keep.
--------+            shuffle_index (bool): whether to shuffle the index.
--------+
--------+        Returns:
--------+            list: shuffled and limited list of records.
--------         """
--------         if shuffle_index:
--------             random.seed(42)
--------             random.shuffle(index)
---------
--------         if limit is not None:
--------             index = index[:limit]
--------         return index
--------\ No newline at end of file
--------diff --git a/src/datasets/collate.py b/src/datasets/collate.py
--------index 4c2c81e..6cb3b10 100644
----------- a/src/datasets/collate.py
--------+++ b/src/datasets/collate.py
--------@@ -19,6 +19,15 @@ def collate_fn(dataset_items: list[dict]):
-------- 
--------     # Pad audio sequences to the same length
--------     audio_tensors = [elem["data_object"] for elem in dataset_items]
--------+    
--------+    # Handle different audio tensor shapes
--------+    if len(audio_tensors) == 0:
--------+        # Return empty batch
--------+        result_batch["data_object"] = torch.empty(0)
--------+        result_batch["labels"] = torch.empty(0, dtype=torch.long)
--------+        return result_batch
--------+    
--------+    # Get max length for padding
--------     max_length = max(audio.shape[-1] for audio in audio_tensors)
--------     
--------     padded_audio = []
--------@@ -30,6 +39,6 @@ def collate_fn(dataset_items: list[dict]):
--------         padded_audio.append(audio)
--------     
--------     result_batch["data_object"] = torch.stack(padded_audio)
---------    result_batch["labels"] = torch.tensor([elem["labels"] for elem in dataset_items])
--------+    result_batch["labels"] = torch.tensor([elem["labels"] for elem in dataset_items], dtype=torch.long)
-------- 
--------     return result_batch
--------\ No newline at end of file
--------diff --git a/src/datasets/data_utils.py b/src/datasets/data_utils.py
--------index 8262ceb..63e8cce 100644
----------- a/src/datasets/data_utils.py
--------+++ b/src/datasets/data_utils.py
--------@@ -36,6 +36,9 @@ def move_batch_transforms_to_device(batch_transforms, device):
--------             tensor name.
--------         device (str): device to use for batch transforms.
--------     """
--------+    if batch_transforms is None:
--------+        return
--------+        
--------     for transform_type in batch_transforms.keys():
--------         transforms = batch_transforms.get(transform_type)
--------         if transforms is not None:
--------@@ -60,6 +63,7 @@ def get_dataloaders(config, device):
--------     """
--------     # transforms or augmentations init
--------     batch_transforms = instantiate(config.transforms.batch_transforms)
--------+    
--------     move_batch_transforms_to_device(batch_transforms, device)
-------- 
--------     # dataset partitions init
--------diff --git a/src/datasets/mydataset.py b/src/datasets/mydataset.py
--------index 02a09c3..94e7e12 100644
----------- a/src/datasets/mydataset.py
--------+++ b/src/datasets/mydataset.py
--------@@ -1,5 +1,6 @@
-------- import numpy as np
-------- import torch
--------+import torchaudio
-------- from tqdm.auto import tqdm
-------- 
-------- from src.datasets.base_dataset import BaseDataset
--------@@ -37,6 +38,50 @@ class AudioSpoofingDataset(BaseDataset):
-------- 
--------         super().__init__(index, instance_transforms=instance_transforms, *args, **kwargs)
-------- 
--------+    def __getitem__(self, idx):
--------+        """
--------+        Get item by index.
--------+
--------+        Args:
--------+            idx (int): index of the item.
--------+
--------+        Returns:
--------+            dict: item data with 'data_object' and 'labels' keys.
--------+        """
--------+        item = self.index[idx]
--------+        
--------+        # Load audio file
--------+        audio_path = item["path"]
--------+        label = item["label"]
--------+        
--------+        try:
--------+            # Load audio using torchaudio
--------+            waveform, sample_rate = torchaudio.load(audio_path)
--------+            
--------+            # Convert to mono if stereo
--------+            if waveform.shape[0] > 1:
--------+                waveform = torch.mean(waveform, dim=0, keepdim=True)
--------+            
--------+            # Create item with correct keys
--------+            item_data = {
--------+                "data_object": waveform,
--------+                "labels": label
--------+            }
--------+            
--------+            # Apply instance transforms
--------+            if self.instance_transforms is not None:
--------+                item_data = self._apply_instance_transforms(item_data)
--------+            
--------+            return item_data
--------+            
--------+        except Exception as e:
--------+            # Return zero tensor as fallback
--------+            fallback_waveform = torch.zeros(1, 16000)  # 1 second of silence at 16kHz
--------+            return {
--------+                "data_object": fallback_waveform,
--------+                "labels": label
--------+            }
--------+
--------     def _create_index(self, label_path, audio_path, out_path):
--------         """
--------         Args:
--------@@ -47,25 +92,40 @@ class AudioSpoofingDataset(BaseDataset):
--------         Returns:
--------             index (list[dict]): list of dictionaries, each with "path" and "label" fields
--------         """
---------
--------         index = []
--------+        
--------+        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ
--------+        with open(label_path, "r") as f:
--------+            total_lines = sum(1 for _ in f)
--------+        
--------+        bonafide_count = 0
--------+        spoof_count = 0
-------- 
--------         with open(label_path, "r") as f:
---------            for line in f:
--------+            for line_num, line in enumerate(tqdm(f, total=total_lines, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫")):
--------                 parts = line.strip().split()
--------                 file_id = parts[1]
--------                 class_name = parts[-1]
--------                 label = 0 if class_name == "bonafide" else 1  # Fixed typo
--------                 path = str(Path(audio_path) / f"{file_id}.flac")
--------+                
--------+                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
--------+                if not Path(path).exists():
--------+                    continue
--------+                
--------                 index.append(
--------                     {
--------                         "path" : path,
--------                         "label" : label
--------                     }
--------                 )
---------        print("Separate to path and labels complete")
--------+                
--------+                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
--------+                if label == 0:
--------+                    bonafide_count += 1
--------+                else:
--------+                    spoof_count += 1
--------+        
--------         write_json(index, out_path)
-------- 
---------        print(f"Created {len(index)} entries in {out_path}")
---------
--------         return index
--------diff --git a/src/loss/crossentropy.py b/src/loss/crossentropy.py
--------index d8ad43e..677200c 100644
----------- a/src/loss/crossentropy.py
--------+++ b/src/loss/crossentropy.py
--------@@ -1,28 +1,80 @@
-------- import torch
---------from torch import nn
---------import torch.nn.functional as F
--------+import torch.nn as nn
--------+from typing import Dict, Any
--------+
-------- 
-------- class CrossEntropyLoss(nn.Module):
--------     """
---------    –ü—Ä–æ—Å—Ç–æ–π CrossEntropy loss –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
--------+    Cross Entropy Loss for audio anti-spoofing.
--------     """
-------- 
---------    def __init__(self):
---------        super().__init__()
--------+    def __init__(self, **kwargs):
--------+        """
--------+        Args:
--------+            **kwargs: additional arguments
--------+        """
--------+        super(CrossEntropyLoss, self).__init__()
--------+        
--------+        print("üéØ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CrossEntropyLoss...")
--------+        
--------+        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
--------+        for key, value in kwargs.items():
--------+            print(f"   üìä {key}: {value}")
--------+        
--------+        self.criterion = nn.CrossEntropyLoss()
--------+        print("‚úÖ CrossEntropyLoss –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
-------- 
---------    def forward(self, logits: torch.Tensor, labels: torch.Tensor, **kwargs):
--------+    def forward(self, **batch) -> Dict[str, torch.Tensor]:
--------         """
---------        CrossEntropy loss compute
--------+        Compute cross entropy loss.
--------         
--------         Args:
---------            logits (Tensor): model output predictions (batch_size, num_classes)
---------            labels (Tensor): ground truth labels (batch_size,)
---------            **kwargs: –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã (–∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è)
--------+            **batch: input batch containing logits and labels
--------+            
--------         Returns:
---------            losses (dict): dictionary loss
--------+            Dict[str, torch.Tensor]: loss dictionary
--------         """
--------+        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
--------+        if hasattr(self, '_debug_forward') and self._debug_forward:
--------+            print(f"   üíî CrossEntropyLoss forward: –≤—Ö–æ–¥–Ω—ã–µ –∫–ª—é—á–∏ {list(batch.keys())}")
--------+            for key, value in batch.items():
--------+                if isinstance(value, torch.Tensor):
--------+                    print(f"      {key}: shape={value.shape}, dtype={value.dtype}")
--------+        
--------+        # –ü–æ–ª—É—á–∞–µ–º logits –∏ labels
--------+        logits = batch['logits']
--------+        labels = batch['labels']
--------         
---------        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π CrossEntropy loss –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
---------        loss = F.cross_entropy(logits, labels)
--------+        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã
--------+        if logits.dim() == 1:
--------+            logits = logits.unsqueeze(0)
--------+        if labels.dim() == 0:
--------+            labels = labels.unsqueeze(0)
--------         
---------        return {"loss": loss}
--------+        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã
--------+        if hasattr(self, '_debug_forward') and self._debug_forward:
--------+            print(f"   üìä Logits: shape={logits.shape}, range=[{logits.min().item():.4f}, {logits.max().item():.4f}]")
--------+            print(f"   üìä Labels: shape={labels.shape}, unique={torch.unique(labels).tolist()}")
--------+        
--------+        # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ—Ç–µ—Ä—é
--------+        loss = self.criterion(logits, labels)
--------+        
--------+        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
--------+        if hasattr(self, '_debug_forward') and self._debug_forward:
--------+            print(f"   üíî Loss: {loss.item():.4f}")
--------+        
--------+        return {
--------+            'loss': loss
--------+        }
--------+
--------+    def set_debug_mode(self, debug_forward=False):
--------+        """
--------+        –í–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è forward pass.
--------+        
--------+        Args:
--------+            debug_forward (bool): –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å forward pass
--------+        """
--------+        self._debug_forward = debug_forward
--------+        if debug_forward:
--------+            print(f"üêõ –†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –≤–∫–ª—é—á–µ–Ω –¥–ª—è {self.__class__.__name__}")
--------+            print(f"   üíî Debug forward: {debug_forward}")
--------diff --git a/src/metrics/eer.py b/src/metrics/eer.py
--------index de45458..a9be4a6 100644
----------- a/src/metrics/eer.py
--------+++ b/src/metrics/eer.py
--------@@ -1,88 +1,138 @@
---------import numpy as np
-------- import torch
---------from abc import abstractmethod
---------
---------class BaseMetric:
---------    """
---------    Base class for all metrics
---------    """
--------+import numpy as np
--------+from typing import Dict, Any
-------- 
---------    def __init__(self, name=None, *args, **kwargs):
---------        self.name = name if name is not None else type(self).__name__
--------+from src.metrics.base_metric import BaseMetric
-------- 
---------    @abstractmethod
---------    def __call__(self, **batch):
---------        raise NotImplementedError()
-------- 
-------- class EERMetric(BaseMetric):
--------     """
---------    Equal Error Rate (EER) metric.
---------    –û–∂–∏–¥–∞–µ—Ç –≤ batch –¥–≤–∞ –ø–æ–ª—è:
---------        - 'logits': torch tensor —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏ logits
---------        - 'labels': torch tensor —Å –º–µ—Ç–∫–∞–º–∏ (1 ‚Äî bona fide, 0 ‚Äî spoof)
--------+    Equal Error Rate (EER) metric for audio anti-spoofing.
--------     """
-------- 
---------    def __init__(self, name="eer"):
---------        super().__init__(name=name)
---------
---------    def __call__(self, **batch):
---------    
---------        logits = batch["logits"]
---------        labels = batch["labels"]
---------
--------+    def __init__(self, **kwargs):
--------+        """
--------+        Args:
--------+            **kwargs: additional arguments
--------+        """
--------+        super(EERMetric, self).__init__()
--------+        
--------+        print("üìà –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è EERMetric...")
--------         
---------        if hasattr(logits, "detach"):
---------            logits = logits.detach().cpu().numpy()
---------        if hasattr(labels, "detach"):
---------            labels = labels.detach().cpu().numpy()
--------+        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
--------+        for key, value in kwargs.items():
--------+            print(f"   üìä {key}: {value}")
--------+        
--------+        self.name = "eer"
--------+        print("‚úÖ EERMetric –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
-------- 
--------+    def forward(self, **batch) -> float:
--------+        """
--------+        Compute EER metric.
--------         
---------        import torch.nn.functional as F
---------        if hasattr(logits, "detach"):
--------+        Args:
--------+            **batch: input batch containing scores and labels
--------             
---------            scores = F.softmax(logits, dim=-1)[:, 1]
---------        else:
---------            
---------            logits_tensor = torch.from_numpy(logits)
---------            scores_tensor = F.softmax(logits_tensor, dim=-1)
---------            scores = scores_tensor[:, 1].numpy()
---------
--------+        Returns:
--------+            float: EER value
--------+        """
--------+        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
--------+        if hasattr(self, '_debug_forward') and self._debug_forward:
--------+            print(f"   üìà EERMetric forward: –≤—Ö–æ–¥–Ω—ã–µ –∫–ª—é—á–∏ {list(batch.keys())}")
--------+            for key, value in batch.items():
--------+                if isinstance(value, torch.Tensor):
--------+                    print(f"      {key}: shape={value.shape}, dtype={value.dtype}")
--------         
---------        bona_scores = scores[labels == 1]
---------        spoof_scores = scores[labels == 0]
---------
---------        if len(bona_scores) == 0 or len(spoof_scores) == 0:
--------+        # –ü–æ–ª—É—á–∞–µ–º scores –∏ labels
--------+        if 'scores' in batch:
--------+            scores = batch['scores']
--------+        elif 'logits' in batch:
--------+            # –ï—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å logits, –±–µ—Ä–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—Ç–æ—Ä–æ–≥–æ –∫–ª–∞—Å—Å–∞ (spoof)
--------+            logits = batch['logits']
--------+            scores = torch.softmax(logits, dim=1)[:, 1]
--------+        else:
--------+            print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã scores –∏–ª–∏ logits –≤ –±–∞—Ç—á–µ")
--------             return 0.0
---------
---------        eer, _ = self.compute_eer(bona_scores, spoof_scores)
--------+        
--------+        labels = batch['labels']
--------+        
--------+        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã
--------+        if hasattr(self, '_debug_forward') and self._debug_forward:
--------+            print(f"   üìä Scores: shape={scores.shape}, range=[{scores.min().item():.4f}, {scores.max().item():.4f}]")
--------+            print(f"   üìä Labels: shape={labels.shape}, unique={torch.unique(labels).tolist()}")
--------+        
--------+        # –í—ã—á–∏—Å–ª—è–µ–º EER
--------+        eer = self._compute_eer(scores, labels)
--------+        
--------+        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
--------+        if hasattr(self, '_debug_forward') and self._debug_forward:
--------+            print(f"   üìà EER: {eer:.4f}")
--------+        
--------         return eer
-------- 
---------    @staticmethod
---------    def compute_det_curve(target_scores, nontarget_scores):
---------        n_scores = target_scores.size + nontarget_scores.size
---------        all_scores = np.concatenate((target_scores, nontarget_scores))
---------        labels = np.concatenate(
---------            (np.ones(target_scores.size), np.zeros(nontarget_scores.size)))
---------
---------        indices = np.argsort(all_scores, kind='mergesort')
---------        labels = labels[indices]
---------
---------        tar_trial_sums = np.cumsum(labels)
---------        nontarget_trial_sums = nontarget_scores.size - \
---------            (np.arange(1, n_scores + 1) - tar_trial_sums)
------+---                    metrics.update(met.name, met(**batch))
------+--+                    metric_value = met(**batch)
------+--+                    metrics.update(met.name, metric_value)
------+--                 except Exception as e:
------+---                    print(f"–û—à–∏–±–∫–∞ –≤ –º–µ—Ç—Ä–∏–∫–µ {met.name}: {e}")
------+--                     continue
------+--         return batch
------+-- 
------+--@@ -72,4 +72,13 @@ class Trainer(BaseTrainer):
------+--         Log data from batch. Calls self.writer.add_* to log data
------+--         to the experiment tracker.
------+--         """
------+---        pass
------+--\ No newline at end of file
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–∞—Ç—á–µ –¥–ª—è writer
------+--+        if self.writer is not None:
------+--+            # –õ–æ–≥–∏—Ä—É–µ–º learning rate
------+--+            if mode == "train" and self.lr_scheduler is not None:
------+--+                self.writer.add_scalar("learning_rate", self.lr_scheduler.get_last_lr()[0])
------+--+            
------+--+            # –õ–æ–≥–∏—Ä—É–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—É—é –Ω–æ—Ä–º—É
------+--+            if mode == "train":
------+--+                grad_norm = self._get_grad_norm()
------+--+                self.writer.add_scalar("grad_norm", grad_norm)
------+--\ No newline at end of file
------+--diff --git a/src/transforms/__init__.py b/src/transforms/__init__.py
------+--index bea0123..1c032b1 100644
------+----- a/src/transforms/__init__.py
------+--+++ b/src/transforms/__init__.py
------+--@@ -1,3 +1,3 @@
------+-- from src.transforms.normalize import Normalize
------+-- from src.transforms.scale import RandomScale1D
------+---from src.transforms.stft import AudioFrontend
------+--\ No newline at end of file
------+--+from src.transforms.stft import STFTTransform, MelSpectrogramTransform
------+--\ No newline at end of file
------+--diff --git a/src/transforms/stft.py b/src/transforms/stft.py
------+--index 954ff81..f7e362f 100644
------+----- a/src/transforms/stft.py
------+--+++ b/src/transforms/stft.py
------+--@@ -1,37 +1,177 @@
------+-- import torch
------+-- import torch.nn as nn
------+--+import torchaudio
------+--+from typing import Dict, Any
------+-- 
------+-- 
------+---def audio_frontend(waveform):
------+--+class STFTTransform(nn.Module):
------+--+    """
------+--+    Short-Time Fourier Transform (STFT) for audio processing.
------+--+    """
------+-- 
------+---    n_fft = 1024
------+---    hop_length = 256
------+---    win_length = 1024
------+--+    def __init__(self, n_fft=1024, hop_length=512, win_length=1024, **kwargs):
------+--+        """
------+--+        Args:
------+--+            n_fft (int): FFT window size
------+--+            hop_length (int): Number of samples between successive frames
------+--+            win_length (int): Window size
------+--+            **kwargs: additional arguments
------+--+        """
------+--+        super(STFTTransform, self).__init__()
------+--+        
------+--+        print("üéµ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è STFTTransform...")
------+--+        print(f"   üìä n_fft: {n_fft}")
------+--+        print(f"   üìä hop_length: {hop_length}")
------+--+        print(f"   üìä win_length: {win_length}")
------+--+        
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
------+--+        for key, value in kwargs.items():
------+--+            print(f"   üìä {key}: {value}")
------+--+        
------+--+        self.n_fft = n_fft
------+--+        self.hop_length = hop_length
------+--+        self.win_length = win_length
------+--+        
------+--+        print("‚úÖ STFTTransform –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
------+-- 
------+---    waveform = waveform.squeeze()
------+--+    def forward(self, audio: torch.Tensor) -> torch.Tensor:
------+--+        """
------+--+        Apply STFT to audio signal.
------+--+        
------+--+        Args:
------+--+            audio (torch.Tensor): input audio tensor
------+--+            
------+--+        Returns:
------+--+            torch.Tensor: STFT spectrogram
------+--+        """
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
------+--+            print(f"   üéµ STFTTransform forward: audio shape={audio.shape}")
------+--+            print(f"      Audio range: [{audio.min().item():.4f}, {audio.max().item():.4f}]")
------+--+            print(f"      Audio dtype: {audio.dtype}")
------+--+        
------+--+        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∞—É–¥–∏–æ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ñ–æ—Ä–º—É
------+--+        if audio.dim() == 1:
------+--+            audio = audio.unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
------+--+        elif audio.dim() == 3:
------+--+            audio = audio.squeeze(1)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–π –∫–∞–Ω–∞–ª
------+--+        
------+--+        # –ü—Ä–∏–º–µ–Ω—è–µ–º STFT
------+--+        stft_output = torch.stft(
------+--+            audio,
------+--+            n_fft=self.n_fft,
------+--+            hop_length=self.hop_length,
------+--+            win_length=self.win_length,
------+--+            return_complex=True,
------+--+            window=torch.hann_window(self.win_length).to(audio.device)
------+--+        )
------+--+        
------+--+        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É
------+--+        spectrogram = torch.abs(stft_output)
------+--+        
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
------+--+            print(f"   üìä STFT output shape: {stft_output.shape}")
------+--+            print(f"   üìä Spectrogram shape: {spectrogram.shape}")
------+--+            print(f"   üìä Spectrogram range: [{spectrogram.min().item():.4f}, {spectrogram.max().item():.4f}]")
------+--+        
------+--+        return spectrogram
------+-- 
------+---    stft = torch.stft(
------+---        waveform,
------+---        n_fft=n_fft,
------+---        hop_length=hop_length,
------+---        win_length=win_length,
------+---        window=torch.hann_window(win_length, device=waveform.device),
------+---        return_complex=True
------+---    )
------+--+    def set_debug_mode(self, debug_forward=False):
------+--+        """
------+--+        –í–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è forward pass.
------+--+        
------+--+        Args:
------+--+            debug_forward (bool): –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å forward pass
------+--+        """
------+--+        self._debug_forward = debug_forward
------+--+        if debug_forward:
------+--+            print(f"üêõ –†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –≤–∫–ª—é—á–µ–Ω –¥–ª—è {self.__class__.__name__}")
------+--+            print(f"   üéµ Debug forward: {debug_forward}")
------+-- 
------+---    magnitude = torch.abs(stft)
------+---    log_magnitude = torch.log(magnitude + 1e-8)
------+---    log_magnitude = log_magnitude.unsqueeze(0)
------+---    return log_magnitude
------+-- 
------+--+class MelSpectrogramTransform(nn.Module):
------+--+    """
------+--+    Mel Spectrogram transform for audio processing.
------+--+    """
------+-- 
------+---class AudioFrontend(nn.Module):
------+---    
------+---    def __init__(self):
------+---        super().__init__()
------+---    
------+---    def forward(self, waveform):
------+---      
------+--+    def __init__(self, sample_rate=16000, n_fft=1024, hop_length=512, n_mels=80, **kwargs):
------+--+        """
------+--+        Args:
------+--+            sample_rate (int): Audio sample rate
------+--+            n_fft (int): FFT window size
------+--+            hop_length (int): Number of samples between successive frames
------+--+            n_mels (int): Number of mel filter banks
------+--+            **kwargs: additional arguments
------+--+        """
------+--+        super(MelSpectrogramTransform, self).__init__()
------+--+        
------+--+        print("üéµ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MelSpectrogramTransform...")
------+--+        print(f"   üìä sample_rate: {sample_rate}")
------+--+        print(f"   üìä n_fft: {n_fft}")
------+--+        print(f"   üìä hop_length: {hop_length}")
------+--+        print(f"   üìä n_mels: {n_mels}")
------+--+        
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
------+--+        for key, value in kwargs.items():
------+--+            print(f"   üìä {key}: {value}")
------+--+        
------+--+        self.sample_rate = sample_rate
------+--+        self.n_fft = n_fft
------+--+        self.hop_length = hop_length
------+--+        self.n_mels = n_mels
------+--+        
------+--+        # –°–æ–∑–¥–∞–µ–º mel spectrogram transform
------+--+        self.mel_transform = torchaudio.transforms.MelSpectrogram(
------+--+            sample_rate=sample_rate,
------+--+            n_fft=n_fft,
------+--+            hop_length=hop_length,
------+--+            n_mels=n_mels,
------+--+            window_fn=torch.hann_window
------+--+        )
------+--+        
------+--+        print("‚úÖ MelSpectrogramTransform –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
------+-- 
------+--+    def forward(self, audio: torch.Tensor) -> torch.Tensor:
------+--+        """
------+--+        Apply Mel Spectrogram transform to audio signal.
------+--+        
------+--+        Args:
------+--+            audio (torch.Tensor): input audio tensor
------+--+            
------+--+        Returns:
------+--+            torch.Tensor: Mel spectrogram
------+--+        """
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
------+--+            print(f"   üéµ MelSpectrogramTransform forward: audio shape={audio.shape}")
------+--+            print(f"      Audio range: [{audio.min().item():.4f}, {audio.max().item():.4f}]")
------+--+            print(f"      Audio dtype: {audio.dtype}")
------+--+        
------+--+        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∞—É–¥–∏–æ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ñ–æ—Ä–º—É
------+--+        if audio.dim() == 1:
------+--+            audio = audio.unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
------+--+        elif audio.dim() == 3:
------+--+            audio = audio.squeeze(1)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–π –∫–∞–Ω–∞–ª
------+--+        
------+--+        # –ü—Ä–∏–º–µ–Ω—è–µ–º mel spectrogram transform
------+--+        mel_spectrogram = self.mel_transform(audio)
------+--+        
------+--+        # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
------+--+            print(f"   üìä Mel spectrogram shape: {mel_spectrogram.shape}")
------+--+            print(f"   üìä Mel spectrogram range: [{mel_spectrogram.min().item():.4f}, {mel_spectrogram.max().item():.4f}]")
------+--+        
------+--+        return mel_spectrogram
------+-- 
------+---        return audio_frontend(waveform)
------+--\ No newline at end of file
------+--+    def set_debug_mode(self, debug_forward=False):
------+--+        """
------+--+        –í–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è forward pass.
------+--+        
------+--+        Args:
------+--+            debug_forward (bool): –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å forward pass
------+--+        """
------+--+        self._debug_forward = debug_forward
------+--+        if debug_forward:
------+--+            print(f"üêõ –†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –≤–∫–ª—é—á–µ–Ω –¥–ª—è {self.__class__.__name__}")
------+--+            print(f"   üéµ Debug forward: {debug_forward}")
------+--\ No newline at end of file
------+--diff --git a/train.py b/train.py
------+--index 90a7a4f..ea54b46 100644
------+----- a/train.py
------+--+++ b/train.py
------+--@@ -26,6 +26,7 @@ def main(config):
------+-- 
------+--     project_config = OmegaConf.to_container(config)
------+--     logger = setup_saving_and_logging(config)
------+--+    
------+--     writer = instantiate(config.writer, logger, project_config)
------+-- 
------+--     if config.trainer.device == "auto":
------+--@@ -34,20 +35,26 @@ def main(config):
------+--         device = config.trainer.device
------+-- 
------+--     # setup data_loader instances
------+---    # batch_transforms should be put on device
------+--     dataloaders, batch_transforms = get_dataloaders(config, device)
------+-- 
------+--     # build model architecture, then print to console
------+--     model = instantiate(config.model).to(device)
------+--+    
------+--+    # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏
------+--+    total_params = sum(p.numel() for p in model.parameters())
------+--+    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
------+--+    
------+--     logger.info(model)
------+-- 
------+--     # get function handles of loss and metrics
------+--     loss_function = instantiate(config.loss_function).to(device)
------+--+    
------+--     metrics = instantiate(config.metrics)
------+-- 
------+--     # build optimizer, learning rate scheduler
------+--     trainable_params = filter(lambda p: p.requires_grad, model.parameters())
------+--     optimizer = instantiate(config.optimizer, params=trainable_params)
------+--+    
------+--     lr_scheduler = instantiate(config.lr_scheduler, optimizer=optimizer)
------+-- 
------+--     # epoch_len = number of iterations for iteration-based training
------+-diff --git a/src/metrics/tracker.py b/src/metrics/tracker.py
------+-index 79712bd..e9a1d72 100644
------+---- a/src/metrics/tracker.py
------+-+++ b/src/metrics/tracker.py
------+-@@ -50,24 +50,51 @@ class MetricTracker:
------+-         self._eer_labels.extend(labels.detach().cpu().numpy())
------+- 
------+-     def compute_eer(self):
------ --
---------        frr = np.concatenate(
---------            (np.atleast_1d(0), tar_trial_sums / target_scores.size))
---------        far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums /
---------                              nontarget_scores.size))
---------        thresholds = np.concatenate(
---------            (np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))
---------        return frr, far, thresholds
--------+    def _compute_eer(self, scores: torch.Tensor, labels: torch.Tensor) -> float:
------ -+        """
--------+        Compute Equal Error Rate.
--------+        
--------+        Args:
--------+            scores (torch.Tensor): prediction scores
--------+            labels (torch.Tensor): ground truth labels
--------+            
--------+        Returns:
--------+            float: EER value
------+-+        Compute Equal Error Rate from accumulated scores and labels.
------ -+        """
--------+        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy
--------+        scores_np = scores.detach().cpu().numpy()
--------+        labels_np = labels.detach().cpu().numpy()
--------+        
------+-         if not self._eer_scores:
------+-             return 0.0
------+-         
------+-         scores = np.array(self._eer_scores)
------+-         labels = np.array(self._eer_labels)
------+-         
------+--        bona_scores = scores[labels == 1]
------+--        spoof_scores = scores[labels == 0]
------ -+        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
--------+        thresholds = np.unique(scores_np)
--------+        
------+-+        thresholds = np.unique(scores)
------+-         
------+--        if len(bona_scores) == 0 or len(spoof_scores) == 0:
------+--            return 0.0
------ -+        # –í—ã—á–∏—Å–ª—è–µ–º FAR –∏ FRR –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ä–æ–≥–∞
------ -+        far_values = []
------ -+        frr_values = []
------ -+        
------ -+        for threshold in thresholds:
--------+            # FAR = FP / (FP + TN) = FP / (FP + TN)
--------+            # FRR = FN / (FN + TP) = FN / (FN + TP)
--------+            
------ -+            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: 1 –µ—Å–ª–∏ score >= threshold, –∏–Ω–∞—á–µ 0
--------+            predictions = (scores_np >= threshold).astype(int)
------+-+            predictions = (scores >= threshold).astype(int)
------ -+            
------ -+            # –í—ã—á–∏—Å–ª—è–µ–º confusion matrix
--------+            tp = np.sum((predictions == 1) & (labels_np == 1))
--------+            tn = np.sum((predictions == 0) & (labels_np == 0))
--------+            fp = np.sum((predictions == 1) & (labels_np == 0))
--------+            fn = np.sum((predictions == 0) & (labels_np == 1))
------+-+            tp = np.sum((predictions == 1) & (labels == 1))
------+-+            tn = np.sum((predictions == 0) & (labels == 0))
------+-+            fp = np.sum((predictions == 1) & (labels == 0))
------+-+            fn = np.sum((predictions == 0) & (labels == 1))
------ -+            
------ -+            # –í—ã—á–∏—Å–ª—è–µ–º FAR –∏ FRR
------ -+            far = fp / (fp + tn) if (fp + tn) > 0 else 0
------@@ -1044,1330 +2324,345 @@ index bbf7cb1..e69de29 100644
------ -+        
------ -+        # EER - —ç—Ç–æ —Å—Ä–µ–¥–Ω–µ–µ FAR –∏ FRR –≤ —ç—Ç–æ–π —Ç–æ—á–∫–µ
------ -+        eer = (far_values[min_idx] + frr_values[min_idx]) / 2
--------+        
--------+        return float(eer)
-------- 
---------    @classmethod
---------    def compute_eer(cls, bona_scores, spoof_scores):
---------        frr, far, thresholds = cls.compute_det_curve(bona_scores, spoof_scores)
---------        abs_diffs = np.abs(frr - far)
---------        min_index = np.argmin(abs_diffs)
---------        eer = np.mean((frr[min_index], far[min_index]))
---------        return eer, thresholds[min_index]
--------\ No newline at end of file
--------+    def set_debug_mode(self, debug_forward=False):
--------+        """
--------+        –í–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è forward pass.
--------+        
--------+        Args:
--------+            debug_forward (bool): –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å forward pass
--------+        """
--------+        self._debug_forward = debug_forward
--------+        if debug_forward:
--------+            print(f"üêõ –†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –≤–∫–ª—é—á–µ–Ω –¥–ª—è {self.__class__.__name__}")
--------+            print(f"   üìà Debug forward: {debug_forward}")
--------\ No newline at end of file
--------diff --git a/src/model/model.py b/src/model/model.py
--------index 28a4ce4..6ec39da 100644
----------- a/src/model/model.py
--------+++ b/src/model/model.py
--------@@ -1,153 +1,113 @@
-------- import torch
---------from torch import nn
--------+import torch.nn as nn
--------+from typing import Dict, Any
-------- 
---------class mfm_block(nn.Module):
---------    def __init__(self, channels):
---------        super().__init__()
---------        self.channels = channels
---------
---------    def forward(self, x):
---------        partition = self.channels // 2
---------        first_batch = x[:, :partition, ...]
---------        second_batch = x[:, partition:, ...]
---------        output = torch.maximum(first_batch, second_batch)
---------        return output
-------- 
-------- class LCNN(nn.Module):
---------    def __init__(self, in_channels=1, num_classes=2, dropout_p=0.3):
---------        super().__init__()
---------
---------        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=5, stride=1, padding=2)
---------        self.mfm2 = mfm_block(64)
---------        self.dropout2 = nn.Dropout2d(dropout_p)
---------        self.MaxPool3 = nn.MaxPool2d(kernel_size=2, stride=2)
---------
---------        self.conv4 = nn.Conv2d(32, 64, kernel_size=1, stride=1)
---------        self.mfm5 = mfm_block(64)
---------        self.dropout5 = nn.Dropout2d(dropout_p)
---------        self.BatchNorm6 = nn.BatchNorm2d(32)
---------
---------        self.conv7 = nn.Conv2d(32, 96, kernel_size=3, stride=1, padding=1)
---------        self.mfm8 = mfm_block(96)
---------        self.dropout8 = nn.Dropout2d(dropout_p)
---------
---------        self.MaxPool9 = nn.MaxPool2d(kernel_size=2, stride=2)
---------        self.BatchNorm10 = nn.BatchNorm2d(48)
---------
---------        self.conv11 = nn.Conv2d(48, 96, kernel_size=1, stride=1)
---------        self.mfm12 = mfm_block(96)
---------        self.dropout12 = nn.Dropout2d(dropout_p)
---------        self.BatchNorm13 = nn.BatchNorm2d(48)
---------
---------        self.conv14 = nn.Conv2d(48, 128, kernel_size=3, stride=1, padding=1)
---------        self.mfm15 = mfm_block(128)
---------        self.dropout15 = nn.Dropout2d(dropout_p)
---------
---------        self.MaxPool16 = nn.MaxPool2d(kernel_size=2, stride=2)
---------
---------        self.conv17 = nn.Conv2d(64, 128, kernel_size=1, stride=1)
---------        self.mfm18 = mfm_block(128)
---------        self.dropout18 = nn.Dropout2d(dropout_p)
---------        self.BatchNorm19 = nn.BatchNorm2d(64)
---------
---------        self.conv20 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
---------        self.mfm21 = mfm_block(64)
---------        self.dropout21 = nn.Dropout2d(dropout_p)
---------        self.BatchNorm22 = nn.BatchNorm2d(32)
---------
---------        self.conv23 = nn.Conv2d(32, 64, kernel_size=1, stride=1)
---------        self.mfm24 = mfm_block(64)
---------        self.dropout24 = nn.Dropout2d(dropout_p)
---------        self.BatchNorm25 = nn.BatchNorm2d(32)
---------
---------        self.conv26 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
---------        self.mfm27 = mfm_block(64)
---------        self.dropout27 = nn.Dropout2d(dropout_p)
---------
---------        self.MaxPool28 = nn.MaxPool2d(kernel_size=2, stride=2)
---------
---------        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
---------        self.fc29 = nn.Linear(32, 160)
---------        self.dropout29 = nn.Dropout(dropout_p)
---------        self.mfm30 = mfm_block(160)
---------        self.BatchNorm31 = nn.BatchNorm1d(80)
---------        self.fc32 = nn.Linear(80, num_classes)
--------+    """
--------+    Light CNN model for audio anti-spoofing.
--------+    """
--------+
--------+    def __init__(self, num_classes=2, **kwargs):
--------+        """
--------+        Args:
--------+            num_classes (int): number of output classes
--------+            **kwargs: additional arguments
--------+        """
--------+        super(LCNN, self).__init__()
------ -         
---------        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
---------        self._initialize_weights()
---------
---------    def _initialize_weights(self):
---------        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
---------        for m in self.modules():
---------            if isinstance(m, nn.Conv2d):
---------                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
---------                if m.bias is not None:
---------                    nn.init.constant_(m.bias, 0)
---------            elif isinstance(m, nn.BatchNorm2d):
---------                nn.init.constant_(m.weight, 1)
---------                nn.init.constant_(m.bias, 0)
---------            elif isinstance(m, nn.Linear):
---------                nn.init.normal_(m.weight, 0, 0.01)
---------                nn.init.constant_(m.bias, 0)
---------
---------    def forward(self, data_object, **kwargs):
---------        x = data_object
---------        x = self.conv1(x)
---------        x = self.mfm2(x)
---------        x = self.dropout2(x)
---------        x = self.MaxPool3(x)
---------
---------        x = self.conv4(x)
---------        x = self.mfm5(x)
---------        x = self.dropout5(x)
---------        x = self.BatchNorm6(x)
---------
---------        x = self.conv7(x)
---------        x = self.mfm8(x)
---------        x = self.dropout8(x)
---------
---------        x = self.MaxPool9(x)
---------        x = self.BatchNorm10(x)
---------
---------        x = self.conv11(x)
---------        x = self.mfm12(x)
---------        x = self.dropout12(x)
---------        x = self.BatchNorm13(x)
---------
---------        x = self.conv14(x)
---------        x = self.mfm15(x)
---------        x = self.dropout15(x)
---------
---------        x = self.MaxPool16(x)
---------
---------        x = self.conv17(x)
---------        x = self.mfm18(x)
---------        x = self.dropout18(x)
---------        x = self.BatchNorm19(x)
---------
---------        x = self.conv20(x)
---------        x = self.mfm21(x)
---------        x = self.dropout21(x)
---------        x = self.BatchNorm22(x)
---------
---------        x = self.conv23(x)
---------        x = self.mfm24(x)
---------        x = self.dropout24(x)
---------        x = self.BatchNorm25(x)
---------
---------        x = self.conv26(x)
---------        x = self.mfm27(x)
---------        x = self.dropout27(x)
--------+        self.num_classes = num_classes
--------+        
--------+        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
--------+        self.features = nn.Sequential(
--------+            # –ü–µ—Ä–≤—ã–π –±–ª–æ–∫
--------+            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),
--------+            nn.BatchNorm2d(64),
--------+            nn.ReLU(inplace=True),
--------+            nn.MaxPool2d(kernel_size=2, stride=2),
--------+            
--------+            # –í—Ç–æ—Ä–æ–π –±–ª–æ–∫
--------+            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
--------+            nn.BatchNorm2d(128),
--------+            nn.ReLU(inplace=True),
--------+            nn.MaxPool2d(kernel_size=2, stride=2),
--------+            
--------+            # –¢—Ä–µ—Ç–∏–π –±–ª–æ–∫
--------+            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
--------+            nn.BatchNorm2d(256),
--------+            nn.ReLU(inplace=True),
--------+            nn.MaxPool2d(kernel_size=2, stride=2),
--------+            
--------+            # –ß–µ—Ç–≤–µ—Ä—Ç—ã–π –±–ª–æ–∫
--------+            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
--------+            nn.BatchNorm2d(512),
--------+            nn.ReLU(inplace=True),
--------+            nn.MaxPool2d(kernel_size=2, stride=2),
--------+        )
--------+        
--------+        # Global Average Pooling
--------+        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))
--------+        
--------+        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
--------+        self.classifier = nn.Sequential(
--------+            nn.Dropout(0.5),
--------+            nn.Linear(512, 256),
--------+            nn.ReLU(inplace=True),
--------+            nn.Dropout(0.5),
--------+            nn.Linear(256, num_classes)
--------+        )
--------+
--------+    def forward(self, **batch) -> Dict[str, torch.Tensor]:
--------+        """
--------+        Forward pass of the model.
--------+        
--------+        Args:
--------+            **batch: input batch containing tensors
--------+            
--------+        Returns:
--------+            Dict[str, torch.Tensor]: model outputs
--------+        """
--------+        # –ü–æ–ª—É—á–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
--------+        if 'spectrogram' in batch:
--------+            x = batch['spectrogram']
--------+        elif 'data_object' in batch:
--------+            x = batch['data_object']
--------+        else:
--------+            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ç–µ–Ω–∑–æ—Ä –∏–∑ –±–∞—Ç—á–∞
--------+            x = next(iter(batch.values()))
--------+        
--------+        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ñ–æ—Ä–º—É
--------+        if x.dim() == 3:
--------+            x = x.unsqueeze(1)  # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–∞–ª
--------+        elif x.dim() == 2:
--------+            x = x.unsqueeze(0).unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º batch –∏ –∫–∞–Ω–∞–ª
--------+        
--------+        # –ü—Ä–æ—Ö–æ–¥–∏–º —á–µ—Ä–µ–∑ —Å–ª–æ–∏
--------+        x = self.features(x)
--------+        
--------+        x = self.global_avg_pool(x)
--------+        x = x.view(x.size(0), -1)
--------+        
--------+        x = self.classifier(x)
--------+        
--------+        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—ã—Ö–æ–¥—ã
--------+        outputs = {
--------+            'logits': x
--------+        }
--------+        
--------+        return outputs
-------- 
---------        x = self.MaxPool28(x)
------+--        # –í—ã—á–∏—Å–ª—è–µ–º EER
------+--        from src.metrics.eer import EERMetric
------+--        eer_metric = EERMetric()
------+--        eer, _ = eer_metric.compute_eer(bona_scores, spoof_scores)
------+--        return eer
------+-+        return float(eer)
------ - 
---------        x = self.adaptive_pool(x)
---------        x = x.view(x.size(0), -1)
---------        x = self.fc29(x)
---------        x = self.dropout29(x)
---------        x = x.unsqueeze(-1).unsqueeze(-1)
---------        x = self.mfm30(x)
---------        x = x.squeeze(-1).squeeze(-1)
---------        x = self.BatchNorm31(x)
---------        logits = self.fc32(x)
---------        return {"logits": logits}
--------\ No newline at end of file
--------+# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å hydra
--------+def create_model(**kwargs) -> LCNN:
--------+    """
--------+    –°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ LCNN.
--------+    
--------+    Args:
--------+        **kwargs: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
--------+        
--------+    Returns:
--------+        LCNN: —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏
--------+    """
--------+    model = LCNN(**kwargs)
--------+    return model
--------\ No newline at end of file
------+-     def avg(self, key):
------+-         """
------ -diff --git a/src/trainer/base_trainer.py b/src/trainer/base_trainer.py
--------index e35ffba..0d4e7a1 100644
------+-index 0d4e7a1..9f6663a 100644
------ ---- a/src/trainer/base_trainer.py
------ -+++ b/src/trainer/base_trainer.py
--------@@ -148,250 +148,224 @@ class BaseTrainer:
--------         """
--------         try:
--------             self._train_process()
---------        except KeyboardInterrupt as e:
---------            self.logger.info("Saving model on keyboard interrupt")
---------            self._save_checkpoint(self._last_epoch, save_best=False)
---------            raise e
--------+        except KeyboardInterrupt:
--------+            self._save_checkpoint(self._last_epoch, save_best=False, only_best=True)
--------+            raise
--------+        except Exception as e:
--------+            raise
-------- 
--------     def _train_process(self):
--------         """
---------        Full training logic:
---------
---------        Training model for an epoch, evaluating it on non-train partitions,
---------        and monitoring the performance improvement (for early stopping
---------        and saving the best checkpoint).
--------+        Full training logic.
--------         """
--------         not_improved_count = 0
--------         for epoch in range(self.start_epoch, self.epochs + 1):
--------             self._last_epoch = epoch
---------            result = self._train_epoch(epoch)
---------
---------            # save logged information into logs dict
---------            logs = {"epoch": epoch}
---------            logs.update(result)
--------+            self._train_epoch(epoch)
-------- 
---------            # print logged information to the screen
---------            for key, value in logs.items():
---------                self.logger.info(f"    {key:15s}: {value}")
--------+            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞ val, test –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
--------+            if "val" in self.evaluation_dataloaders:
--------+                val_logs = {}
--------+                dataloader = self.evaluation_dataloaders["val"]
--------+                val_part_logs = self._evaluation_epoch(epoch, "val", dataloader)
--------+                val_logs.update(val_part_logs)
-------- 
---------            # evaluate model performance according to configured metric,
---------            # save best checkpoint as model_best
---------            best, stop_process, not_improved_count = self._monitor_performance(
---------                logs, not_improved_count
---------            )
--------+                # log best so far
--------+                if self.mnt_mode != "off":
--------+                    improved = self._monitor_performance(val_logs, not_improved_count)
--------+                    if improved:
--------+                        not_improved_count = 0
--------+                    else:
--------+                        not_improved_count += 1
-------- 
---------            if epoch % self.save_period == 0 or best:
---------                self._save_checkpoint(epoch, save_best=best, only_best=True)
--------+                if self.mnt_mode != "off" and not_improved_count > self.early_stop:
--------+                    break
-------- 
---------            if stop_process:  # early_stop
---------                break
--------+            if epoch % self.save_period == 0:
--------+                self._save_checkpoint(epoch, save_best=False)
-------- 
--------     def _train_epoch(self, epoch):
--------         """
---------        Training logic for an epoch, including logging and evaluation on
---------        non-train partitions.
--------+        Training logic for an epoch.
-------- 
--------         Args:
---------            epoch (int): current training epoch.
---------        Returns:
---------            logs (dict): logs that contain the average loss and metric in
---------                this epoch.
--------+            epoch (int): Current epoch number.
--------         """
---------        self.is_train = True
------+-@@ -194,6 +194,10 @@ class BaseTrainer:
------ -         self.model.train()
------ -         self.train_metrics.reset()
---------        self.writer.set_step((epoch - 1) * self.epoch_len)
---------        self.writer.add_scalar("epoch", epoch)
---------        for batch_idx, batch in enumerate(
---------            tqdm(self.train_dataloader, desc="train", total=self.epoch_len)
---------        ):
------+-         
------+-+        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–µ—Ä–µ–¥–∏–Ω—ã —ç–ø–æ—Ö–∏
------+-+        total_batches = len(self.train_dataloader)
------+-+        mid_epoch_batch = total_batches // 2
------ -+        
--------+        pbar = tqdm(self.train_dataloader, desc=f"Train Epoch {epoch}")
--------+        for batch_idx, batch in enumerate(pbar):
------+-         pbar = tqdm(self.train_dataloader, desc=f"Train Epoch {epoch}")
------+-         for batch_idx, batch in enumerate(pbar):
------ -             try:
---------                batch = self.process_batch(
---------                    batch,
---------                    metrics=self.train_metrics,
---------                )
---------            except torch.cuda.OutOfMemoryError as e:
---------                if self.skip_oom:
---------                    self.logger.warning("OOM on batch. Skipping batch.")
---------                    torch.cuda.empty_cache()  # free some memory
--------+                batch = self.process_batch(batch, self.train_metrics)
--------+                self._log_batch(batch_idx, batch, "train")
--------+                
--------+                # –í—ã–≤–æ–¥–∏–º –ª–æ—Å—Å –≤ –∫–æ–Ω—Å–æ–ª—å –∫–∞–∂–¥—ã–µ 50 –±–∞—Ç—á–µ–π
--------+                if batch_idx % 50 == 0:
--------+                    loss_key = self.config.writer.loss_names[0]
--------+                    current_loss = self.train_metrics.avg(loss_key)
--------+                    print(f"[Batch {batch_idx}] Loss: {current_loss:.6f}")
--------+                
--------+                # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏
--------+                if batch_idx == len(self.train_dataloader) // 2 and "val" in self.evaluation_dataloaders:
--------+                    self._quick_validation(epoch, "val", self.evaluation_dataloaders["val"])
--------+                    
--------+            except RuntimeError as e:
--------+                if "out of memory" in str(e) and self.skip_oom:
--------+                    if hasattr(torch.cuda, 'empty_cache'):
--------+                        torch.cuda.empty_cache()
--------                     continue
--------                 else:
--------                     raise e
--------+                    
--------+        self._log_scalars(self.train_metrics)
--------+
--------+    def _quick_validation(self, epoch, part, dataloader):
--------+        """
--------+        –ë—ã—Å—Ç—Ä–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è EER –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏.
-------- 
---------            self.train_metrics.update("grad_norm", self._get_grad_norm())
---------
---------            # log current results
---------            if batch_idx % self.log_step == 0:
---------                self.writer.set_step((epoch - 1) * self.epoch_len + batch_idx)
---------                self.logger.debug(
---------                    "Train Epoch: {} {} Loss: {:.6f}".format(
---------                        epoch, self._progress(batch_idx), batch["loss"].item()
---------                    )
---------                )
---------                self.writer.add_scalar(
---------                    "learning rate", self.lr_scheduler.get_last_lr()[0]
---------                )
---------                self._log_scalars(self.train_metrics)
---------                self._log_batch(batch_idx, batch)
---------                # we don't want to reset train metrics at the start of every epoch
---------                # because we are interested in recent train metrics
---------                last_train_metrics = self.train_metrics.result()
---------                self.train_metrics.reset()
---------            if batch_idx + 1 >= self.epoch_len:
---------                break
---------
---------        logs = last_train_metrics
---------
---------        # Run val/test
---------        for part, dataloader in self.evaluation_dataloaders.items():
---------            val_logs = self._evaluation_epoch(epoch, part, dataloader)
---------            logs.update(**{f"{part}_{name}": value for name, value in val_logs.items()})
---------
---------        return logs
--------+        Args:
--------+            epoch (int): Current epoch number.
--------+            part (str): Name of the data part.
--------+            dataloader (DataLoader): Dataloader for validation.
--------+        """
--------+        self.model.eval()
--------+        temp_metrics = MetricTracker(
--------+            *self.config.writer.loss_names,
--------+            *[m.name for m in self.metrics["inference"]],
--------+            writer=None,  # –ù–µ –ª–æ–≥–∏—Ä—É–µ–º –≤ writer –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
--------+        )
--------+        
--------+        with torch.no_grad():
--------+            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –±–∞—Ç—á–µ–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ—Ü–µ–Ω–∫–∏
--------+            num_batches = min(10, len(dataloader))  # –ú–∞–∫—Å–∏–º—É–º 10 –±–∞—Ç—á–µ–π
--------+            for batch_idx, batch in enumerate(dataloader):
--------+                if batch_idx >= num_batches:
--------+                    break
------+-@@ -206,9 +210,18 @@ class BaseTrainer:
------+-                     current_loss = self.train_metrics.avg(loss_key)
------+-                     print(f"[Batch {batch_idx}] Loss: {current_loss:.6f}")
------+-                 
------+--                # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏
------+--                if batch_idx == len(self.train_dataloader) // 2 and "val" in self.evaluation_dataloaders:
------+--                    self._quick_validation(epoch, "val", self.evaluation_dataloaders["val"])
------+-+                # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏ (–µ—Å–ª–∏ val_period = 1)
------+-+                if batch_idx == mid_epoch_batch and "val" in self.evaluation_dataloaders:
------+-+                    print(f"\n--- –í–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏ {epoch} ---")
------+-+                    val_logs = {}
------+-+                    dataloader = self.evaluation_dataloaders["val"]
------+-+                    val_part_logs = self._evaluation_epoch(epoch, "val", dataloader)
------+-+                    val_logs.update(val_part_logs)
------ -+                    
--------+                try:
--------+                    batch = self.process_batch(batch, temp_metrics)
--------+                except RuntimeError as e:
--------+                    if "out of memory" in str(e) and self.skip_oom:
--------+                        if hasattr(torch.cuda, 'empty_cache'):
--------+                            torch.cuda.empty_cache()
--------+                        continue
--------+                    else:
--------+                        raise e
-------- 
--------     def _evaluation_epoch(self, epoch, part, dataloader):
--------         """
---------        Evaluate model on the partition after training for an epoch.
--------+        Validate after training an epoch.
-------- 
--------         Args:
---------            epoch (int): current training epoch.
---------            part (str): partition to evaluate on
---------            dataloader (DataLoader): dataloader for the partition.
--------+            epoch (int): Current epoch number.
--------+            part (str): Name of the data part.
--------+            dataloader (DataLoader): Dataloader for validation.
--------+
--------         Returns:
---------            logs (dict): logs that contain the information about evaluation.
--------+            dict: Dictionary with validation logs.
--------         """
---------        self.is_train = False
--------         self.model.eval()
--------         self.evaluation_metrics.reset()
--------+        
--------         with torch.no_grad():
---------            for batch_idx, batch in tqdm(
---------                enumerate(dataloader),
---------                desc=part,
---------                total=len(dataloader),
---------            ):
---------                batch = self.process_batch(
---------                    batch,
---------                    metrics=self.evaluation_metrics,
---------                )
---------            self.writer.set_step(epoch * self.epoch_len, part)
---------            self._log_scalars(self.evaluation_metrics)
---------            self._log_batch(
---------                batch_idx, batch, part
---------            )  # log only the last batch during inference
---------
--------+            pbar = tqdm(dataloader, desc=f"Validation {part} Epoch {epoch}")
--------+            for batch_idx, batch in enumerate(pbar):
--------+                try:
--------+                    batch = self.process_batch(batch, self.evaluation_metrics)
--------+                    self._log_batch(batch_idx, batch, part)
--------+                        
--------+                except RuntimeError as e:
--------+                    if "out of memory" in str(e) and self.skip_oom:
--------+                        if hasattr(torch.cuda, 'empty_cache'):
--------+                            torch.cuda.empty_cache()
--------+                        continue
--------+                    else:
--------+                        raise e
--------+
--------+        self._log_scalars(self.evaluation_metrics)
--------         return self.evaluation_metrics.result()
-------- 
--------     def _monitor_performance(self, logs, not_improved_count):
--------         """
---------        Check if there is an improvement in the metrics. Used for early
---------        stopping and saving the best checkpoint.
--------+        Monitor the performance and save the best model.
-------- 
--------         Args:
---------            logs (dict): logs after training and evaluating the model for
---------                an epoch.
---------            not_improved_count (int): the current number of epochs without
---------                improvement.
--------+            logs (dict): Dictionary with validation logs.
--------+            not_improved_count (int): Number of epochs without improvement.
--------+
--------         Returns:
---------            best (bool): if True, the monitored metric has improved.
---------            stop_process (bool): if True, stop the process (early stopping).
---------                The metric did not improve for too much epochs.
---------            not_improved_count (int): updated number of epochs without
---------                improvement.
------+-+                    # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –∫–æ–Ω—Å–æ–ª—å
------+-+                    for metric_name, metric_value in val_logs.items():
------+-+                        print(f"    {metric_name}: {metric_value:.6f}")
------+-+                    print("--- –ö–æ–Ω–µ—Ü –≤–∞–ª–∏–¥–∞—Ü–∏–∏ ---\n")
------+-                     
------+-             except RuntimeError as e:
------+-                 if "out of memory" in str(e) and self.skip_oom:
------+-@@ -220,39 +233,6 @@ class BaseTrainer:
------+-                     
------+-         self._log_scalars(self.train_metrics)
------+- 
------+--    def _quick_validation(self, epoch, part, dataloader):
------ --        """
---------        best = False
---------        stop_process = False
---------        if self.mnt_mode != "off":
---------            try:
---------                # check whether model performance improved or not,
---------                # according to specified metric(mnt_metric)
---------                if self.mnt_mode == "min":
---------                    improved = logs[self.mnt_metric] <= self.mnt_best
---------                elif self.mnt_mode == "max":
---------                    improved = logs[self.mnt_metric] >= self.mnt_best
---------                else:
---------                    improved = False
---------            except KeyError:
---------                self.logger.warning(
---------                    f"Warning: Metric '{self.mnt_metric}' is not found. "
---------                    "Model performance monitoring is disabled."
---------                )
---------                self.mnt_mode = "off"
---------                improved = False
---------
---------            if improved:
---------                self.mnt_best = logs[self.mnt_metric]
---------                not_improved_count = 0
---------                best = True
---------            else:
---------                not_improved_count += 1
------+--        –ë—ã—Å—Ç—Ä–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è EER –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏.
------ --
---------            if not_improved_count >= self.early_stop:
---------                self.logger.info(
---------                    "Validation performance didn't improve for {} epochs. "
---------                    "Training stops.".format(self.early_stop)
---------                )
---------                stop_process = True
---------        return best, stop_process, not_improved_count
--------+            bool: True if the model improved.
--------+        """
--------+        if self.mnt_mode == "off":
--------+            return False
--------+
--------+        try:
--------+            current = logs[self.mnt_metric]
--------+        except KeyError:
--------+            return False
--------+
--------+        if self.mnt_mode == "min":
--------+            improved = current < self.mnt_best
--------+        else:
--------+            improved = current > self.mnt_best
--------+
--------+        if improved:
--------+            self.mnt_best = current
--------+            self._save_checkpoint(self._last_epoch, save_best=True)
--------+
--------+        return improved
-------- 
--------     def move_batch_to_device(self, batch):
--------         """
---------        Move all necessary tensors to the device.
--------+        Move batch to device.
-------- 
--------         Args:
---------            batch (dict): dict-based batch containing the data from
---------                the dataloader.
--------+            batch (dict): Batch to move to device.
--------+
--------         Returns:
---------            batch (dict): dict-based batch containing the data from
---------                the dataloader with some of the tensors on the device.
--------+            dict: Batch on device.
--------         """
---------        for tensor_for_device in self.cfg_trainer.device_tensors:
---------            batch[tensor_for_device] = batch[tensor_for_device].to(self.device)
--------+        for k, v in batch.items():
--------+            if isinstance(v, torch.Tensor):
--------+                batch[k] = v.to(self.device)
--------         return batch
-------- 
--------     def transform_batch(self, batch):
--------         """
---------        Transforms elements in batch. Like instance transform inside the
---------        BaseDataset class, but for the whole batch. Improves pipeline speed,
---------        especially if used with a GPU.
---------
---------        Each tensor in a batch undergoes its own transform defined by the key.
--------+        Transform batch using batch transforms.
-------- 
--------         Args:
---------            batch (dict): dict-based batch containing the data from
---------                the dataloader.
--------+            batch (dict): Batch to transform.
--------+
--------         Returns:
---------            batch (dict): dict-based batch containing the data from
---------                the dataloader (possibly transformed via batch transform).
------+--        Args:
------+--            epoch (int): Current epoch number.
------+--            part (str): Name of the data part.
------+--            dataloader (DataLoader): Dataloader for validation.
------ --        """
---------        # do batch transforms on device
---------        transform_type = "train" if self.is_train else "inference"
---------        transforms = self.batch_transforms.get(transform_type)
---------        if transforms is not None:
---------            for transform_name in transforms.keys():
---------                batch[transform_name] = transforms[transform_name](
---------                    batch[transform_name]
---------                )
--------+            dict: Transformed batch.
--------+        """
--------+        if self.batch_transforms is not None:
--------+            for transform_name, transform in self.batch_transforms.items():
--------+                if transform_name in batch:
--------+                    batch[transform_name] = transform(batch[transform_name])
--------         return batch
-------- 
--------     def _clip_grad_norm(self):
--------         """
---------        Clips the gradient norm by the value defined in
---------        config.trainer.max_grad_norm
--------+        Clip gradient norm.
--------         """
---------        if self.config["trainer"].get("max_grad_norm", None) is not None:
--------+        if self.cfg_trainer.get("grad_clip_norm") is not None:
--------             clip_grad_norm_(
---------                self.model.parameters(), self.config["trainer"]["max_grad_norm"]
--------+                self.model.parameters(), self.cfg_trainer.grad_clip_norm
--------             )
-------- 
--------     @torch.no_grad()
--------     def _get_grad_norm(self, norm_type=2):
--------         """
---------        Calculates the gradient norm for logging.
--------+        Get gradient norm.
-------- 
--------         Args:
---------            norm_type (float | str | None): the order of the norm.
--------+            norm_type (int): Type of norm.
--------+
--------         Returns:
---------            total_norm (float): the calculated norm.
--------+            float: Gradient norm.
--------         """
--------         parameters = self.model.parameters()
--------         if isinstance(parameters, torch.Tensor):
--------@@ -401,17 +375,14 @@ class BaseTrainer:
--------             torch.stack([torch.norm(p.grad.detach(), norm_type) for p in parameters]),
--------             norm_type,
--------         )
---------        return total_norm.item()
--------+        return total_norm
-------- 
--------     def _progress(self, batch_idx):
--------         """
---------        Calculates the percentage of processed batch within the epoch.
--------+        Print progress.
-------- 
--------         Args:
---------            batch_idx (int): the current batch index.
---------        Returns:
---------            progress (str): contains current step and percentage
---------                within the epoch.
--------+            batch_idx (int): Current batch index.
--------         """
--------         base = "[{}/{} ({:.0f}%)]"
--------         if hasattr(self.train_dataloader, "n_samples"):
--------@@ -425,129 +396,106 @@ class BaseTrainer:
--------     @abstractmethod
--------     def _log_batch(self, batch_idx, batch, mode="train"):
--------         """
---------        Abstract method. Should be defined in the nested Trainer Class.
---------
--------         Log data from batch. Calls self.writer.add_* to log data
--------         to the experiment tracker.
-------- 
--------         Args:
---------            batch_idx (int): index of the current batch.
---------            batch (dict): dict-based batch after going through
---------                the 'process_batch' function.
---------            mode (str): train or inference. Defines which logging
---------                rules to apply.
--------+            batch_idx (int): Current batch index.
--------+            batch (dict): Batch data.
--------+            mode (str): Mode (train or validation).
--------         """
---------        return NotImplementedError()
--------+        pass
-------- 
--------     def _log_scalars(self, metric_tracker: MetricTracker):
--------         """
---------        Wrapper around the writer 'add_scalar' to log all metrics.
--------+        Log scalars to the experiment tracker.
-------- 
--------         Args:
---------            metric_tracker (MetricTracker): calculated metrics.
--------+            metric_tracker (MetricTracker): Metric tracker.
--------         """
---------        if self.writer is None:
---------            return
---------        for metric_name in metric_tracker.keys():
---------            self.writer.add_scalar(f"{metric_name}", metric_tracker.avg(metric_name))
--------+        for metric_name, metric_value in metric_tracker.result().items():
--------+            self.writer.add_scalar(metric_name, metric_value)
-------- 
--------     def _save_checkpoint(self, epoch, save_best=False, only_best=False):
--------         """
---------        Save the checkpoints.
--------+        Save checkpoint.
-------- 
--------         Args:
---------            epoch (int): current epoch number.
---------            save_best (bool): if True, rename the saved checkpoint to 'model_best.pth'.
---------            only_best (bool): if True and the checkpoint is the best, save it only as
---------                'model_best.pth'(do not duplicate the checkpoint as
---------                checkpoint-epochEpochNumber.pth)
--------+            epoch (int): Current epoch number.
--------+            save_best (bool): Whether to save the best model.
--------+            only_best (bool): Whether to save only the best model.
--------         """
--------         arch = type(self.model).__name__
--------+
--------         state = {
--------             "arch": arch,
--------             "epoch": epoch,
--------             "state_dict": self.model.state_dict(),
--------             "optimizer": self.optimizer.state_dict(),
---------            "lr_scheduler": self.lr_scheduler.state_dict(),
--------             "monitor_best": self.mnt_best,
--------             "config": self.config,
--------         }
---------        filename = str(self.checkpoint_dir / f"checkpoint-epoch{epoch}.pth")
---------        if not (only_best and save_best):
---------            torch.save(state, filename)
---------            if self.config.writer.log_checkpoints:
---------                self.writer.add_checkpoint(filename, str(self.checkpoint_dir.parent))
---------            self.logger.info(f"Saving checkpoint: {filename} ...")
--------+
--------+        if self.lr_scheduler is not None:
--------+            state["lr_scheduler"] = self.lr_scheduler.state_dict()
--------+
--------+        filename = str(self.checkpoint_dir / "checkpoint-epoch{}.pth".format(epoch))
--------+        if not (self.checkpoint_dir).exists():
--------+            self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
--------+
--------         if save_best:
--------             best_path = str(self.checkpoint_dir / "model_best.pth")
--------             torch.save(state, best_path)
---------            if self.config.writer.log_checkpoints:
---------                self.writer.add_checkpoint(best_path, str(self.checkpoint_dir.parent))
---------            self.logger.info("Saving current best: model_best.pth ...")
--------+            del state["optimizer"], state["lr_scheduler"], state["config"]
--------+            torch.save(state, best_path + ".tmp")
--------+            import os
--------+            os.replace(best_path + ".tmp", best_path)
--------+        elif not only_best:
--------+            torch.save(state, filename)
--------+            del state["optimizer"], state["lr_scheduler"], state["config"]
--------+            torch.save(state, filename + ".tmp")
--------+            import os
--------+            os.replace(filename + ".tmp", filename)
-------- 
--------     def _resume_checkpoint(self, resume_path):
--------         """
---------        Resume from a saved checkpoint (in case of server crash, etc.).
---------        The function loads state dicts for everything, including model,
---------        optimizers, etc.
---------
---------        Notice that the checkpoint should be located in the current experiment
---------        saved directory (where all checkpoints are saved in '_save_checkpoint').
--------+        Resume from saved checkpoint.
-------- 
--------         Args:
---------            resume_path (str): Path to the checkpoint to be resumed.
--------+            resume_path (str): Path to checkpoint.
--------         """
--------         resume_path = str(resume_path)
---------        self.logger.info(f"Loading checkpoint: {resume_path} ...")
---------        checkpoint = torch.load(resume_path, self.device)
--------+        checkpoint = torch.load(resume_path, map_location=self.device)
--------         self.start_epoch = checkpoint["epoch"] + 1
--------         self.mnt_best = checkpoint["monitor_best"]
-------- 
--------         # load architecture params from checkpoint.
--------         if checkpoint["config"]["model"] != self.config["model"]:
--------             self.logger.warning(
---------                "Warning: Architecture configuration given in the config file is different from that "
---------                "of the checkpoint. This may yield an exception when state_dict is loaded."
--------+                "Warning: Architecture configuration given in config file is different from that of checkpoint. "
--------+                "This may create an exception while state_dict is being loaded."
--------             )
--------         self.model.load_state_dict(checkpoint["state_dict"])
-------- 
--------         # load optimizer state from checkpoint only when optimizer type is not changed.
---------        if (
---------            checkpoint["config"]["optimizer"] != self.config["optimizer"]
---------            or checkpoint["config"]["lr_scheduler"] != self.config["lr_scheduler"]
---------        ):
--------+        if checkpoint["config"]["optimizer"] != self.config["optimizer"]:
--------             self.logger.warning(
---------                "Warning: Optimizer or lr_scheduler given in the config file is different "
---------                "from that of the checkpoint. Optimizer and scheduler parameters "
---------                "are not resumed."
--------+                "Warning: Optimizer or lr_scheduler given in config file is different "
--------+                "from that of checkpoint. Optimizer parameters not being resumed."
--------             )
--------         else:
--------             self.optimizer.load_state_dict(checkpoint["optimizer"])
---------            self.lr_scheduler.load_state_dict(checkpoint["lr_scheduler"])
-------- 
---------        self.logger.info(
---------            f"Checkpoint loaded. Resume training from epoch {self.start_epoch}"
------+--        self.model.eval()
------+--        temp_metrics = MetricTracker(
------+--            *self.config.writer.loss_names,
------+--            *[m.name for m in self.metrics["inference"]],
------+--            writer=None,  # –ù–µ –ª–æ–≥–∏—Ä—É–µ–º –≤ writer –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
------ --        )
--------+        if self.lr_scheduler is not None and "lr_scheduler" in checkpoint:
--------+            self.lr_scheduler.load_state_dict(checkpoint["lr_scheduler"])
-------- 
--------     def _from_pretrained(self, pretrained_path):
--------         """
---------        Init model with weights from pretrained pth file.
---------
---------        Notice that 'pretrained_path' can be any path on the disk. It is not
---------        necessary to locate it in the experiment saved dir. The function
---------        initializes only the model.
--------+        Load pretrained model.
-------- 
--------         Args:
---------            pretrained_path (str): path to the model state dict.
--------+            pretrained_path (str): Path to pretrained model.
--------         """
--------         pretrained_path = str(pretrained_path)
---------        if hasattr(self, "logger"):  # to support both trainer and inferencer
---------            self.logger.info(f"Loading model weights from: {pretrained_path} ...")
---------        else:
---------            print(f"Loading model weights from: {pretrained_path} ...")
---------        checkpoint = torch.load(pretrained_path, self.device)
------+--        
------+--        with torch.no_grad():
------+--            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –±–∞—Ç—á–µ–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ—Ü–µ–Ω–∫–∏
------+--            num_batches = min(10, len(dataloader))  # –ú–∞–∫—Å–∏–º—É–º 10 –±–∞—Ç—á–µ–π
------+--            for batch_idx, batch in enumerate(dataloader):
------+--                if batch_idx >= num_batches:
------+--                    break
------+--                    
------+--                try:
------+--                    batch = self.process_batch(batch, temp_metrics)
------+--                except RuntimeError as e:
------+--                    if "out of memory" in str(e) and self.skip_oom:
------+--                        if hasattr(torch.cuda, 'empty_cache'):
------+--                            torch.cuda.empty_cache()
------+--                        continue
------+--                    else:
------+--                        raise e
------ --
---------        if checkpoint.get("state_dict") is not None:
---------            self.model.load_state_dict(checkpoint["state_dict"])
---------        else:
---------            self.model.load_state_dict(checkpoint)
--------\ No newline at end of file
--------+        checkpoint = torch.load(pretrained_path, map_location=self.device)
--------+        self.model.load_state_dict(checkpoint["state_dict"])
--------\ No newline at end of file
--------diff --git a/src/trainer/trainer.py b/src/trainer/trainer.py
--------index 3313fea..f2b2faa 100644
----------- a/src/trainer/trainer.py
--------+++ b/src/trainer/trainer.py
--------@@ -61,9 +61,9 @@ class Trainer(BaseTrainer):
--------         for met in metric_funcs:
--------             if met.name != "eer":
--------                 try:
---------                    metrics.update(met.name, met(**batch))
--------+                    metric_value = met(**batch)
--------+                    metrics.update(met.name, metric_value)
--------                 except Exception as e:
---------                    print(f"–û—à–∏–±–∫–∞ –≤ –º–µ—Ç—Ä–∏–∫–µ {met.name}: {e}")
--------                     continue
--------         return batch
-------- 
--------@@ -72,4 +72,13 @@ class Trainer(BaseTrainer):
--------         Log data from batch. Calls self.writer.add_* to log data
--------         to the experiment tracker.
------+-     def _evaluation_epoch(self, epoch, part, dataloader):
------ -         """
---------        pass
--------\ No newline at end of file
--------+        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±–∞—Ç—á–µ –¥–ª—è writer
--------+        if self.writer is not None:
--------+            # –õ–æ–≥–∏—Ä—É–µ–º learning rate
--------+            if mode == "train" and self.lr_scheduler is not None:
--------+                self.writer.add_scalar("learning_rate", self.lr_scheduler.get_last_lr()[0])
--------+            
--------+            # –õ–æ–≥–∏—Ä—É–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—É—é –Ω–æ—Ä–º—É
--------+            if mode == "train":
--------+                grad_norm = self._get_grad_norm()
--------+                self.writer.add_scalar("grad_norm", grad_norm)
--------\ No newline at end of file
--------diff --git a/src/transforms/__init__.py b/src/transforms/__init__.py
--------index bea0123..1c032b1 100644
----------- a/src/transforms/__init__.py
--------+++ b/src/transforms/__init__.py
--------@@ -1,3 +1,3 @@
-------- from src.transforms.normalize import Normalize
-------- from src.transforms.scale import RandomScale1D
---------from src.transforms.stft import AudioFrontend
--------\ No newline at end of file
--------+from src.transforms.stft import STFTTransform, MelSpectrogramTransform
--------\ No newline at end of file
--------diff --git a/src/transforms/stft.py b/src/transforms/stft.py
--------index 954ff81..f7e362f 100644
----------- a/src/transforms/stft.py
--------+++ b/src/transforms/stft.py
--------@@ -1,37 +1,177 @@
-------- import torch
-------- import torch.nn as nn
--------+import torchaudio
--------+from typing import Dict, Any
-------- 
-------- 
---------def audio_frontend(waveform):
--------+class STFTTransform(nn.Module):
--------+    """
--------+    Short-Time Fourier Transform (STFT) for audio processing.
--------+    """
-------- 
---------    n_fft = 1024
---------    hop_length = 256
---------    win_length = 1024
--------+    def __init__(self, n_fft=1024, hop_length=512, win_length=1024, **kwargs):
--------+        """
--------+        Args:
--------+            n_fft (int): FFT window size
--------+            hop_length (int): Number of samples between successive frames
--------+            win_length (int): Window size
--------+            **kwargs: additional arguments
--------+        """
--------+        super(STFTTransform, self).__init__()
--------+        
--------+        print("üéµ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è STFTTransform...")
--------+        print(f"   üìä n_fft: {n_fft}")
--------+        print(f"   üìä hop_length: {hop_length}")
--------+        print(f"   üìä win_length: {win_length}")
--------+        
--------+        # –õ–æ–≥–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
--------+        for key, value in kwargs.items():
--------+            print(f"   üìä {key}: {value}")
--------+        
--------+        self.n_fft = n_fft
--------+        self.hop_length = hop_length
--------+        self.win_length = win_length
--------+        
--------+        print("‚úÖ STFTTransform –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
-------- 
---------    waveform = waveform.squeeze()
--------+    def forward(self, audio: torch.Tensor) -> torch.Tensor:
--------+        """
--------+        Apply STFT to audio signal.
--------+        
--------+        Args:
--------+            audio (torch.Tensor): input audio tensor
--------+            
--------+        Returns:
--------+            torch.Tensor: STFT spectrogram
--------+        """
--------+        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
--------+        if hasattr(self, '_debug_forward') and self._debug_forward:
--------+            print(f"   üéµ STFTTransform forward: audio shape={audio.shape}")
--------+            print(f"      Audio range: [{audio.min().item():.4f}, {audio.max().item():.4f}]")
--------+            print(f"      Audio dtype: {audio.dtype}")
--------+        
--------+        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∞—É–¥–∏–æ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ñ–æ—Ä–º—É
--------+        if audio.dim() == 1:
--------+            audio = audio.unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
--------+        elif audio.dim() == 3:
--------+            audio = audio.squeeze(1)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–π –∫–∞–Ω–∞–ª
--------+        
--------+        # –ü—Ä–∏–º–µ–Ω—è–µ–º STFT
--------+        stft_output = torch.stft(
--------+            audio,
--------+            n_fft=self.n_fft,
--------+            hop_length=self.hop_length,
--------+            win_length=self.win_length,
--------+            return_complex=True,
--------+            window=torch.hann_window(self.win_length).to(audio.device)
--------+        )
--------+        
--------+        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É
--------+        spectrogram = torch.abs(stft_output)
--------+        
--------+        # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
--------+        if hasattr(self, '_debug_forward') and self._debug_forward:
--------+            print(f"   üìä STFT output shape: {stft_output.shape}")
--------+            print(f"   üìä Spectrogram shape: {spectrogram.shape}")
--------+            print(f"   üìä Spectrogram range: [{spectrogram.min().item():.4f}, {spectrogram.max().item():.4f}]")
--------+        
--------+        return spectrogram
-------- 
---------    stft = torch.stft(
---------        waveform,
---------        n_fft=n_fft,
---------        hop_length=hop_length,
---------        win_length=win_length,
---------        window=torch.hann_window(win_length, device=waveform.device),
---------        return_complex=True
---------    )
--------+    def set_debug_mode(self, debug_forward=False):
--------+        """
--------+        –í–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è forward pass.
--------+        
--------+        Args:
--------+            debug_forward (bool): –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å forward pass
--------+        """
--------+        self._debug_forward = debug_forward
--------+        if debug_forward:
--------+            print(f"üêõ –†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –≤–∫–ª—é—á–µ–Ω –¥–ª—è {self.__class__.__name__}")
--------+            print(f"   üéµ Debug forward: {debug_forward}")
-------- 
---------    magnitude = torch.abs(stft)
---------    log_magnitude = torch.log(magnitude + 1e-8)
---------    log_magnitude = log_magnitude.unsqueeze(0)
---------    return log_magnitude
-------- 
--------+class MelSpectrogramTransform(nn.Module):
--------+    """
--------+    Mel Spectrogram transform for audio processing.
--------+    """
-------- 
---------class AudioFrontend(nn.Module):
---------    
---------    def __init__(self):
---------        super().__init__()
---------    
---------    def forward(self, waveform):
---------      
--------+    def __init__(self, sample_rate=16000, n_fft=1024, hop_length=512, n_mels=80, **kwargs):
--------+        """
--------+        Args:
--------+            sample_rate (int): Audio sample rate
--------+            n_fft (int): FFT window size
--------+            hop_length (int): Number of samples between successive frames
--------+            n_mels (int): Number of mel filter banks
--------+            **kwargs: additional arguments
--------+        """
--------+        super(MelSpectrogramTransform, self).__init__()
--------+        
--------+        print("üéµ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MelSpectrogramTransform...")
--------+        print(f"   üìä sample_rate: {sample_rate}")
--------+        print(f"   üìä n_fft: {n_fft}")
--------+        print(f"   üìä hop_length: {hop_length}")
--------+        print(f"   üìä n_mels: {n_mels}")
--------+        
--------+        # –õ–æ–≥–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
--------+        for key, value in kwargs.items():
--------+            print(f"   üìä {key}: {value}")
--------+        
--------+        self.sample_rate = sample_rate
--------+        self.n_fft = n_fft
--------+        self.hop_length = hop_length
--------+        self.n_mels = n_mels
--------+        
--------+        # –°–æ–∑–¥–∞–µ–º mel spectrogram transform
--------+        self.mel_transform = torchaudio.transforms.MelSpectrogram(
--------+            sample_rate=sample_rate,
--------+            n_fft=n_fft,
--------+            hop_length=hop_length,
--------+            n_mels=n_mels,
--------+            window_fn=torch.hann_window
--------+        )
--------+        
--------+        print("‚úÖ MelSpectrogramTransform –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
-------- 
--------+    def forward(self, audio: torch.Tensor) -> torch.Tensor:
--------+        """
--------+        Apply Mel Spectrogram transform to audio signal.
--------+        
--------+        Args:
--------+            audio (torch.Tensor): input audio tensor
--------+            
--------+        Returns:
--------+            torch.Tensor: Mel spectrogram
--------+        """
--------+        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
--------+        if hasattr(self, '_debug_forward') and self._debug_forward:
--------+            print(f"   üéµ MelSpectrogramTransform forward: audio shape={audio.shape}")
--------+            print(f"      Audio range: [{audio.min().item():.4f}, {audio.max().item():.4f}]")
--------+            print(f"      Audio dtype: {audio.dtype}")
--------+        
--------+        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∞—É–¥–∏–æ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ñ–æ—Ä–º—É
--------+        if audio.dim() == 1:
--------+            audio = audio.unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
--------+        elif audio.dim() == 3:
--------+            audio = audio.squeeze(1)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–π –∫–∞–Ω–∞–ª
--------+        
--------+        # –ü—Ä–∏–º–µ–Ω—è–µ–º mel spectrogram transform
--------+        mel_spectrogram = self.mel_transform(audio)
--------+        
--------+        # –õ–æ–≥–∏—Ä—É–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
--------+        if hasattr(self, '_debug_forward') and self._debug_forward:
--------+            print(f"   üìä Mel spectrogram shape: {mel_spectrogram.shape}")
--------+            print(f"   üìä Mel spectrogram range: [{mel_spectrogram.min().item():.4f}, {mel_spectrogram.max().item():.4f}]")
--------+        
--------+        return mel_spectrogram
-------- 
---------        return audio_frontend(waveform)
--------\ No newline at end of file
--------+    def set_debug_mode(self, debug_forward=False):
--------+        """
--------+        –í–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è forward pass.
--------+        
--------+        Args:
--------+            debug_forward (bool): –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å forward pass
--------+        """
--------+        self._debug_forward = debug_forward
--------+        if debug_forward:
--------+            print(f"üêõ –†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ –≤–∫–ª—é—á–µ–Ω –¥–ª—è {self.__class__.__name__}")
--------+            print(f"   üéµ Debug forward: {debug_forward}")
--------\ No newline at end of file
--------diff --git a/train.py b/train.py
--------index 90a7a4f..ea54b46 100644
----------- a/train.py
--------+++ b/train.py
--------@@ -26,6 +26,7 @@ def main(config):
-------- 
--------     project_config = OmegaConf.to_container(config)
--------     logger = setup_saving_and_logging(config)
--------+    
--------     writer = instantiate(config.writer, logger, project_config)
-------- 
--------     if config.trainer.device == "auto":
--------@@ -34,20 +35,26 @@ def main(config):
--------         device = config.trainer.device
-------- 
--------     # setup data_loader instances
---------    # batch_transforms should be put on device
--------     dataloaders, batch_transforms = get_dataloaders(config, device)
-------- 
--------     # build model architecture, then print to console
--------     model = instantiate(config.model).to(device)
--------+    
--------+    # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏
--------+    total_params = sum(p.numel() for p in model.parameters())
--------+    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
--------+    
--------     logger.info(model)
-------- 
--------     # get function handles of loss and metrics
--------     loss_function = instantiate(config.loss_function).to(device)
--------+    
--------     metrics = instantiate(config.metrics)
-------- 
--------     # build optimizer, learning rate scheduler
--------     trainable_params = filter(lambda p: p.requires_grad, model.parameters())
--------     optimizer = instantiate(config.optimizer, params=trainable_params)
--------+    
--------     lr_scheduler = instantiate(config.lr_scheduler, optimizer=optimizer)
-------- 
--------     # epoch_len = number of iterations for iteration-based training
-------diff --git a/src/metrics/tracker.py b/src/metrics/tracker.py
-------index 79712bd..e9a1d72 100644
---------- a/src/metrics/tracker.py
-------+++ b/src/metrics/tracker.py
-------@@ -50,24 +50,51 @@ class MetricTracker:
-------         self._eer_labels.extend(labels.detach().cpu().numpy())
------+-         Validate after training an epoch.
------+diff --git a/src/datasets/data_utils.py b/src/datasets/data_utils.py
------+index 63e8cce..5a004ee 100644
------+--- a/src/datasets/data_utils.py
------++++ b/src/datasets/data_utils.py
------+@@ -46,7 +46,7 @@ def move_batch_transforms_to_device(batch_transforms, device):
------+                 transforms[transform_name] = transforms[transform_name].to(device)
------+ 
------+ 
------+-def get_dataloaders(config, device):
------++def get_dataloaders(config, device, debug_mode=False):
------+     """
------+     Create dataloaders for each of the dataset partitions.
------+     Also creates instance and batch transforms.
------+@@ -54,6 +54,7 @@ def get_dataloaders(config, device):
------+     Args:
------+         config (DictConfig): hydra experiment config.
------+         device (str): device to use for batch transforms.
------++        debug_mode (bool): if True, create minimal dataloaders for debugging.
------+     Returns:
------+         dataloaders (dict[DataLoader]): dict containing dataloader for a
------+             partition defined by key.
------+@@ -71,22 +72,51 @@ def get_dataloaders(config, device):
------  
-------     def compute_eer(self):
------+     # dataloaders init
------+     dataloaders = {}
------++    debug_subset = None  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–¥–∏–Ω subset –¥–ª—è –≤—Å–µ—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
------++    
------+     for dataset_partition in config.datasets.keys():
------+         dataset = datasets[dataset_partition]
------ -
-------+        """
-------+        Compute Equal Error Rate from accumulated scores and labels.
-------+        """
-------         if not self._eer_scores:
-------             return 0.0
-------         
-------         scores = np.array(self._eer_scores)
-------         labels = np.array(self._eer_labels)
-------         
--------        bona_scores = scores[labels == 1]
--------        spoof_scores = scores[labels == 0]
-------+        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
-------+        thresholds = np.unique(scores)
-------         
--------        if len(bona_scores) == 0 or len(spoof_scores) == 0:
--------            return 0.0
-------+        # –í—ã—á–∏—Å–ª—è–µ–º FAR –∏ FRR –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ä–æ–≥–∞
-------+        far_values = []
-------+        frr_values = []
-------+        
-------+        for threshold in thresholds:
-------+            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: 1 –µ—Å–ª–∏ score >= threshold, –∏–Ω–∞—á–µ 0
-------+            predictions = (scores >= threshold).astype(int)
-------+            
-------+            # –í—ã—á–∏—Å–ª—è–µ–º confusion matrix
-------+            tp = np.sum((predictions == 1) & (labels == 1))
-------+            tn = np.sum((predictions == 0) & (labels == 0))
-------+            fp = np.sum((predictions == 1) & (labels == 0))
-------+            fn = np.sum((predictions == 0) & (labels == 1))
-------+            
-------+            # –í—ã—á–∏—Å–ª—è–µ–º FAR –∏ FRR
-------+            far = fp / (fp + tn) if (fp + tn) > 0 else 0
-------+            frr = fn / (fn + tp) if (fn + tp) > 0 else 0
-------+            
-------+            far_values.append(far)
-------+            frr_values.append(frr)
------+-        assert config.dataloader.batch_size <= len(dataset), (
------+-            f"The batch size ({config.dataloader.batch_size}) cannot "
------ +        
-------+        # –ù–∞—Ö–æ–¥–∏–º —Ç–æ—á–∫—É, –≥–¥–µ FAR ‚âà FRR
-------+        far_values = np.array(far_values)
-------+        frr_values = np.array(frr_values)
------++        # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ –≤—Å–µ —Ä–∞–∑–¥–µ–ª—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ train
------++        if debug_mode:
------++            from torch.utils.data import Subset
------++            if debug_subset is None:
------++                # –°–æ–∑–¥–∞–µ–º subset —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–æ–±—ã—á–Ω–æ train)
------++                debug_subset_indices = range(min(4, len(dataset)))
------++                debug_subset = Subset(dataset, debug_subset_indices)
------++                print(f"üîß Debug mode: –∏—Å–ø–æ–ª—å–∑—É–µ–º {len(debug_subset)} –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Ä–∞–∑–¥–µ–ª–æ–≤")
------++            dataset = debug_subset
------++
------++        # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∏–∑–º–µ–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä–∞
------++        if debug_mode:
------++            batch_size = min(2, len(dataset))
------++            num_workers = 0
------++            pin_memory = False
------++        else:
------++            batch_size = config.dataloader.batch_size
------++            num_workers = getattr(config.dataloader, 'num_workers', 4)
------++            pin_memory = getattr(config.dataloader, 'pin_memory', True)
------++
------++        assert batch_size <= len(dataset), (
------++            f"The batch size ({batch_size}) cannot "
------+             f"be larger than the dataset length ({len(dataset)})"
------+         )
------+ 
------+         partition_dataloader = instantiate(
------+             config.dataloader,
------+             dataset=dataset,
------++            batch_size=batch_size,
------++            num_workers=num_workers,
------++            pin_memory=pin_memory,
------+             collate_fn=collate_fn,
------+-            drop_last=(dataset_partition == "train"),
------+-            shuffle=(dataset_partition == "train"),
------++            drop_last=False,  # –í debug —Ä–µ–∂–∏–º–µ –Ω–µ –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
------++            shuffle=False,    # –í debug —Ä–µ–∂–∏–º–µ –Ω–µ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
------+             worker_init_fn=set_worker_seed,
------+         )
------ +        
-------+        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å, –≥–¥–µ —Ä–∞–∑–Ω–æ—Å—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω–∞
-------+        diff = np.abs(far_values - frr_values)
-------+        min_idx = np.argmin(diff)
------+         dataloaders[dataset_partition] = partition_dataloader
------ +        
-------+        # EER - —ç—Ç–æ —Å—Ä–µ–¥–Ω–µ–µ FAR –∏ FRR –≤ —ç—Ç–æ–π —Ç–æ—á–∫–µ
-------+        eer = (far_values[min_idx] + frr_values[min_idx]) / 2
-------         
--------        # –í—ã—á–∏—Å–ª—è–µ–º EER
--------        from src.metrics.eer import EERMetric
--------        eer_metric = EERMetric()
--------        eer, _ = eer_metric.compute_eer(bona_scores, spoof_scores)
--------        return eer
-------+        return float(eer)
------++        if debug_mode:
------++            print(f"üìÅ {dataset_partition}: {len(dataset)} –æ–±—Ä–∞–∑—Ü–æ–≤, batch_size={batch_size}")
------  
-------     def avg(self, key):
------+     return dataloaders, batch_transforms
------+\ No newline at end of file
------+diff --git a/src/datasets/mydataset.py b/src/datasets/mydataset.py
------+index 94e7e12..e5d6aa7 100644
------+--- a/src/datasets/mydataset.py
------++++ b/src/datasets/mydataset.py
------+@@ -15,7 +15,7 @@ class AudioSpoofingDataset(BaseDataset):
------+ 
------+     def __init__(
------+         self, name="train", label_path=None, audio_path=None, out_path=None, 
------+-        instance_transforms=None, *args, **kwargs
------++        instance_transforms=None, max_samples=None, *args, **kwargs
------+     ):
------+         """
------+         Args:
------+@@ -24,11 +24,13 @@ class AudioSpoofingDataset(BaseDataset):
------+             audio_path (str): path to the directory with .flac files
------+             out_path (str): where to save index.json
------+             instance_transforms (dict): transforms to apply to instances
------++            max_samples (int): maximum number of samples for debugging (None for all)
------          """
------+         self.name = name
------+         self.label_path = label_path
------+         self.audio_path = audio_path
------+         self.out_path = out_path
------++        self.max_samples = max_samples
------+         
------+         # Create index if it doesn't exist
------+         if Path(out_path).exists():
------+@@ -36,6 +38,10 @@ class AudioSpoofingDataset(BaseDataset):
------+         else:
------+             index = self._create_index(label_path, audio_path, out_path)
------+ 
------++        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
------++        if max_samples is not None:
------++            index = index[:max_samples]
------++
------+         super().__init__(index, instance_transforms=instance_transforms, *args, **kwargs)
------+ 
------+     def __getitem__(self, idx):
------ diff --git a/src/trainer/base_trainer.py b/src/trainer/base_trainer.py
-------index 0d4e7a1..9f6663a 100644
------+index de03b18..15a1282 100644
------ --- a/src/trainer/base_trainer.py
------ +++ b/src/trainer/base_trainer.py
-------@@ -194,6 +194,10 @@ class BaseTrainer:
-------         self.model.train()
-------         self.train_metrics.reset()
-------         
-------+        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–µ—Ä–µ–¥–∏–Ω—ã —ç–ø–æ—Ö–∏
-------+        total_batches = len(self.train_dataloader)
-------+        mid_epoch_batch = total_batches // 2
-------+        
-------         pbar = tqdm(self.train_dataloader, desc=f"Train Epoch {epoch}")
-------         for batch_idx, batch in enumerate(pbar):
-------             try:
-------@@ -206,9 +210,18 @@ class BaseTrainer:
-------                     current_loss = self.train_metrics.avg(loss_key)
-------                     print(f"[Batch {batch_idx}] Loss: {current_loss:.6f}")
------+@@ -172,8 +172,9 @@ class BaseTrainer:
------+                 
------+                 # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ª–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Ü–µ —ç–ø–æ—Ö–∏
------+                 if self.writer is not None:
------++                    self.writer.set_step(epoch, "val")
------+                     for metric_name, metric_value in val_logs.items():
------+-                        self.writer.add_scalar(f"val_{metric_name}_final", metric_value, epoch)
------++                        self.writer.add_scalar(f"val_{metric_name}_final", metric_value)
------+                 
------+                 # –í—ã–≤–æ–¥–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Å–æ–ª—å
------+                 print(f"    –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —ç–ø–æ—Ö–∏ {epoch}:")
------+@@ -223,16 +224,20 @@ class BaseTrainer:
------+                     
------+                     # –õ–æ–≥–∏—Ä—É–µ–º train_loss –≤ CometML –∫–∞–∂–¥—ã–µ 50 –±–∞—Ç—á–µ–π
------+                     if self.writer is not None:
------+-                        self.writer.add_scalar("train_loss_batch", current_loss, batch_idx)
------++                        self.writer.set_step(batch_idx, "train")
------++                        self.writer.add_scalar("train_loss_batch", current_loss)
------                  
--------                # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏
--------                if batch_idx == len(self.train_dataloader) // 2 and "val" in self.evaluation_dataloaders:
--------                    self._quick_validation(epoch, "val", self.evaluation_dataloaders["val"])
-------+                # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏ (–µ—Å–ª–∏ val_period = 1)
-------+                if batch_idx == mid_epoch_batch and "val" in self.evaluation_dataloaders:
-------+                    print(f"\n--- –í–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏ {epoch} ---")
-------+                    val_logs = {}
-------+                    dataloader = self.evaluation_dataloaders["val"]
-------+                    val_part_logs = self._evaluation_epoch(epoch, "val", dataloader)
-------+                    val_logs.update(val_part_logs)
-------+                    
-------+                    # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –∫–æ–Ω—Å–æ–ª—å
-------+                    for metric_name, metric_value in val_logs.items():
-------+                        print(f"    {metric_name}: {metric_value:.6f}")
-------+                    print("--- –ö–æ–Ω–µ—Ü –≤–∞–ª–∏–¥–∞—Ü–∏–∏ ---\n")
------+                 # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏ (–µ—Å–ª–∏ val_period = 1)
------+                 if batch_idx == mid_epoch_batch and "val" in self.evaluation_dataloaders:
------+                     # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º
------+                     was_training = self.is_train
------++                    was_model_training = self.model.training
------+                     
------+-                    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏
------+-                    self.is_train = False
------+-                    self.model.eval()
------++                    # –í debug —Ä–µ–∂–∏–º–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏ –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è
------++                    debug_mode = getattr(self.config, 'debug_mode', False)
------++                    if debug_mode:
------++                        print("üîß Debug mode: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏")
------++                        continue
------+                     
------+                     # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π MetricTracker –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏
------+                     mid_epoch_metrics = MetricTracker(
------+@@ -251,8 +256,9 @@ class BaseTrainer:
------+                     
------+                     # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ª–æ–≥–∏—Ä—É–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏
------+                     if self.writer is not None:
------++                        self.writer.set_step(batch_idx, "val")
------+                         for metric_name, metric_value in val_logs.items():
------+-                            self.writer.add_scalar(f"val_{metric_name}_mid_epoch", metric_value, batch_idx)
------++                            self.writer.add_scalar(f"val_{metric_name}_mid_epoch", metric_value)
------+                     
------+                     # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Å–æ–ª—å
------+                     print(f"    –í–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏ {epoch}:")
------+@@ -261,8 +267,8 @@ class BaseTrainer:
------+                     print()
------+                     
------+                     # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è
------+-                    self.is_train = True
------+-                    self.model.train()
------++                    self.is_train = was_training
------++                    self.model.train(was_model_training)
------                      
------              except RuntimeError as e:
------                  if "out of memory" in str(e) and self.skip_oom:
-------@@ -220,39 +233,6 @@ class BaseTrainer:
-------                     
-------         self._log_scalars(self.train_metrics)
------+@@ -276,8 +282,9 @@ class BaseTrainer:
------+         
------+         # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ª–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
------+         if self.writer is not None:
------++            self.writer.set_step(epoch, "train")
------+             for metric_name, metric_value in self.train_metrics.result().items():
------+-                self.writer.add_scalar(f"train_{metric_name}_epoch", metric_value, epoch)
------++                self.writer.add_scalar(f"train_{metric_name}_epoch", metric_value)
------  
--------    def _quick_validation(self, epoch, part, dataloader):
--------        """
--------        –ë—ã—Å—Ç—Ä–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è EER –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏.
--------
--------        Args:
--------            epoch (int): Current epoch number.
--------            part (str): Name of the data part.
--------            dataloader (DataLoader): Dataloader for validation.
--------        """
--------        self.model.eval()
--------        temp_metrics = MetricTracker(
--------            *self.config.writer.loss_names,
--------            *[m.name for m in self.metrics["inference"]],
--------            writer=None,  # –ù–µ –ª–æ–≥–∏—Ä—É–µ–º –≤ writer –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏
--------        )
--------        
--------        with torch.no_grad():
--------            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –±–∞—Ç—á–µ–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ—Ü–µ–Ω–∫–∏
--------            num_batches = min(10, len(dataloader))  # –ú–∞–∫—Å–∏–º—É–º 10 –±–∞—Ç—á–µ–π
--------            for batch_idx, batch in enumerate(dataloader):
--------                if batch_idx >= num_batches:
--------                    break
--------                    
--------                try:
--------                    batch = self.process_batch(batch, temp_metrics)
--------                except RuntimeError as e:
--------                    if "out of memory" in str(e) and self.skip_oom:
--------                        if hasattr(torch.cuda, 'empty_cache'):
--------                            torch.cuda.empty_cache()
--------                        continue
--------                    else:
--------                        raise e
--------
------      def _evaluation_epoch(self, epoch, part, dataloader):
------          """
-------         Validate after training an epoch.
------+@@ -291,12 +298,26 @@ class BaseTrainer:
------+         Returns:
------+             dict: Dictionary with validation logs.
------+         """
------+-        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏
------+-        self.is_train = False
------+-        self.model.eval()
------++        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∫–ª—é—á–µ–Ω –ª–∏ debug_mode (One Batch Test)
------++        debug_mode = getattr(self.config, 'debug_mode', False)
------++        
------++        if debug_mode:
------++            # –í —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ç–æ–∂–µ –¥–æ–ª–∂–Ω–∞ "–æ–±—É—á–∞—Ç—å—Å—è" –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
------++            print(f"üîß Debug mode: –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Ä–µ–∂–∏–º–µ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è")
------++            self.is_train = True  # –û—Å—Ç–∞–≤–ª—è–µ–º –≤ —Ä–µ–∂–∏–º–µ –æ–±—É—á–µ–Ω–∏—è
------++            self.model.train()    # –ú–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º–µ –æ–±—É—á–µ–Ω–∏—è
------++            use_gradients = True  # –†–∞–∑—Ä–µ—à–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
------++        else:
------++            # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏
------++            self.is_train = False
------++            self.model.eval()
------++            use_gradients = False
------++        
------+         self.evaluation_metrics.reset()
------+         
------+-        with torch.no_grad():
------++        context_manager = torch.no_grad() if not use_gradients else torch.enable_grad()
------++        
------++        with context_manager:
------+             pbar = tqdm(dataloader, desc=f"Validation {part} Epoch {epoch}")
------+             for batch_idx, batch in enumerate(pbar):
------+                 try:
------+@@ -311,14 +332,16 @@ class BaseTrainer:
------+                     else:
------+                         raise e
------+ 
------+-        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è
------+-        self.is_train = True
------++        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è (–µ—Å–ª–∏ –Ω–µ debug)
------++        if not debug_mode:
------++            self.is_train = True
------+         self._log_scalars(self.evaluation_metrics)
------+         
------+         # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ª–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
------+         if self.writer is not None:
------++            self.writer.set_step(epoch, "val")
------+             for metric_name, metric_value in self.evaluation_metrics.result().items():
------+-                self.writer.add_scalar(f"val_{metric_name}_epoch", metric_value, epoch)
------++                self.writer.add_scalar(f"val_{metric_name}_epoch", metric_value)
------+                 
------+         return self.evaluation_metrics.result()
------+ 
------+diff --git a/train.py b/train.py
------+index ea54b46..4060e3c 100644
------+--- a/train.py
------++++ b/train.py
------+@@ -35,7 +35,8 @@ def main(config):
------+         device = config.trainer.device
------+ 
------+     # setup data_loader instances
------+-    dataloaders, batch_transforms = get_dataloaders(config, device)
------++    debug_mode = getattr(config, 'debug_mode', False)
------++    dataloaders, batch_transforms = get_dataloaders(config, device, debug_mode)
------+ 
------+     # build model architecture, then print to console
------+     model = instantiate(config.model).to(device)
------diff --git a/src/configs/baseline.yaml b/src/configs/baseline.yaml
------index 40903a9..1947c72 100644
--------- a/src/configs/baseline.yaml
------+++ b/src/configs/baseline.yaml
------@@ -13,5 +13,5 @@ defaults:
------ 
------ data_path: ${oc.env:DATA_PATH,data}
------ project_name: anti-spoofing
-------run_name: anti-spoofing-experiment
------+run_name: baseline-experiment
------ 
------diff --git a/src/configs/writer/cometml.yaml b/src/configs/writer/cometml.yaml
------index 8675b47..451af75 100644
--------- a/src/configs/writer/cometml.yaml
------+++ b/src/configs/writer/cometml.yaml
------@@ -2,7 +2,7 @@ _target_: src.logger.cometml.CometMLWriter
------ project_name: "anti-spoofing"
------ workspace: null
------ run_id: null
-------run_name: "inference-test"
------+run_name: "training-experiment"
------ mode: "online"
------ loss_names: ["loss"]
------ log_checkpoints: False
------diff --git a/src/datasets/data_utils.py b/src/datasets/data_utils.py
------index 63e8cce..5a004ee 100644
--------- a/src/datasets/data_utils.py
------+++ b/src/datasets/data_utils.py
------@@ -46,7 +46,7 @@ def move_batch_transforms_to_device(batch_transforms, device):
------                 transforms[transform_name] = transforms[transform_name].to(device)
------ 
------ 
-------def get_dataloaders(config, device):
------+def get_dataloaders(config, device, debug_mode=False):
------     """
------     Create dataloaders for each of the dataset partitions.
------     Also creates instance and batch transforms.
------@@ -54,6 +54,7 @@ def get_dataloaders(config, device):
------     Args:
------         config (DictConfig): hydra experiment config.
------         device (str): device to use for batch transforms.
------+        debug_mode (bool): if True, create minimal dataloaders for debugging.
------     Returns:
------         dataloaders (dict[DataLoader]): dict containing dataloader for a
------             partition defined by key.
------@@ -71,22 +72,51 @@ def get_dataloaders(config, device):
------ 
------     # dataloaders init
------     dataloaders = {}
------+    debug_subset = None  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–¥–∏–Ω subset –¥–ª—è –≤—Å–µ—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
------+    
------     for dataset_partition in config.datasets.keys():
------         dataset = datasets[dataset_partition]
-------
-------        assert config.dataloader.batch_size <= len(dataset), (
-------            f"The batch size ({config.dataloader.batch_size}) cannot "
------+        
------+        # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ –≤—Å–µ —Ä–∞–∑–¥–µ–ª—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ train
------+        if debug_mode:
------+            from torch.utils.data import Subset
------+            if debug_subset is None:
------+                # –°–æ–∑–¥–∞–µ–º subset —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–æ–±—ã—á–Ω–æ train)
------+                debug_subset_indices = range(min(4, len(dataset)))
------+                debug_subset = Subset(dataset, debug_subset_indices)
------+                print(f"üîß Debug mode: –∏—Å–ø–æ–ª—å–∑—É–µ–º {len(debug_subset)} –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Ä–∞–∑–¥–µ–ª–æ–≤")
------+            dataset = debug_subset
------+
------+        # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∏–∑–º–µ–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä–∞
------+        if debug_mode:
------+            batch_size = min(2, len(dataset))
------+            num_workers = 0
------+            pin_memory = False
------+        else:
------+            batch_size = config.dataloader.batch_size
------+            num_workers = getattr(config.dataloader, 'num_workers', 4)
------+            pin_memory = getattr(config.dataloader, 'pin_memory', True)
------+
------+        assert batch_size <= len(dataset), (
------+            f"The batch size ({batch_size}) cannot "
------             f"be larger than the dataset length ({len(dataset)})"
------         )
------ 
------         partition_dataloader = instantiate(
------             config.dataloader,
------             dataset=dataset,
------+            batch_size=batch_size,
------+            num_workers=num_workers,
------+            pin_memory=pin_memory,
------             collate_fn=collate_fn,
-------            drop_last=(dataset_partition == "train"),
-------            shuffle=(dataset_partition == "train"),
------+            drop_last=False,  # –í debug —Ä–µ–∂–∏–º–µ –Ω–µ –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
------+            shuffle=False,    # –í debug —Ä–µ–∂–∏–º–µ –Ω–µ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
------             worker_init_fn=set_worker_seed,
------         )
------+        
------         dataloaders[dataset_partition] = partition_dataloader
------+        
------+        if debug_mode:
------+            print(f"üìÅ {dataset_partition}: {len(dataset)} –æ–±—Ä–∞–∑—Ü–æ–≤, batch_size={batch_size}")
------ 
------     return dataloaders, batch_transforms
------\ No newline at end of file
------diff --git a/src/datasets/mydataset.py b/src/datasets/mydataset.py
------index 94e7e12..e5d6aa7 100644
--------- a/src/datasets/mydataset.py
------+++ b/src/datasets/mydataset.py
------@@ -15,7 +15,7 @@ class AudioSpoofingDataset(BaseDataset):
------ 
------     def __init__(
------         self, name="train", label_path=None, audio_path=None, out_path=None, 
-------        instance_transforms=None, *args, **kwargs
------+        instance_transforms=None, max_samples=None, *args, **kwargs
------     ):
------         """
------         Args:
------@@ -24,11 +24,13 @@ class AudioSpoofingDataset(BaseDataset):
------             audio_path (str): path to the directory with .flac files
------             out_path (str): where to save index.json
------             instance_transforms (dict): transforms to apply to instances
------+            max_samples (int): maximum number of samples for debugging (None for all)
------         """
------         self.name = name
------         self.label_path = label_path
------         self.audio_path = audio_path
------         self.out_path = out_path
------+        self.max_samples = max_samples
------         
------         # Create index if it doesn't exist
------         if Path(out_path).exists():
------@@ -36,6 +38,10 @@ class AudioSpoofingDataset(BaseDataset):
------         else:
------             index = self._create_index(label_path, audio_path, out_path)
------ 
------+        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
------+        if max_samples is not None:
------+            index = index[:max_samples]
------+
------         super().__init__(index, instance_transforms=instance_transforms, *args, **kwargs)
------ 
------     def __getitem__(self, idx):
------diff --git a/src/logger/utils.py b/src/logger/utils.py
------index c465f41..2795052 100644
--------- a/src/logger/utils.py
------+++ b/src/logger/utils.py
------@@ -4,7 +4,7 @@ import matplotlib.pyplot as plt
------ import PIL
------ from torchvision.transforms import ToTensor
------ 
-------plt.switch_backend("agg")  # fix RuntimeError: main thread is not in main loop
------+plt.switch_backend("agg")
------ 
------ 
------ def plot_images(imgs, config):
------diff --git a/src/trainer/base_trainer.py b/src/trainer/base_trainer.py
------index de03b18..c827e0b 100644
--------- a/src/trainer/base_trainer.py
------+++ b/src/trainer/base_trainer.py
------@@ -170,16 +170,17 @@ class BaseTrainer:
------                 val_part_logs = self._evaluation_epoch(epoch, "val", dataloader)
------                 val_logs.update(val_part_logs)
------                 
-------                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ª–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Ü–µ —ç–ø–æ—Ö–∏
-------                if self.writer is not None:
-------                    for metric_name, metric_value in val_logs.items():
-------                        self.writer.add_scalar(f"val_{metric_name}_final", metric_value, epoch)
-------                
------                 # –í—ã–≤–æ–¥–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Å–æ–ª—å
-------                print(f"    –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —ç–ø–æ—Ö–∏ {epoch}:")
------+                print(f"\nüìä –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —ç–ø–æ—Ö–∏ {epoch}:")
------                 for metric_name, metric_value in val_logs.items():
-------                    print(f"        {metric_name}: {metric_value:.6f}")
------+                    print(f"    val_{metric_name}: {metric_value:.6f}")
------                 print()
------+                
------+                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ª–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Ü–µ —ç–ø–æ—Ö–∏
------+                if self.writer is not None:
------+                    self.writer.set_step(epoch, "val")
------+                    for metric_name, metric_value in val_logs.items():
------+                        self.writer.add_scalar(f"val_{metric_name}_epoch", metric_value)
------ 
------                 # log best so far
------                 if self.mnt_mode != "off":
------@@ -215,24 +216,34 @@ class BaseTrainer:
------                 batch = self.process_batch(batch, self.train_metrics)
------                 self._log_batch(batch_idx, batch, "train")
------                 
-------                # –í—ã–≤–æ–¥–∏–º –ª–æ—Å—Å –≤ –∫–æ–Ω—Å–æ–ª—å –∫–∞–∂–¥—ã–µ 50 –±–∞—Ç—á–µ–π
-------                if batch_idx % 50 == 0:
------+                # –í—ã–≤–æ–¥–∏–º –ª–æ—Å—Å –≤ –∫–æ–Ω—Å–æ–ª—å –∫–∞–∂–¥—ã–µ log_step –±–∞—Ç—á–µ–π
------+                if batch_idx % self.log_step == 0:
------                     loss_key = self.config.writer.loss_names[0]
------                     current_loss = self.train_metrics.avg(loss_key)
-------                    print(f"[Batch {batch_idx}] Loss: {current_loss:.6f}")
------+                    current_eer = self.train_metrics.avg("eer") if self.train_metrics._eer_scores else 0.0
------                     
-------                    # –õ–æ–≥–∏—Ä—É–µ–º train_loss –≤ CometML –∫–∞–∂–¥—ã–µ 50 –±–∞—Ç—á–µ–π
------+                    print(f"[Epoch {epoch}, Batch {batch_idx}] Loss: {current_loss:.6f}, EER: {current_eer:.6f}")
------+                    
------+                    # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ CometML –∫–∞–∂–¥—ã–µ log_step –±–∞—Ç—á–µ–π
------                     if self.writer is not None:
-------                        self.writer.add_scalar("train_loss_batch", current_loss, batch_idx)
------+                        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–∏–π —à–∞–≥ –∫–∞–∫ epoch * num_batches + batch_idx
------+                        global_step = (epoch - 1) * len(self.train_dataloader) + batch_idx
------+                        self.writer.set_step(global_step, "train")
------+                        self.writer.add_scalar("train_loss_batch", current_loss)
------+                        if self.train_metrics._eer_scores:
------+                            self.writer.add_scalar("train_eer_batch", current_eer)
------                 
------                 # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏ (–µ—Å–ª–∏ val_period = 1)
------                 if batch_idx == mid_epoch_batch and "val" in self.evaluation_dataloaders:
------                     # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º
------                     was_training = self.is_train
------+                    was_model_training = self.model.training
------                     
-------                    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏
-------                    self.is_train = False
-------                    self.model.eval()
------+                    # –í debug —Ä–µ–∂–∏–º–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏ –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è
------+                    debug_mode = getattr(self.config, 'debug_mode', False)
------+                    if debug_mode:
------+                        print("üîß Debug mode: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏")
------+                        continue
------                     
------                     # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π MetricTracker –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏
------                     mid_epoch_metrics = MetricTracker(
------@@ -251,8 +262,9 @@ class BaseTrainer:
------                     
------                     # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ª–æ–≥–∏—Ä—É–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏
------                     if self.writer is not None:
------+                        self.writer.set_step(batch_idx, "val")
------                         for metric_name, metric_value in val_logs.items():
-------                            self.writer.add_scalar(f"val_{metric_name}_mid_epoch", metric_value, batch_idx)
------+                            self.writer.add_scalar(f"val_{metric_name}_mid_epoch", metric_value)
------                     
------                     # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Å–æ–ª—å
------                     print(f"    –í–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —ç–ø–æ—Ö–∏ {epoch}:")
------@@ -261,8 +273,8 @@ class BaseTrainer:
------                     print()
------                     
------                     # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è
-------                    self.is_train = True
-------                    self.model.train()
------+                    self.is_train = was_training
------+                    self.model.train(was_model_training)
------                     
------             except RuntimeError as e:
------                 if "out of memory" in str(e) and self.skip_oom:
------@@ -275,9 +287,15 @@ class BaseTrainer:
------         self._log_scalars(self.train_metrics)
------         
------         # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ª–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
------+        train_results = self.train_metrics.result()
------+        print(f"\nüìä –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ —ç–ø–æ—Ö–∏ {epoch}:")
------+        for metric_name, metric_value in train_results.items():
------+            print(f"    train_{metric_name}: {metric_value:.6f}")
------+        
------         if self.writer is not None:
-------            for metric_name, metric_value in self.train_metrics.result().items():
-------                self.writer.add_scalar(f"train_{metric_name}_epoch", metric_value, epoch)
------+            self.writer.set_step(epoch, "train")
------+            for metric_name, metric_value in train_results.items():
------+                self.writer.add_scalar(f"train_{metric_name}_epoch", metric_value)
------ 
------     def _evaluation_epoch(self, epoch, part, dataloader):
------         """
------@@ -291,12 +309,26 @@ class BaseTrainer:
------         Returns:
------             dict: Dictionary with validation logs.
------         """
-------        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏
-------        self.is_train = False
-------        self.model.eval()
------+        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∫–ª—é—á–µ–Ω –ª–∏ debug_mode (One Batch Test)
------+        debug_mode = getattr(self.config, 'debug_mode', False)
------+        
------+        if debug_mode:
------+            # –í —Ä–µ–∂–∏–º–µ –æ—Ç–ª–∞–¥–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ç–æ–∂–µ –¥–æ–ª–∂–Ω–∞ "–æ–±—É—á–∞—Ç—å—Å—è" –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
------+            print(f"üîß Debug mode: –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤ —Ä–µ–∂–∏–º–µ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è")
------+            self.is_train = True  # –û—Å—Ç–∞–≤–ª—è–µ–º –≤ —Ä–µ–∂–∏–º–µ –æ–±—É—á–µ–Ω–∏—è
------+            self.model.train()    # –ú–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º–µ –æ–±—É—á–µ–Ω–∏—è
------+            use_gradients = True  # –†–∞–∑—Ä–µ—à–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
------+        else:
------+            # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏
------+            self.is_train = False
------+            self.model.eval()
------+            use_gradients = False
------+        
------         self.evaluation_metrics.reset()
------         
-------        with torch.no_grad():
------+        context_manager = torch.no_grad() if not use_gradients else torch.enable_grad()
------+        
------+        with context_manager:
------             pbar = tqdm(dataloader, desc=f"Validation {part} Epoch {epoch}")
------             for batch_idx, batch in enumerate(pbar):
------                 try:
------@@ -311,14 +343,12 @@ class BaseTrainer:
------                     else:
------                         raise e
------ 
-------        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è
-------        self.is_train = True
-------        self._log_scalars(self.evaluation_metrics)
------+        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è (–µ—Å–ª–∏ –Ω–µ debug)
------+        if not debug_mode:
------+            self.is_train = True
------         
-------        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ª–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
-------        if self.writer is not None:
-------            for metric_name, metric_value in self.evaluation_metrics.result().items():
-------                self.writer.add_scalar(f"val_{metric_name}_epoch", metric_value, epoch)
------+        # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–æ—Å–Ω–æ–≤–Ω–æ–π —Å–ø–æ—Å–æ–±)
------+        self._log_scalars(self.evaluation_metrics)
------                 
------         return self.evaluation_metrics.result()
------ 
------@@ -449,6 +479,9 @@ class BaseTrainer:
------         Args:
------             metric_tracker (MetricTracker): Metric tracker.
------         """
------+        if self.writer is None:
------+            return
------+            
------         for metric_name, metric_value in metric_tracker.result().items():
------             # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –º–µ—Ç—Ä–∏–∫
------             if metric_tracker == self.train_metrics:
------diff --git a/src/trainer/inferencer.py b/src/trainer/inferencer.py
------index 06185a3..2dc68a0 100644
--------- a/src/trainer/inferencer.py
------+++ b/src/trainer/inferencer.py
------@@ -60,14 +60,14 @@ class Inferencer(BaseTrainer):
------         self.model = model
------         self.batch_transforms = batch_transforms
------ 
-------        # define dataloaders
------+       
------         self.evaluation_dataloaders = {k: v for k, v in dataloaders.items()}
------ 
-------        # path definition
------+      
------ 
------         self.save_path = save_path
------ 
-------        # define metrics
------+      
------         self.metrics = metrics
------         self.writer = writer
------         if self.metrics is not None:
------@@ -79,7 +79,7 @@ class Inferencer(BaseTrainer):
------             self.evaluation_metrics = None
------ 
------         if not skip_model_load:
-------            # init model
------+           
------             self._from_pretrained(config.inferencer.get("from_pretrained"))
------ 
------     def run_inference(self):
------@@ -128,15 +128,13 @@ class Inferencer(BaseTrainer):
------             for met in self.metrics["inference"]:
------                 metrics.update(met.name, met(**batch))
------ 
-------        # Some saving logic. This is an example
-------        # Use if you need to save predictions on disk
------+    
------ 
------         batch_size = batch["logits"].shape[0]
------         current_id = batch_idx * batch_size
------ 
------         for i in range(batch_size):
-------            # clone because of
-------            # https://github.com/pytorch/pytorch/issues/1995
------+         
------             logits = batch["logits"][i].clone()
------             label = batch["labels"][i].clone()
------             pred_label = logits.argmax(dim=-1)
------@@ -149,7 +147,7 @@ class Inferencer(BaseTrainer):
------             }
------ 
------             if self.save_path is not None:
-------                # you can use safetensors or other lib here
------+             
------                 torch.save(output, self.save_path / part / f"output_{output_id}.pth")
------ 
------         return batch
------@@ -189,7 +187,7 @@ class Inferencer(BaseTrainer):
------ 
------         results = self.evaluation_metrics.result()
------         
-------        # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ CometML
------+      
------         if self.writer is not None:
------             for metric_name, metric_value in results.items():
------                 self.writer.add_scalar(f"inference_{part}_{metric_name}", metric_value, 0)
------diff --git a/train.py b/train.py
------index ea54b46..57b9354 100644
--------- a/train.py
------+++ b/train.py
------@@ -35,7 +35,8 @@ def main(config):
------         device = config.trainer.device
------ 
------     # setup data_loader instances
-------    dataloaders, batch_transforms = get_dataloaders(config, device)
------+    debug_mode = getattr(config, 'debug_mode', False)
------+    dataloaders, batch_transforms = get_dataloaders(config, device, debug_mode)
------ 
------     # build model architecture, then print to console
------     model = instantiate(config.model).to(device)
------@@ -44,7 +45,23 @@ def main(config):
------     total_params = sum(p.numel() for p in model.parameters())
------     trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
------     
------+    print(f"\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏:")
------+    print(f"üî¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")
------+    print(f"üéØ –û–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {trainable_params:,}")
------+    print(f"üìÅ –†–∞–∑–º–µ—Ä—ã –¥–∞—Ç–∞—Å–µ—Ç–æ–≤:")
------+    for partition, dataloader in dataloaders.items():
------+        print(f"    {partition}: {len(dataloader.dataset)} –æ–±—Ä–∞–∑—Ü–æ–≤, batch_size={dataloader.batch_size}")
------+    print()
------+    
------     logger.info(model)
------+    
------+    # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –≤ CometML
------+    if writer is not None:
------+        writer.exp.log_parameters({
------+            "total_params": total_params,
------+            "trainable_params": trainable_params,
------+            "model_name": config.model._target_.split('.')[-1],
------+        })
------ 
------     # get function handles of loss and metrics
------     loss_function = instantiate(config.loss_function).to(device)
----diff --git a/one_batch_test.py b/one_batch_test.py
----deleted file mode 100644
----index 4fe3755..0000000
------- a/one_batch_test.py
----+++ /dev/null
----@@ -1,123 +0,0 @@
-----import warnings
-----import hydra
-----import torch
-----from hydra.utils import instantiate
-----from omegaconf import OmegaConf
-----
-----from src.datasets.data_utils import get_dataloaders
-----from src.trainer import Trainer
-----from src.utils.init_utils import set_random_seed, setup_saving_and_logging
-----
-----warnings.filterwarnings("ignore", category=UserWarning)
-----
-----@hydra.main(version_base=None, config_path="src/configs", config_name="baseline")
-----def main(config):
-----    """
-----    One Batch Test script. Tests if the model can overfit on a small batch.
-----    This is useful for debugging the training pipeline.
-----    """
-----    print("üîç –ó–∞–ø—É—Å–∫ One Batch Test...")
-----    print("üìä –û–∂–∏–¥–∞–µ–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –º–∞–ª–µ–Ω—å–∫–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ")
-----    
-----    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
-----    set_random_seed(config.trainer.seed)
-----    
-----    # –î–æ–±–∞–≤–ª—è–µ–º debug_mode –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
-----    OmegaConf.set_struct(config, False)
-----    config.debug_mode = True
-----    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
-----    config.trainer.n_epochs = 100
-----    # –ß–∞—â–µ –ª–æ–≥–∏—Ä—É–µ–º
-----    config.trainer.log_step = 1
-----    # –û—Ç–∫–ª—é—á–∞–µ–º early stopping
-----    config.trainer.early_stop = 200
-----    OmegaConf.set_struct(config, True)
-----    
-----    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
-----    project_config = OmegaConf.to_container(config)
-----    logger = setup_saving_and_logging(config)
-----    writer = instantiate(config.writer, logger, project_config)
-----    
-----    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
-----    if config.trainer.device == "auto":
-----        device = "cuda" if torch.cuda.is_available() else "cpu"
-----    else:
-----        device = config.trainer.device
-----    
-----    print(f"üñ•Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
-----    
-----    # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏-–¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä—ã (debug_mode=True)
-----    dataloaders, batch_transforms = get_dataloaders(config, device, debug_mode=True)
-----    
-----    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —Ä–∞–∑–¥–µ–ª—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ –¥–∞–Ω–Ω—ã–µ
-----    print("\nüìä –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ One Batch Test:")
-----    train_batch = next(iter(dataloaders["train"]))
-----    val_batch = next(iter(dataloaders["val"]))
-----    
-----    print(f"üìù Train batch shape: {train_batch['data_object'].shape}")
-----    print(f"üìù Val batch shape: {val_batch['data_object'].shape}")
-----    print(f"üìù Train labels: {train_batch['labels']}")
-----    print(f"üìù Val labels: {val_batch['labels']}")
-----    
-----    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–¥–µ–Ω—Ç–∏—á–Ω—ã –ª–∏ –¥–∞–Ω–Ω—ã–µ
-----    data_identical = torch.equal(train_batch['data_object'], val_batch['data_object'])
-----    labels_identical = torch.equal(train_batch['labels'], val_batch['labels'])
-----    
-----    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã: {data_identical}")
-----    print(f"‚úÖ –ú–µ—Ç–∫–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã: {labels_identical}")
-----    
-----    if not (data_identical and labels_identical):
-----        print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –î–∞–Ω–Ω—ã–µ train –∏ val –Ω–µ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã!")
-----    else:
-----        print("üéØ –û—Ç–ª–∏—á–Ω–æ: Train –∏ Val –∏—Å–ø–æ–ª—å–∑—É—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ")
-----    
-----    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
-----    model = instantiate(config.model).to(device)
-----    
-----    # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
-----    total_params = sum(p.numel() for p in model.parameters())
-----    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
-----    print(f"üî¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")
-----    print(f"üéØ –û–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {trainable_params:,}")
-----    
-----    # –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å –∏ –º–µ—Ç—Ä–∏–∫–∏
-----    loss_function = instantiate(config.loss_function).to(device)
-----    metrics = instantiate(config.metrics)
-----    
-----    # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
-----    trainable_params_iter = filter(lambda p: p.requires_grad, model.parameters())
-----    optimizer = instantiate(config.optimizer, params=trainable_params_iter)
-----    lr_scheduler = instantiate(config.lr_scheduler, optimizer=optimizer)
-----    
-----    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
-----    trainer = Trainer(
-----        model=model,
-----        criterion=loss_function,
-----        metrics=metrics,
-----        optimizer=optimizer,
-----        lr_scheduler=lr_scheduler,
-----        config=config,
-----        device=device,
-----        dataloaders=dataloaders,
-----        epoch_len=None,
-----        logger=logger,
-----        writer=writer,
-----        batch_transforms=batch_transforms,
-----        skip_oom=config.trainer.get("skip_oom", True),
-----    )
-----    
-----    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º One Batch Test...")
-----    print("üìà –û–∂–∏–¥–∞–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ:")
-----    print("   - Loss –¥–æ–ª–∂–µ–Ω –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ —É–º–µ–Ω—å—à–∞—Ç—å—Å—è")
-----    print("   - –ß–µ—Ä–µ–∑ 50-100 —ç–ø–æ—Ö loss –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å < 0.01")
-----    print("   - Accuracy –¥–æ–ª–∂–Ω–∞ —Å—Ç—Ä–µ–º–∏—Ç—å—Å—è –∫ 100%")
-----    print("   - EER –¥–æ–ª–∂–Ω–∞ —Å—Ç—Ä–µ–º–∏—Ç—å—Å—è –∫ 0%")
-----    print("-" * 50)
-----    
-----    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
-----    trainer.train()
-----    
-----    print("‚úÖ One Batch Test –∑–∞–≤–µ—Ä—à–µ–Ω!")
-----
-----if __name__ == "__main__":
-----    main() 
----\ No newline at end of file
----diff --git a/src/model/model.py b/src/model/model.py
----index 6ec39da..181862d 100644
------- a/src/model/model.py
----+++ b/src/model/model.py
----@@ -56,6 +56,25 @@ class LCNN(nn.Module):
----             nn.Dropout(0.5),
----             nn.Linear(256, num_classes)
----         )
----+        
----+        # –î–û–ë–ê–í–õ–Ø–ï–ú –ü–†–ê–í–ò–õ–¨–ù–£–Æ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Æ –í–ï–°–û–í
----+        self._init_weights()
----+
----+    def _init_weights(self):
----+        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏"""
----+        print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏...")
----+        for m in self.modules():
----+            if isinstance(m, nn.Conv2d):
----+                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
----+                if m.bias is not None:
----+                    nn.init.constant_(m.bias, 0)
----+            elif isinstance(m, nn.BatchNorm2d):
----+                nn.init.constant_(m.weight, 1)
----+                nn.init.constant_(m.bias, 0)
----+            elif isinstance(m, nn.Linear):
----+                nn.init.normal_(m.weight, 0, 0.01)
----+                nn.init.constant_(m.bias, 0)
----+        print("‚úÖ –í–µ—Å–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
---- 
----     def forward(self, **batch) -> Dict[str, torch.Tensor]:
----         """
----diff --git a/src/trainer/base_trainer_fixed.py b/src/trainer/base_trainer_fixed.py
----deleted file mode 100644
----index 0519ecb..0000000
------- a/src/trainer/base_trainer_fixed.py
----+++ /dev/null
----@@ -1 +0,0 @@
----- 
----\ No newline at end of file
----diff --git a/src/trainer/trainer.py b/src/trainer/trainer.py
----index b5c2173..bacd019 100644
------- a/src/trainer/trainer.py
----+++ b/src/trainer/trainer.py
----@@ -55,8 +55,38 @@ class Trainer(BaseTrainer):
---- 
----         # –û–±–Ω–æ–≤–ª—è–µ–º EER –º–µ—Ç—Ä–∏–∫—É
----         if "logits" in batch:
-----            scores = torch.softmax(batch["logits"], dim=1)[:, 1]
----+            logits = batch["logits"]
----             labels = batch["labels"]
----+            
----+            # –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ª–æ–≥–∏—Ç–æ–≤
----+            if not self.is_train:  # –í–∞–ª–∏–¥–∞—Ü–∏—è
----+                print(f"üîç –õ–û–ì–ò–¢–´ - shape: {logits.shape}")
----+                print(f"üîç –õ–û–ì–ò–¢–´ - min: {logits.min().item():.6f}, max: {logits.max().item():.6f}")
----+                print(f"üîç –õ–û–ì–ò–¢–´ - mean: {logits.mean().item():.6f}, std: {logits.std().item():.6f}")
----+                print(f"üîç –õ–û–ì–ò–¢–´ –ø–µ—Ä–≤—ã–µ 5: {logits[:5].detach().cpu().numpy()}")
----+                
----+            scores = torch.softmax(logits, dim=1)[:, 1]
----+            
----+            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
----+            if not self.is_train:  # –≠—Ç–æ –≤–∞–ª–∏–¥–∞—Ü–∏—è
----+                unique_labels = torch.unique(labels)
----+                score_stats = {
----+                    'min': scores.min().item(),
----+                    'max': scores.max().item(), 
----+                    'mean': scores.mean().item(),
----+                    'std': scores.std().item()
----+                }
----+                print(f"üîç VAL –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê - Labels: {unique_labels.tolist()}")
----+                print(f"üîç SCORES - min={score_stats['min']:.6f}, max={score_stats['max']:.6f}")
----+                print(f"üîç SCORES - mean={score_stats['mean']:.6f}, std={score_stats['std']:.6f}")
----+                print(f"üîç SCORES –ø–µ—Ä–≤—ã–µ 10: {scores[:10].detach().cpu().numpy()}")
----+                print(f"üîç LABELS –ø–µ—Ä–≤—ã–µ 10: {labels[:10].detach().cpu().numpy()}")
----+                
----+                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤
----+                class_0_count = (labels == 0).sum().item()
----+                class_1_count = (labels == 1).sum().item()
----+                print(f"üîç –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï - –∫–ª–∞—Å—Å 0: {class_0_count}, –∫–ª–∞—Å—Å 1: {class_1_count}")
----+            
----             metrics.update_eer(scores, labels)
---- 
----         # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
----diff --git a/src/trainer/trainer_fixed.py b/src/trainer/trainer_fixed.py
----deleted file mode 100644
----index 2010b3b..0000000
------- a/src/trainer/trainer_fixed.py
----+++ /dev/null
----@@ -1,112 +0,0 @@
-----from src.metrics.tracker import MetricTracker
-----from src.trainer.base_trainer import BaseTrainer
-----import torch
-----
-----class Trainer(BaseTrainer):
-----    """
-----    –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–µ—Ä—Å–∏—è Trainer class.
-----    """
-----
-----    def process_batch(self, batch, metrics: MetricTracker):
-----        """
-----        –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏.
-----        """
-----        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
-----        batch = self.move_batch_to_device(batch)
-----        batch = self.transform_batch(batch)
-----
-----        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
-----        metric_funcs = self.metrics["inference"]
-----        if self.is_train:
-----            metric_funcs = self.metrics["train"]
-----            self.optimizer.zero_grad()
-----
-----        # Forward pass —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å
-----        outputs = self.model(**batch)
-----        batch.update(outputs)
-----
-----        # –í—ã—á–∏—Å–ª—è–µ–º loss
-----        all_losses = self.criterion(**batch)
-----        batch.update(all_losses)
-----
-----        # –û–ë–£–ß–ï–ù–ò–ï –¢–û–õ–¨–ö–û –í –¢–†–ï–ù–ò–†–û–í–û–ß–ù–û–ú –†–ï–ñ–ò–ú–ï
-----        if self.is_train:
-----            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ loss –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π
-----            if torch.isnan(batch["loss"]) or torch.isinf(batch["loss"]):
-----                print(f"‚ö†Ô∏è WARNING: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π loss –æ–±–Ω–∞—Ä—É–∂–µ–Ω: {batch['loss'].item()}")
-----                return batch
-----            
-----            # Backward pass
-----            batch["loss"].backward()
-----            
-----            # –û–¢–ö–õ–Æ–ß–ï–ù GRADIENT CLIPPING
-----            # self._clip_grad_norm()  # ‚Üê –û–¢–ö–õ–Æ–ß–ï–ù–û
-----            
-----            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
-----            grad_norm = self._get_grad_norm()
-----            if torch.isnan(grad_norm) or torch.isinf(grad_norm):
-----                print(f"‚ö†Ô∏è WARNING: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã: {grad_norm}")
-----                return batch
-----            
-----            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
-----            self.optimizer.step()
-----            
-----            # LR SCHEDULER –í–´–ó–´–í–ê–ï–¢–°–Ø –í –ö–û–ù–¶–ï –≠–ü–û–•–ò, –ù–ï –ó–î–ï–°–¨!
-----            # if self.lr_scheduler is not None:
-----            #     self.lr_scheduler.step()  # ‚Üê –£–ë–†–ê–ù–û! –≠—Ç–æ –±—ã–ª–∞ –≥–ª–∞–≤–Ω–∞—è –æ—à–∏–±–∫–∞!
-----
-----        # –û–±–Ω–æ–≤–ª—è–µ–º loss –º–µ—Ç—Ä–∏–∫–∏
-----        for loss_name in self.config.writer.loss_names:
-----            if loss_name in batch:
-----                loss_value = batch[loss_name].item()
-----                if not (torch.isnan(torch.tensor(loss_value)) or torch.isinf(torch.tensor(loss_value))):
-----                    metrics.update(loss_name, loss_value)
-----
-----        # –û–±–Ω–æ–≤–ª—è–µ–º EER –º–µ—Ç—Ä–∏–∫—É
-----        if "logits" in batch:
-----            try:
-----                logits = batch["logits"]
-----                labels = batch["labels"]
-----                
-----                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å logits
-----                if torch.isnan(logits).any() or torch.isinf(logits).any():
-----                    print(f"‚ö†Ô∏è WARNING: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ logits")
-----                else:
-----                    scores = torch.softmax(logits, dim=1)[:, 1]
-----                    metrics.update_eer(scores, labels)
-----            except Exception as e:
-----                print(f"‚ö†Ô∏è WARNING: –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ EER: {e}")
-----
-----        # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
-----        for met in metric_funcs:
-----            if met.name != "eer":
-----                try:
-----                    metric_value = met(**batch)
-----                    if not (torch.isnan(torch.tensor(metric_value)) or torch.isinf(torch.tensor(metric_value))):
-----                        metrics.update(met.name, metric_value)
-----                except Exception as e:
-----                    continue
-----
-----        return batch
-----
-----    def _log_batch(self, batch_idx, batch, mode="train"):
-----        """
-----        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞—Ç—á–∞ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏.
-----        """
-----        if self.writer is not None:
-----            # –õ–æ–≥–∏—Ä—É–µ–º learning rate
-----            if mode == "train" and self.lr_scheduler is not None:
-----                try:
-----                    current_lr = self.lr_scheduler.get_last_lr()[0]
-----                    self.writer.add_scalar("learning_rate", current_lr)
-----                except:
-----                    pass
-----            
-----            # –õ–æ–≥–∏—Ä—É–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—É—é –Ω–æ—Ä–º—É
-----            if mode == "train":
-----                try:
-----                    grad_norm = self._get_grad_norm()
-----                    if not (torch.isnan(grad_norm) or torch.isinf(grad_norm)):
-----                        self.writer.add_scalar("grad_norm", grad_norm.item())
-----                except:
-----                    pass 
----\ No newline at end of file
----diff --git a/test_fixes.py b/test_fixes.py
----deleted file mode 100644
----index bd158bd..0000000
------- a/test_fixes.py
----+++ /dev/null
----@@ -1,122 +0,0 @@
-----"""
-----–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –≤ –∫–æ–¥–µ.
-----"""
-----import warnings
-----import hydra
-----import torch
-----from hydra.utils import instantiate
-----from omegaconf import OmegaConf
-----
-----from src.datasets.data_utils import get_dataloaders
-----from src.utils.init_utils import set_random_seed, setup_saving_and_logging
-----
-----warnings.filterwarnings("ignore", category=UserWarning)
-----
-----# –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç—Ä–µ–Ω–µ—Ä
-----from src.trainer.trainer_fixed import Trainer
-----
-----@hydra.main(version_base=None, config_path="src/configs", config_name="baseline")
-----def main(config):
-----    """
-----    –¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π:
-----    1. LR scheduler –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤ –∫–æ–Ω—Ü–µ —ç–ø–æ—Ö–∏
-----    2. Gradient clipping –æ—Ç–∫–ª—é—á–µ–Ω
-----    3. –î–æ–±–∞–≤–ª–µ–Ω—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ NaN/Inf
-----    4. –£–ª—É—á—à–µ–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
-----    """
-----    print("üîß –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è...")
-----    
-----    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º seed
-----    set_random_seed(config.trainer.seed)
-----    
-----    # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è —Ç–µ—Å—Ç–∞
-----    OmegaConf.set_struct(config, False)
-----    config.trainer.n_epochs = 3  # –¢–æ–ª—å–∫–æ 3 —ç–ø–æ—Ö–∏ –¥–ª—è —Ç–µ—Å—Ç–∞
-----    config.trainer.log_step = 10  # –ß–∞—â–µ –ª–æ–≥–∏—Ä—É–µ–º
-----    config.optimizer.lr = 0.001  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π LR
-----    config.writer.run_name = "fixes-test"
-----    OmegaConf.set_struct(config, True)
-----    
-----    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
-----    project_config = OmegaConf.to_container(config)
-----    logger = setup_saving_and_logging(config)
-----    writer = instantiate(config.writer, logger, project_config)
-----    
-----    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
-----    device = "cuda" if torch.cuda.is_available() else "cpu"
-----    print(f"üñ•Ô∏è  –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
-----    
-----    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä—ã
-----    dataloaders, batch_transforms = get_dataloaders(config, device, debug_mode=False)
-----    
-----    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
-----    model = instantiate(config.model).to(device)
-----    print(f"üî¢ –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –º–æ–¥–µ–ª–∏: {sum(p.numel() for p in model.parameters()):,}")
-----    
-----    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
-----    loss_function = instantiate(config.loss_function).to(device)
-----    metrics = instantiate(config.metrics)
-----    
-----    # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
-----    trainable_params = filter(lambda p: p.requires_grad, model.parameters())
-----    optimizer = instantiate(config.optimizer, params=trainable_params)
-----    lr_scheduler = instantiate(config.lr_scheduler, optimizer=optimizer)
-----    
-----    print(f"üìâ –ù–∞—á–∞–ª—å–Ω—ã–π LR: {lr_scheduler.get_last_lr()[0]}")
-----    print(f"üìÖ LR scheduler: —É–º–µ–Ω—å—à–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ {config.lr_scheduler.step_size} —ç–ø–æ—Ö –Ω–∞ {config.lr_scheduler.gamma}")
-----    
-----    # –°–æ–∑–¥–∞–µ–º –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —Ç—Ä–µ–Ω–µ—Ä
-----    trainer = Trainer(
-----        model=model,
-----        criterion=loss_function,
-----        metrics=metrics,
-----        optimizer=optimizer,
-----        lr_scheduler=lr_scheduler,
-----        config=config,
-----        device=device,
-----        dataloaders=dataloaders,
-----        epoch_len=None,
-----        logger=logger,
-----        writer=writer,
-----        batch_transforms=batch_transforms,
-----        skip_oom=True,
-----    )
-----    
-----    print("\nüöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏...")
-----    print("üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:")
-----    print("   ‚úÖ LR scheduler –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω –≤ –∫–æ–Ω–µ—Ü —ç–ø–æ—Ö–∏")
-----    print("   ‚úÖ Gradient clipping –æ—Ç–∫–ª—é—á–µ–Ω")
-----    print("   ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ NaN/Inf")
-----    print("   ‚úÖ –£–ª—É—á—à–µ–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ")
-----    print("-" * 50)
-----    
-----    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–¥–∏–Ω –±–∞—Ç—á –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
-----    print("\nüß™ –¢–µ—Å—Ç –æ–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞:")
-----    train_dataloader = dataloaders["train"]
-----    batch = next(iter(train_dataloader))
-----    
-----    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
-----    print(f"üìä –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch['data_object'].shape}")
-----    print(f"üìä –ú–µ—Ç–∫–∏: {batch['labels'].shape}, —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ: {torch.unique(batch['labels'])}")
-----    
-----    # –¢–µ—Å—Ç–∏—Ä—É–µ–º forward pass
-----    model.eval()
-----    with torch.no_grad():
-----        batch = trainer.move_batch_to_device(batch)
-----        batch = trainer.transform_batch(batch)
-----        outputs = model(**batch)
-----        loss_dict = loss_function(**{**batch, **outputs})
-----        
-----        print(f"üìä Logits shape: {outputs['logits'].shape}")
-----        print(f"üìä Loss: {loss_dict['loss'].item():.6f}")
-----        print(f"üìä Logits range: [{outputs['logits'].min().item():.4f}, {outputs['logits'].max().item():.4f}]")
-----    
-----    print("\n‚úÖ –¢–µ—Å—Ç –æ–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞ –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ!")
-----    
-----    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
-----    trainer.train()
-----    
-----    print("\n‚úÖ –¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω!")
-----
-----if __name__ == "__main__":
-----    main() 
----\ No newline at end of file
--diff --git a/src/transforms/normalize.py b/src/transforms/normalize.py
--index 38aa0d3..9e03473 100644
----- a/src/transforms/normalize.py
--+++ b/src/transforms/normalize.py
--@@ -8,15 +8,15 @@ class Normalize(nn.Module):
-- 
--     def __init__(self, mean, std):
--         super().__init__()
---        self.mean = torch.tensor(mean).view(1, -1, 1, 1)
---        self.std = torch.tensor(std).view(1, -1, 1, 1)
--+        self.mean = torch.tensor(mean)
--+        self.std = torch.tensor(std)
-- 
--     def forward(self, x):
--         """
--         –ü—Ä–∏–º–µ–Ω—è–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é.
--         
--         Args:
---            x (torch.Tensor): –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä [batch_size, channels, height, width]
--+            x (torch.Tensor): –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä –ª—é–±–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
--             
--         Returns:
--             torch.Tensor: –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä
--@@ -25,4 +25,15 @@ class Normalize(nn.Module):
--         mean = self.mean.to(device)
--         std = self.std.to(device)
--         
--+        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ mean –∏ std –ø–æ–¥ –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä
--+        if x.dim() == 4:  # [batch, channels, height, width]
--+            mean = mean.view(1, -1, 1, 1)
--+            std = std.view(1, -1, 1, 1)
--+        elif x.dim() == 3:  # [batch, freq, time] - –Ω–∞—à —Å–ª—É—á–∞–π –ø–æ—Å–ª–µ STFT
--+            mean = mean.view(1, 1, 1) if len(mean) == 1 else mean.view(1, -1, 1)
--+            std = std.view(1, 1, 1) if len(std) == 1 else std.view(1, -1, 1)
--+        elif x.dim() == 2:  # [batch, features]
--+            mean = mean.view(1, -1)
--+            std = std.view(1, -1)
--+        
--         return (x - mean) / std
--\ No newline at end of file
-diff --git a/src/trainer/base_trainer.py b/src/trainer/base_trainer.py
-index ff77b50..e27829d 100644
---- a/src/trainer/base_trainer.py
-+++ b/src/trainer/base_trainer.py
-@@ -496,13 +496,14 @@ class BaseTrainer:
-                 the dataloader (possibly transformed via batch transform).
-         """
-         # do batch transforms on device
--        transform_type = "train" if self.is_train else "inference"
--        transforms = self.batch_transforms.get(transform_type)
--        if transforms is not None:
--            for transform_name in transforms.keys():
--                batch[transform_name] = transforms[transform_name](
--                    batch[transform_name]
--                )
-+        if self.batch_transforms is not None:
-+            transform_type = "train" if self.is_train else "inference"
-+            transforms = self.batch_transforms.get(transform_type)
-+            if transforms is not None:
-+                for transform_name in transforms.keys():
-+                    batch[transform_name] = transforms[transform_name](
-+                        batch[transform_name]
-+                    )
-         return batch
- 
-     def _clip_grad_norm(self):
diff --git a/src/metrics/tracker.py b/src/metrics/tracker.py
index d353d72..4d349a5 100644
--- a/src/metrics/tracker.py
+++ b/src/metrics/tracker.py
@@ -33,8 +33,10 @@ class MetricTracker:
         for col in self._data.columns:
             self._data[col].values[:] = 0
         
+        # –°–±—Ä–æ—Å EER –¥–∞–Ω–Ω—ã—Ö
         self._eer_scores = []
         self._eer_labels = []
+        print(f"üîÑ MetricTracker —Å–±—Ä–æ—à–µ–Ω. EER lists –æ—á–∏—â–µ–Ω—ã.")
 
     def update(self, key, value, n=1):
         
@@ -44,24 +46,61 @@ class MetricTracker:
         self._data.loc[key, "average"] = self._data.total[key] / self._data.counts[key]
 
     def update_eer(self, scores, labels):
-     
-
-        self._eer_scores.extend(scores.detach().cpu().numpy())
-        self._eer_labels.extend(labels.detach().cpu().numpy())
+        """
+        Update EER scores and labels.
+        
+        Args:
+            scores (torch.Tensor): prediction scores
+            labels (torch.Tensor): ground truth labels
+        """
+        if scores.numel() == 0 or labels.numel() == 0:
+            print(f"‚ö†Ô∏è update_eer: –ø–æ–ª—É—á–µ–Ω—ã –ø—É—Å—Ç—ã–µ —Ç–µ–Ω–∑–æ—Ä—ã")
+            return
+            
+        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy
+        scores_np = scores.detach().cpu().numpy().flatten()
+        labels_np = labels.detach().cpu().numpy().flatten()
+        
+        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–∞–∑–º–µ—Ä—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç
+        if len(scores_np) != len(labels_np):
+            print(f"‚ö†Ô∏è update_eer: —Ä–∞–∑–º–µ—Ä—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç scores={len(scores_np)}, labels={len(labels_np)}")
+            return
+        
+        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
+        if np.any(np.isnan(scores_np)) or np.any(np.isinf(scores_np)):
+            print(f"‚ö†Ô∏è update_eer: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ scores (nan/inf)")
+            return
+            
+        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
+        self._eer_scores.extend(scores_np)
+        self._eer_labels.extend(labels_np)
 
     def compute_eer(self):
         """
         Compute Equal Error Rate from accumulated scores and labels.
         """
-        if not self._eer_scores:
+        if not self._eer_scores or len(self._eer_scores) == 0:
+            print(f"‚ö†Ô∏è compute_eer: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è EER")
             return 0.0
         
         scores = np.array(self._eer_scores)
         labels = np.array(self._eer_labels)
         
-
+        print(f"üßÆ –í—ã—á–∏—Å–ª—è–µ–º EER: {len(scores)} —Å–µ–º–ø–ª–æ–≤")
+        print(f"    –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ labels: {np.unique(labels)}")
+        print(f"    Scores range: {scores.min():.4f} - {scores.max():.4f}")
+        
+        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å –æ–±–∞ –∫–ª–∞—Å—Å–∞
+        unique_labels = np.unique(labels)
+        if len(unique_labels) < 2:
+            print(f"‚ö†Ô∏è compute_eer: —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–ª–∞—Å—Å {unique_labels}")
+            return 0.0
+        
         # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
         thresholds = np.unique(scores)
+        if len(thresholds) < 2:
+            print(f"‚ö†Ô∏è compute_eer: –≤—Å–µ scores –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ")
+            return 0.5  # Random baseline
         
         # –í—ã—á–∏—Å–ª—è–µ–º FAR –∏ FRR –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ä–æ–≥–∞
         far_values = []
@@ -95,6 +134,8 @@ class MetricTracker:
         # EER - —ç—Ç–æ —Å—Ä–µ–¥–Ω–µ–µ FAR –∏ FRR –≤ —ç—Ç–æ–π —Ç–æ—á–∫–µ
         eer = (far_values[min_idx] + frr_values[min_idx]) / 2
         
+        print(f"‚úÖ EER –≤—ã—á–∏—Å–ª–µ–Ω: {eer:.6f} (FAR={far_values[min_idx]:.6f}, FRR={frr_values[min_idx]:.6f})")
+        
         return float(eer)
 
     def avg(self, key):
@@ -119,8 +160,8 @@ class MetricTracker:
                 for each metric name.
         """
         result = dict(self._data.average)
-        if self._eer_scores:
-            result['eer'] = self.compute_eer()
+        # –í—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–∞–µ–º EER –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
+        result['eer'] = self.compute_eer()
         return result
 
     def keys(self):
diff --git a/src/model/model.py b/src/model/model.py
index cc6e4f7..9a74bb0 100644
--- a/src/model/model.py
+++ b/src/model/model.py
@@ -93,12 +93,16 @@ class LCNN(nn.Module):
             # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ç–µ–Ω–∑–æ—Ä –∏–∑ –±–∞—Ç—á–∞
             x = next(iter(batch.values()))
         
+        print(f"üîç –ú–æ–¥–µ–ª—å –ø–æ–ª—É—á–∏–ª–∞: x.shape={x.shape}")
+        
         # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ñ–æ—Ä–º—É
         if x.dim() == 3:
             x = x.unsqueeze(1)  # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–∞–ª
         elif x.dim() == 2:
             x = x.unsqueeze(0).unsqueeze(0)  # –î–æ–±–∞–≤–ª—è–µ–º batch –∏ –∫–∞–Ω–∞–ª
         
+        print(f"üîç –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: x.shape={x.shape}")
+        
         # –ü—Ä–æ—Ö–æ–¥–∏–º —á–µ—Ä–µ–∑ —Å–ª–æ–∏
         x = self.features(x)
         
@@ -107,6 +111,8 @@ class LCNN(nn.Module):
         
         x = self.classifier(x)
         
+        print(f"üîç –õ–æ–≥–∏—Ç—ã: x.shape={x.shape}, range=[{x.min().item():.3f}, {x.max().item():.3f}]")
+        
         # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—ã—Ö–æ–¥—ã
         outputs = {
             'logits': x
diff --git a/src/trainer/base_trainer.py b/src/trainer/base_trainer.py
index e27829d..a9582de 100644
--- a/src/trainer/base_trainer.py
+++ b/src/trainer/base_trainer.py
@@ -240,6 +240,7 @@ class BaseTrainer:
                 batch = self.process_batch(
                     batch,
                     metrics=self.train_metrics,
+                    metric_funcs=self.metrics["train"],
                 )
             except torch.cuda.OutOfMemoryError as e:
                 if self.skip_oom:
@@ -337,6 +338,7 @@ class BaseTrainer:
                 batch = self.process_batch(
                     batch,
                     metrics=self.evaluation_metrics,
+                    metric_funcs=self.metrics["inference"],
                 )
             # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ —à–∞–≥–∞–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —É–±—Ä–∞–Ω–æ - –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ _run_validation
             # —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø—Ä–µ—Ñ–∏–∫—Å–∞–º–∏ –∏ step –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
diff --git a/src/trainer/trainer.py b/src/trainer/trainer.py
index 0f5996d..4bf8b2e 100644
--- a/src/trainer/trainer.py
+++ b/src/trainer/trainer.py
@@ -7,43 +7,32 @@ class Trainer(BaseTrainer):
     Trainer class. Defines the logic of batch logging and processing.
     """
 
-    def process_batch(self, batch, metrics: MetricTracker):
+    def process_batch(self, batch, metrics: MetricTracker, metric_funcs):
         """
-        Run batch through the model, compute metrics, compute loss,
-        and do training step (during training stage).
-
-        The function expects that criterion aggregates all losses
-        (if there are many) into a single one defined in the 'loss' key.
+        Run batch through the model, compute metrics, and update the tracker.
 
         Args:
             batch (dict): dict-based batch containing the data from
                 the dataloader.
-            metrics (MetricTracker): MetricTracker object that computes
-                and aggregates the metrics. The metrics depend on the type of
-                the partition (train or inference).
+            metrics (MetricTracker): tracker that aggregates metrics
+                over the dataset.
+            metric_funcs (list): functions that computes metrics.
+
         Returns:
             batch (dict): dict-based batch containing the data from
-                the dataloader (possibly transformed via batch transform),
-                model outputs, and losses.
+                the dataloader (possibly transformed via batch transform).
         """
         batch = self.move_batch_to_device(batch)
-        batch = self.transform_batch(batch)  # transform batch on device -- faster
-
-
-
-        metric_funcs = self.metrics["inference"]
+        batch = self.transform_batch(batch)
+        
+        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
         if self.is_train:
-            metric_funcs = self.metrics["train"]
             self.optimizer.zero_grad()
+        
+        batch.update(self.model(**batch))
+        batch.update(self.criterion(**batch))
 
-        outputs = self.model(**batch)
-        batch.update(outputs)
-
-
-        all_losses = self.criterion(**batch)
-        batch.update(all_losses)
-
-
+        # –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤
         if self.is_train:
             batch["loss"].backward()
             self._clip_grad_norm()
@@ -51,25 +40,38 @@ class Trainer(BaseTrainer):
             if self.lr_scheduler is not None:
                 self.lr_scheduler.step()
 
-       
+        # Update loss metrics
         for loss_name in self.config.writer.loss_names:
             metrics.update(loss_name, batch[loss_name].item())
 
-        
-        if "logits" in batch:
-            scores = torch.softmax(batch["logits"], dim=1)[:, 1]
+        # –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –í–´–ß–ò–°–õ–ï–ù–ò–ï EER
+        if "logits" in batch and "labels" in batch:
+            logits = batch["logits"]
             labels = batch["labels"]
             
-            metrics.update_eer(scores, labels)
-
-      
+            # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Ä–∞–∑–º–µ—Ä—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
+            if logits.dim() == 2 and logits.size(1) >= 2:
+                # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–ª–∞—Å—Å–∞ spoof (–∫–ª–∞—Å—Å 1)
+                scores = torch.softmax(logits, dim=1)[:, 1]
+                
+                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
+                if scores.numel() > 0 and labels.numel() > 0:
+                    metrics.update_eer(scores, labels)
+                else:
+                    print(f"‚ö†Ô∏è –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è EER: scores.numel()={scores.numel()}, labels.numel()={labels.numel()}")
+            else:
+                print(f"‚ö†Ô∏è –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã logits: {logits.shape}")
+        else:
+            print(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–ª—é—á–∏: logits={('logits' in batch)}, labels={('labels' in batch)}")
+
+        # Update other metrics
         for met in metric_funcs:
             if met.name != "eer":
                 try:
                     metrics.update(met.name, met(**batch))
                 except Exception as e:
-                    print(f"–û—à–∏–±–∫–∞ –≤ –º–µ—Ç—Ä–∏–∫–µ {met.name}: {e}")
-                    continue
+                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –º–µ—Ç—Ä–∏–∫–µ {met.name}: {e}")
+
         return batch
 
     def _log_batch(self, batch_idx, batch, mode="train"):
