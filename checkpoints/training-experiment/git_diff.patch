diff --git a/.gitignore b/.gitignore
index 8904069..0520bc9 100644
--- a/.gitignore
+++ b/.gitignore
@@ -102,7 +102,7 @@ ENV/
 .mypy_cache/
 
 # input data, saved log, checkpoints, hydra outputs
-data/*/
+data/ASVspoof2019_LA_*/
 data/*.flac
 data/*.wav
 data/*.mp3
diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
index 8d7993e..9877dd8 100644
--- a/checkpoints/training-experiment/config.yaml
+++ b/checkpoints/training-experiment/config.yaml
@@ -2,7 +2,7 @@ data_path: ${oc.env:DATA_PATH,data}
 project_name: anti-spoofing
 run_name: baseline-experiment
 model:
-  _target_: src.model.model.LCNN_LSTM_Sum
+  _target_: src.model.model.LCNN
   num_classes: 2
   dropout_rate: 0.3
 optimizer:
@@ -84,7 +84,7 @@ writer:
   _target_: src.logger.cometml.CometMLWriter
   project_name: anti-spoofing
   workspace: null
-  run_id: qfsbq71k
+  run_id: olzi2zjh
   run_name: training-experiment
   mode: online
   loss_names:
@@ -96,7 +96,7 @@ trainer:
   seed: 42
   device: auto
   n_epochs: 100
-  save_period: 10
+  save_period: 5
   val_period: 1
   skip_oom: true
   max_grad_norm: 0.5
diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
index d82bfd5..ba570a2 100644
--- a/checkpoints/training-experiment/git_commit.txt
+++ b/checkpoints/training-experiment/git_commit.txt
@@ -1 +1 @@
-4d62c78787a075e277ee56197ddf8844ebc17ca6
+18fcd0da6c9ec2c93fd24773f9f9ce0248a1368b
diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
index a3490e8..e69de29 100644
--- a/checkpoints/training-experiment/git_diff.patch
+++ b/checkpoints/training-experiment/git_diff.patch
@@ -1,8807 +0,0 @@
-diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
-index 7d20c5e..8d7993e 100644
---- a/checkpoints/training-experiment/config.yaml
-+++ b/checkpoints/training-experiment/config.yaml
-@@ -2,12 +2,12 @@ data_path: ${oc.env:DATA_PATH,data}
- project_name: anti-spoofing
- run_name: baseline-experiment
- model:
--  _target_: src.model.model.LCNN
-+  _target_: src.model.model.LCNN_LSTM_Sum
-   num_classes: 2
-   dropout_rate: 0.3
- optimizer:
-   _target_: torch.optim.Adam
--  lr: 0.001
-+  lr: 0.0001
-   weight_decay: 0.0001
- lr_scheduler:
-   _target_: torch.optim.lr_scheduler.StepLR
-@@ -46,17 +46,21 @@ datasets:
-     instance_transforms: ${transforms.instance_transforms}
- dataloader:
-   _target_: torch.utils.data.DataLoader
--  batch_size: 16
-+  batch_size: 32
-   num_workers: 4
-   pin_memory: true
- transforms:
-   instance_transforms:
--    data_object: ${transforms.stft}
--  stft:
--    _target_: src.transforms.stft.STFTTransform
--    n_fft: 1724
--    hop_length: 256
--    win_length: 1724
-+    data_object: ${transforms.lfcc}
-+  lfcc:
-+    _target_: src.transforms.lfcc.LFCCTransform
-+    sample_rate: 16000
-+    n_fft: 512
-+    hop_length: 160
-+    win_length: 320
-+    n_filter: 20
-+    n_lfcc: 20
-+    use_deltas: true
-   batch_transforms:
-     train:
-       data_object:
-@@ -80,7 +84,7 @@ writer:
-   _target_: src.logger.cometml.CometMLWriter
-   project_name: anti-spoofing
-   workspace: null
--  run_id: 4eydlkzn
-+  run_id: qfsbq71k
-   run_name: training-experiment
-   mode: online
-   loss_names:
-diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
-index c96acde..d82bfd5 100644
---- a/checkpoints/training-experiment/git_commit.txt
-+++ b/checkpoints/training-experiment/git_commit.txt
-@@ -1 +1 @@
--deddc98048e0baac61aef55be45f15660179b0ef
-+4d62c78787a075e277ee56197ddf8844ebc17ca6
-diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
-index 8debb1f..e69de29 100644
---- a/checkpoints/training-experiment/git_diff.patch
-+++ b/checkpoints/training-experiment/git_diff.patch
-@@ -1,7650 +0,0 @@
--diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
--index 3838088..7d20c5e 100644
----- a/checkpoints/training-experiment/config.yaml
--+++ b/checkpoints/training-experiment/config.yaml
--@@ -80,7 +80,7 @@ writer:
--   _target_: src.logger.cometml.CometMLWriter
--   project_name: anti-spoofing
--   workspace: null
---  run_id: 6u1wnpk7
--+  run_id: 4eydlkzn
--   run_name: training-experiment
--   mode: online
--   loss_names:
--diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
--index c2cff0d..c96acde 100644
----- a/checkpoints/training-experiment/git_commit.txt
--+++ b/checkpoints/training-experiment/git_commit.txt
--@@ -1 +1 @@
---1c8677ce9872ee5b010a4862958ff50e4236fc3c
--+deddc98048e0baac61aef55be45f15660179b0ef
--diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
--index c0a9298..e69de29 100644
----- a/checkpoints/training-experiment/git_diff.patch
--+++ b/checkpoints/training-experiment/git_diff.patch
--@@ -1,7254 +0,0 @@
---diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
---index dd3f941..3838088 100644
------ a/checkpoints/training-experiment/config.yaml
---+++ b/checkpoints/training-experiment/config.yaml
---@@ -80,7 +80,7 @@ writer:
---   _target_: src.logger.cometml.CometMLWriter
---   project_name: anti-spoofing
---   workspace: null
----  run_id: fiztlom7
---+  run_id: 6u1wnpk7
---   run_name: training-experiment
---   mode: online
---   loss_names:
---diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
---index 360608f..c2cff0d 100644
------ a/checkpoints/training-experiment/git_commit.txt
---+++ b/checkpoints/training-experiment/git_commit.txt
---@@ -1 +1 @@
----8429b2c1716cce76e021ca76bf91458225feb720
---+1c8677ce9872ee5b010a4862958ff50e4236fc3c
---diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
---index 60e0e80..e69de29 100644
------ a/checkpoints/training-experiment/git_diff.patch
---+++ b/checkpoints/training-experiment/git_diff.patch
---@@ -1,7158 +0,0 @@
----diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
----index 75af4b3..dd3f941 100644
------- a/checkpoints/training-experiment/config.yaml
----+++ b/checkpoints/training-experiment/config.yaml
----@@ -4,6 +4,7 @@ run_name: baseline-experiment
---- model:
----   _target_: src.model.model.LCNN
----   num_classes: 2
----+  dropout_rate: 0.3
---- optimizer:
----   _target_: torch.optim.Adam
----   lr: 0.001
----@@ -53,9 +54,9 @@ transforms:
----     data_object: ${transforms.stft}
----   stft:
----     _target_: src.transforms.stft.STFTTransform
-----    n_fft: 1024
-----    hop_length: 512
-----    win_length: 1024
----+    n_fft: 1724
----+    hop_length: 256
----+    win_length: 1724
----   batch_transforms:
----     train:
----       data_object:
----@@ -79,7 +80,7 @@ writer:
----   _target_: src.logger.cometml.CometMLWriter
----   project_name: anti-spoofing
----   workspace: null
-----  run_id: ts0gp052
----+  run_id: fiztlom7
----   run_name: training-experiment
----   mode: online
----   loss_names:
----diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
----index 4e48bcf..360608f 100644
------- a/checkpoints/training-experiment/git_commit.txt
----+++ b/checkpoints/training-experiment/git_commit.txt
----@@ -1 +1 @@
-----0e04a3adc980152fdfdd5a33441b94b650140ad8
----+8429b2c1716cce76e021ca76bf91458225feb720
----diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
----index e07741d..e69de29 100644
------- a/checkpoints/training-experiment/git_diff.patch
----+++ b/checkpoints/training-experiment/git_diff.patch
----@@ -1,6354 +0,0 @@
-----diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
-----index c5597d0..75af4b3 100644
-------- a/checkpoints/training-experiment/config.yaml
-----+++ b/checkpoints/training-experiment/config.yaml
-----@@ -56,12 +56,30 @@ transforms:
-----     n_fft: 1024
-----     hop_length: 512
-----     win_length: 1024
------  batch_transforms: null
-----+  batch_transforms:
-----+    train:
-----+      data_object:
-----+        _target_: torch.nn.Sequential
-----+        _args_:
-----+        - _target_: src.transforms.normalize.Normalize
-----+          mean:
-----+          - 0.0
-----+          std:
-----+          - 1.0
-----+    inference:
-----+      data_object:
-----+        _target_: torch.nn.Sequential
-----+        _args_:
-----+        - _target_: src.transforms.normalize.Normalize
-----+          mean:
-----+          - 0.0
-----+          std:
-----+          - 1.0
----- writer:
-----   _target_: src.logger.cometml.CometMLWriter
-----   project_name: anti-spoofing
-----   workspace: null
------  run_id: utkesn2x
-----+  run_id: ts0gp052
-----   run_name: training-experiment
-----   mode: online
-----   loss_names:
-----diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
-----index 1629df9..4e48bcf 100644
-------- a/checkpoints/training-experiment/git_commit.txt
-----+++ b/checkpoints/training-experiment/git_commit.txt
-----@@ -1 +1 @@
------a01b6b6e5b38bba1618e4cc0990aeaa1cd9b49e3
-----+0e04a3adc980152fdfdd5a33441b94b650140ad8
-----diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
-----index 55f8f61..e69de29 100644
-------- a/checkpoints/training-experiment/git_diff.patch
-----+++ b/checkpoints/training-experiment/git_diff.patch
-----@@ -1,6042 +0,0 @@
------diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
------index 3cf1d33..c5597d0 100644
--------- a/checkpoints/training-experiment/config.yaml
------+++ b/checkpoints/training-experiment/config.yaml
------@@ -56,30 +56,12 @@ transforms:
------     n_fft: 1024
------     hop_length: 512
------     win_length: 1024
-------  batch_transforms:
-------    train:
-------      data_object:
-------        _target_: torch.nn.Sequential
-------        _args_:
-------        - _target_: src.transforms.normalize.Normalize
-------          mean:
-------          - 0.0
-------          std:
-------          - 1.0
-------    inference:
-------      data_object:
-------        _target_: torch.nn.Sequential
-------        _args_:
-------        - _target_: src.transforms.normalize.Normalize
-------          mean:
-------          - 0.0
-------          std:
-------          - 1.0
------+  batch_transforms: null
------ writer:
------   _target_: src.logger.cometml.CometMLWriter
------   project_name: anti-spoofing
------   workspace: null
-------  run_id: nqsnxyzf
------+  run_id: utkesn2x
------   run_name: training-experiment
------   mode: online
------   loss_names:
------diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
------index 4414b1a..1629df9 100644
--------- a/checkpoints/training-experiment/git_commit.txt
------+++ b/checkpoints/training-experiment/git_commit.txt
------@@ -1 +1 @@
-------eb7eddd715700b14a9ab2401d74687a66d57e3a7
------+a01b6b6e5b38bba1618e4cc0990aeaa1cd9b49e3
------diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
------index b2faf66..e69de29 100644
--------- a/checkpoints/training-experiment/git_diff.patch
------+++ b/checkpoints/training-experiment/git_diff.patch
------@@ -1,5967 +0,0 @@
-------diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
-------index 3b8a319..3cf1d33 100644
---------- a/checkpoints/training-experiment/config.yaml
-------+++ b/checkpoints/training-experiment/config.yaml
-------@@ -3,9 +3,7 @@ project_name: anti-spoofing
------- run_name: baseline-experiment
------- model:
-------   _target_: src.model.model.LCNN
--------  in_channels: 1
-------   num_classes: 2
--------  dropout_p: 0.3
------- optimizer:
-------   _target_: torch.optim.Adam
-------   lr: 0.001
-------@@ -81,7 +79,7 @@ writer:
-------   _target_: src.logger.cometml.CometMLWriter
-------   project_name: anti-spoofing
-------   workspace: null
--------  run_id: f4xa9zkq
-------+  run_id: nqsnxyzf
-------   run_name: training-experiment
-------   mode: online
-------   loss_names:
-------diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
-------index c037239..4414b1a 100644
---------- a/checkpoints/training-experiment/git_commit.txt
-------+++ b/checkpoints/training-experiment/git_commit.txt
-------@@ -1 +1 @@
--------7c5d3eb562d7332313b4686c1bb511bb5017fcd8
-------+eb7eddd715700b14a9ab2401d74687a66d57e3a7
-------diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
-------index cef6d7c..e69de29 100644
---------- a/checkpoints/training-experiment/git_diff.patch
-------+++ b/checkpoints/training-experiment/git_diff.patch
-------@@ -1,5892 +0,0 @@
--------diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
--------index 5db7cd5..3b8a319 100644
----------- a/checkpoints/training-experiment/config.yaml
--------+++ b/checkpoints/training-experiment/config.yaml
--------@@ -81,7 +81,7 @@ writer:
--------   _target_: src.logger.cometml.CometMLWriter
--------   project_name: anti-spoofing
--------   workspace: null
---------  run_id: yb3v9d2o
--------+  run_id: f4xa9zkq
--------   run_name: training-experiment
--------   mode: online
--------   loss_names:
--------diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
--------index 0f1c783..c037239 100644
----------- a/checkpoints/training-experiment/git_commit.txt
--------+++ b/checkpoints/training-experiment/git_commit.txt
--------@@ -1 +1 @@
---------4fe20f80ed4eb85bcdf9b7ce5ed09fd0e9add960
--------+7c5d3eb562d7332313b4686c1bb511bb5017fcd8
--------diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
--------index d0254e5..e69de29 100644
----------- a/checkpoints/training-experiment/git_diff.patch
--------+++ b/checkpoints/training-experiment/git_diff.patch
--------@@ -1,5867 +0,0 @@
---------diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
---------index ef54f64..5db7cd5 100644
------------ a/checkpoints/training-experiment/config.yaml
---------+++ b/checkpoints/training-experiment/config.yaml
---------@@ -81,7 +81,7 @@ writer:
---------   _target_: src.logger.cometml.CometMLWriter
---------   project_name: anti-spoofing
---------   workspace: null
----------  run_id: iclj2rnz
---------+  run_id: yb3v9d2o
---------   run_name: training-experiment
---------   mode: online
---------   loss_names:
---------diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
---------index 8e2cf6b..0f1c783 100644
------------ a/checkpoints/training-experiment/git_commit.txt
---------+++ b/checkpoints/training-experiment/git_commit.txt
---------@@ -1 +1 @@
----------bcae19d4a636ee82f9e1d511b00aefa30659a778
---------+4fe20f80ed4eb85bcdf9b7ce5ed09fd0e9add960
---------diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
---------index cd79149..e69de29 100644
------------ a/checkpoints/training-experiment/git_diff.patch
---------+++ b/checkpoints/training-experiment/git_diff.patch
---------@@ -1,5382 +0,0 @@
----------diff --git a/checkpoints/training-experiment/config.yaml b/checkpoints/training-experiment/config.yaml
----------index 3c497ad..ef54f64 100644
------------- a/checkpoints/training-experiment/config.yaml
----------+++ b/checkpoints/training-experiment/config.yaml
----------@@ -81,7 +81,7 @@ writer:
----------   _target_: src.logger.cometml.CometMLWriter
----------   project_name: anti-spoofing
----------   workspace: null
-----------  run_id: v1dyvkfa
----------+  run_id: iclj2rnz
----------   run_name: training-experiment
----------   mode: online
----------   loss_names:
----------diff --git a/checkpoints/training-experiment/git_commit.txt b/checkpoints/training-experiment/git_commit.txt
----------index 165b62c..8e2cf6b 100644
------------- a/checkpoints/training-experiment/git_commit.txt
----------+++ b/checkpoints/training-experiment/git_commit.txt
----------@@ -1 +1 @@
-----------c20e974732a6ccdc523dd9e05876fe4dce43faaa
----------+bcae19d4a636ee82f9e1d511b00aefa30659a778
----------diff --git a/checkpoints/training-experiment/git_diff.patch b/checkpoints/training-experiment/git_diff.patch
----------index a99d21c..e69de29 100644
------------- a/checkpoints/training-experiment/git_diff.patch
----------+++ b/checkpoints/training-experiment/git_diff.patch
----------@@ -1,5357 +0,0 @@
-----------diff --git a/checkpoints/inference-test/config.yaml b/checkpoints/inference-test/config.yaml
-----------index 2f2b128..aec7cc4 100644
-------------- a/checkpoints/inference-test/config.yaml
-----------+++ b/checkpoints/inference-test/config.yaml
-----------@@ -81,7 +81,7 @@ writer:
-----------   _target_: src.logger.cometml.CometMLWriter
-----------   project_name: anti-spoofing
-----------   workspace: null
------------  run_id: j9yzgmw7
-----------+  run_id: kitttsun
-----------   run_name: inference-test
-----------   mode: online
-----------   loss_names:
-----------@@ -97,11 +97,12 @@ trainer:
-----------   val_period: 1
-----------   skip_oom: true
-----------   max_grad_norm: 0.5
------------  log_step: 50
-----------+  log_step: 1
-----------   save_dir: checkpoints
-----------   device_tensors:
-----------   - data_object
-----------   - labels
-----------   monitor: min val_eer
------------  early_stop: 20
-----------+  early_stop: 200
-----------   override: true
-----------+debug_mode: true
-----------diff --git a/checkpoints/inference-test/git_commit.txt b/checkpoints/inference-test/git_commit.txt
-----------index abf19c1..165b62c 100644
-------------- a/checkpoints/inference-test/git_commit.txt
-----------+++ b/checkpoints/inference-test/git_commit.txt
-----------@@ -1 +1 @@
------------1893ddb730be2c6661117bf39596d81a90087a8f
-----------+c20e974732a6ccdc523dd9e05876fe4dce43faaa
-----------diff --git a/checkpoints/inference-test/git_diff.patch b/checkpoints/inference-test/git_diff.patch
-----------index 00d44c3..555d2c6 100644
-------------- a/checkpoints/inference-test/git_diff.patch
-----------+++ b/checkpoints/inference-test/git_diff.patch
-----------@@ -1,1031 +1,2311 @@
----------- diff --git a/checkpoints/inference-test/config.yaml b/checkpoints/inference-test/config.yaml
------------index 61adced..2f2b128 100644
-----------+index 2f2b128..aec7cc4 100644
----------- --- a/checkpoints/inference-test/config.yaml
----------- +++ b/checkpoints/inference-test/config.yaml
----------- @@ -81,7 +81,7 @@ writer:
-----------    _target_: src.logger.cometml.CometMLWriter
-----------    project_name: anti-spoofing
-----------    workspace: null
-------------  run_id: 8gzucarc
------------+  run_id: j9yzgmw7
-----------+-  run_id: j9yzgmw7
-----------++  run_id: kitttsun
-----------    run_name: inference-test
-----------    mode: online
-----------    loss_names:
-----------+@@ -97,11 +97,12 @@ trainer:
-----------+   val_period: 1
-----------+   skip_oom: true
-----------+   max_grad_norm: 0.5
-----------+-  log_step: 50
-----------++  log_step: 1
-----------+   save_dir: checkpoints
-----------+   device_tensors:
-----------+   - data_object
-----------+   - labels
-----------+   monitor: min val_eer
-----------+-  early_stop: 20
-----------++  early_stop: 200
-----------+   override: true
-----------++debug_mode: true
----------- diff --git a/checkpoints/inference-test/git_commit.txt b/checkpoints/inference-test/git_commit.txt
------------index 24ff1b6..abf19c1 100644
-----------+index abf19c1..165b62c 100644
----------- --- a/checkpoints/inference-test/git_commit.txt
----------- +++ b/checkpoints/inference-test/git_commit.txt
----------- @@ -1 +1 @@
-------------2234c3a2bbb1302441afc29a25fec84e32271ba1
------------+1893ddb730be2c6661117bf39596d81a90087a8f
-----------+-1893ddb730be2c6661117bf39596d81a90087a8f
-----------++c20e974732a6ccdc523dd9e05876fe4dce43faaa
----------- diff --git a/checkpoints/inference-test/git_diff.patch b/checkpoints/inference-test/git_diff.patch
------------index bbf7cb1..e69de29 100644
-----------+index 00d44c3..e69de29 100644
----------- --- a/checkpoints/inference-test/git_diff.patch
----------- +++ b/checkpoints/inference-test/git_diff.patch
------------@@ -1,2205 +0,0 @@
-----------+@@ -1,2373 +0,0 @@
----------- -diff --git a/checkpoints/inference-test/config.yaml b/checkpoints/inference-test/config.yaml
-------------index 67acd14..61adced 100644
-----------+-index 61adced..2f2b128 100644
----------- ---- a/checkpoints/inference-test/config.yaml
----------- -+++ b/checkpoints/inference-test/config.yaml
-------------@@ -8,16 +8,14 @@ model:
-------------   dropout_p: 0.3
------------- optimizer:
-------------   _target_: torch.optim.Adam
--------------  lr: 1.0e-05
-------------+  lr: 0.001
-------------   weight_decay: 0.0001
------------- lr_scheduler:
-------------   _target_: torch.optim.lr_scheduler.StepLR
--------------  step_size: 10
--------------  gamma: 0.1
-------------+  step_size: 20
-------------+  gamma: 0.5
------------- loss_function:
--------------  _target_: src.loss.Asoftmax.AsoftMax
--------------  margin: 2
--------------  scale: 15
-------------+  _target_: src.loss.crossentropy.CrossEntropyLoss
------------- metrics:
-------------   train:
-------------   - _target_: src.metrics.eer.EERMetric
-------------@@ -56,7 +54,10 @@ transforms:
-------------   instance_transforms:
-------------     data_object: ${transforms.stft}
-------------   stft:
--------------    _target_: src.transforms.stft.AudioFrontend
-------------+    _target_: src.transforms.stft.STFTTransform
-------------+    n_fft: 1024
-------------+    hop_length: 512
-------------+    win_length: 1024
-------------   batch_transforms:
-------------     train:
-------------       data_object:
-------------@@ -80,7 +81,7 @@ writer:
-----------+-@@ -81,7 +81,7 @@ writer:
----------- -   _target_: src.logger.cometml.CometMLWriter
----------- -   project_name: anti-spoofing
----------- -   workspace: null
--------------  run_id: xzqp1djl
-------------+  run_id: 8gzucarc
-----------+--  run_id: 8gzucarc
-----------+-+  run_id: j9yzgmw7
----------- -   run_name: inference-test
----------- -   mode: online
----------- -   loss_names:
-------------@@ -95,7 +96,7 @@ trainer:
-------------   save_period: 10
-------------   val_period: 1
-------------   skip_oom: true
--------------  max_grad_norm: 1.0
-------------+  max_grad_norm: 0.5
-------------   log_step: 50
-------------   save_dir: checkpoints
-------------   device_tensors:
----------- -diff --git a/checkpoints/inference-test/git_commit.txt b/checkpoints/inference-test/git_commit.txt
-------------index 1bf8e23..24ff1b6 100644
-----------+-index 24ff1b6..abf19c1 100644
----------- ---- a/checkpoints/inference-test/git_commit.txt
----------- -+++ b/checkpoints/inference-test/git_commit.txt
----------- -@@ -1 +1 @@
--------------f24def3dab4de63a438094983749d95d2202c3cf
-------------+2234c3a2bbb1302441afc29a25fec84e32271ba1
-----------+--2234c3a2bbb1302441afc29a25fec84e32271ba1
-----------+-+1893ddb730be2c6661117bf39596d81a90087a8f
----------- -diff --git a/checkpoints/inference-test/git_diff.patch b/checkpoints/inference-test/git_diff.patch
-------------index 1bf2ab0..e69de29 100644
-----------+-index bbf7cb1..e69de29 100644
----------- ---- a/checkpoints/inference-test/git_diff.patch
----------- -+++ b/checkpoints/inference-test/git_diff.patch
-------------@@ -1,185 +0,0 @@
--------------diff --git a/src/configs/baseline.yaml b/src/configs/baseline.yaml
--------------index 6c8ba46..1649280 100644
----------------- a/src/configs/baseline.yaml
--------------+++ b/src/configs/baseline.yaml
--------------@@ -8,7 +8,7 @@ defaults:
--------------   - datasets: asvspoof2019
--------------   - dataloader: default
--------------   - transforms: default
---------------  - writer: wandb
--------------+  - writer: cometml
--------------   - trainer: default
-------------- 
-------------- data_path: ${oc.env:DATA_PATH,data}
-----------+-@@ -1,2205 +0,0 @@
-----------+--diff --git a/checkpoints/inference-test/config.yaml b/checkpoints/inference-test/config.yaml
-----------+--index 67acd14..61adced 100644
-----------+----- a/checkpoints/inference-test/config.yaml
-----------+--+++ b/checkpoints/inference-test/config.yaml
-----------+--@@ -8,16 +8,14 @@ model:
-----------+--   dropout_p: 0.3
-----------+-- optimizer:
-----------+--   _target_: torch.optim.Adam
-----------+---  lr: 1.0e-05
-----------+--+  lr: 0.001
-----------+--   weight_decay: 0.0001
-----------+-- lr_scheduler:
-----------+--   _target_: torch.optim.lr_scheduler.StepLR
-----------+---  step_size: 10
-----------+---  gamma: 0.1
-----------+--+  step_size: 20
-----------+--+  gamma: 0.5
-----------+-- loss_function:
-----------+---  _target_: src.loss.Asoftmax.AsoftMax
-----------+---  margin: 2
-----------+---  scale: 15
-----------+--+  _target_: src.loss.crossentropy.CrossEntropyLoss
-----------+-- metrics:
-----------+--   train:
-----------+--   - _target_: src.metrics.eer.EERMetric
-----------+--@@ -56,7 +54,10 @@ transforms:
-----------+--   instance_transforms:
-----------+--     data_object: ${transforms.stft}
-----------+--   stft:
-----------+---    _target_: src.transforms.stft.AudioFrontend
-----------+--+    _target_: src.transforms.stft.STFTTransform
-----------+--+    n_fft: 1024
-----------+--+    hop_length: 512
-----------+--+    win_length: 1024
-----------+--   batch_transforms:
-----------+--     train:
-----------+--       data_object:
-----------+--@@ -80,7 +81,7 @@ writer:
-----------+--   _target_: src.logger.cometml.CometMLWriter
-----------+--   project_name: anti-spoofing
-----------+--   workspace: null
-----------+---  run_id: xzqp1djl
-----------+--+  run_id: 8gzucarc
-----------+--   run_name: inference-test
-----------+--   mode: online
-----------+--   loss_names:
-----------+--@@ -95,7 +96,7 @@ trainer:
-----------+--   save_period: 10
-----------+--   val_period: 1
-----------+--   skip_oom: true
-----------+---  max_grad_norm: 1.0
-----------+--+  max_grad_norm: 0.5
-----------+--   log_step: 50
-----------+--   save_dir: checkpoints
-----------+--   device_tensors:
-----------+--diff --git a/checkpoints/inference-test/git_commit.txt b/checkpoints/inference-test/git_commit.txt
-----------+--index 1bf8e23..24ff1b6 100644
-----------+----- a/checkpoints/inference-test/git_commit.txt
-----------+--+++ b/checkpoints/inference-test/git_commit.txt
-----------+--@@ -1 +1 @@
-----------+---f24def3dab4de63a438094983749d95d2202c3cf
-----------+--+2234c3a2bbb1302441afc29a25fec84e32271ba1
-----------+--diff --git a/checkpoints/inference-test/git_diff.patch b/checkpoints/inference-test/git_diff.patch
-----------+--index 1bf2ab0..e69de29 100644
-----------+----- a/checkpoints/inference-test/git_diff.patch
-----------+--+++ b/checkpoints/inference-test/git_diff.patch
-----------+--@@ -1,185 +0,0 @@
-----------+---diff --git a/src/configs/baseline.yaml b/src/configs/baseline.yaml
-----------+---index 6c8ba46..1649280 100644
-----------+------ a/src/configs/baseline.yaml
-----------+---+++ b/src/configs/baseline.yaml
-----------+---@@ -8,7 +8,7 @@ defaults:
-----------+---   - datasets: asvspoof2019
-----------+---   - dataloader: default
-----------+---   - transforms: default
-----------+----  - writer: wandb
-----------+---+  - writer: cometml
-----------+---   - trainer: default
-----------+--- 
-----------+--- data_path: ${oc.env:DATA_PATH,data}
-----------+---diff --git a/src/configs/dataloader/default.yaml b/src/configs/dataloader/default.yaml
-----------+---index 86758af..902e80f 100644
-----------+------ a/src/configs/dataloader/default.yaml
-----------+---+++ b/src/configs/dataloader/default.yaml
-----------+---@@ -1,4 +1,4 @@
-----------+--- _target_: torch.utils.data.DataLoader
-----------+----batch_size: 32
-----------+---+batch_size: 16
-----------+--- num_workers: 4
-----------+--- pin_memory: true 
-----------+---\ No newline at end of file
-----------+---diff --git a/src/configs/loss_function/asoftmax.yaml b/src/configs/loss_function/asoftmax.yaml
-----------+---index fe087a7..a96439b 100644
-----------+------ a/src/configs/loss_function/asoftmax.yaml
-----------+---+++ b/src/configs/loss_function/asoftmax.yaml
-----------+---@@ -1,3 +1,3 @@
-----------+--- _target_: src.loss.Asoftmax.AsoftMax
-----------+----margin: 4
-----------+----scale: 30 
-----------+---\ No newline at end of file
-----------+---+margin: 2
-----------+---+scale: 15 
-----------+---\ No newline at end of file
-----------+---diff --git a/src/configs/optimizer/adam.yaml b/src/configs/optimizer/adam.yaml
-----------+---index 9af2fd8..3b50a71 100644
-----------+------ a/src/configs/optimizer/adam.yaml
-----------+---+++ b/src/configs/optimizer/adam.yaml
-----------+---@@ -1,3 +1,3 @@
-----------+--- _target_: torch.optim.Adam
-----------+----lr: 0.0001
-----------+---+lr: 0.00001
-----------+--- weight_decay: 0.0001 
-----------+---\ No newline at end of file
-----------+---diff --git a/src/loss/Asoftmax.py b/src/loss/Asoftmax.py
-----------+---index 25a74e3..6c4ee07 100644
-----------+------ a/src/loss/Asoftmax.py
-----------+---+++ b/src/loss/Asoftmax.py
-----------+---@@ -20,26 +20,29 @@ class AsoftMax(nn.Module):
-----------+---         Returns:
-----------+---             losses (dict): dictionary loss
-----------+---         """
-----------+----       
-----------+---+        
-----------+---+        # Нормализуем logits
-----------+---         logits_norm = F.normalize(logits, p=2, dim=1)
-----------+----        prev_cos = torch.clamp(logits_norm, -1.0 + 1e-6, 1.0 - 1e-6)
-----------+---         
-----------+----        angle = torch.acos(prev_cos)
-----------+----        cos_m = prev_cos.clone()
-----------+---+        # Вычисляем косинус угла
-----------+---+        cos_theta = torch.clamp(logits_norm, -1.0 + 1e-6, 1.0 - 1e-6)
-----------+---         
-----------+---+        # Вычисляем угол
-----------+---+        theta = torch.acos(cos_theta)
-----------+---         
-----------+----        mask = torch.zeros_like(prev_cos)
-----------+---+        # Создаем маску для целевого класса
-----------+---+        mask = torch.zeros_like(cos_theta)
-----------+---         mask.scatter_(1, labels.unsqueeze(1), 1)
-----------+---         
-----------+----       
-----------+----        cos_m = torch.where(mask == 1, 
-----------+----                                 torch.cos(self.margin * angle), 
-----------+----                                 prev_cos)
-----------+---+        # Применяем margin только к целевому классу
-----------+---+        cos_theta_m = torch.where(mask == 1, 
-----------+---+                                 torch.cos(self.margin * theta), 
-----------+---+                                 cos_theta)
-----------+---         
-----------+----       
-----------+----        cos_m = cos_m * self.scale
-----------+---+        # Масштабируем
-----------+---+        cos_theta_m = cos_theta_m * self.scale
-----------+---         
-----------+----   
-----------+----        loss = F.cross_entropy(cos_m, labels)
-----------+---+        # Вычисляем loss
-----------+---+        loss = F.cross_entropy(cos_theta_m, labels)
-----------+---         
-----------+---         return {"loss": loss}
-----------+---\ No newline at end of file
-----------+---diff --git a/src/metrics/eer.py b/src/metrics/eer.py
-----------+---index 61d466e..7e34321 100644
-----------+------ a/src/metrics/eer.py
-----------+---+++ b/src/metrics/eer.py
-----------+---@@ -1,4 +1,5 @@
-----------+--- import numpy as np
-----------+---+import torch
-----------+--- from abc import abstractmethod
-----------+--- 
-----------+--- class BaseMetric:
-----------+---@@ -17,8 +18,8 @@ class EERMetric(BaseMetric):
-----------+---     """
-----------+---     Equal Error Rate (EER) metric.
-----------+---     Ожидает в batch два поля:
-----------+----        - 'scores': numpy array или torch tensor с предсказанными скорингами
-----------+----        - 'labels': numpy array или torch tensor с метками (1 — bona fide, 0 — spoof)
-----------+---+        - 'logits': torch tensor с предсказанными logits
-----------+---+        - 'labels': torch tensor с метками (1 — bona fide, 0 — spoof)
-----------+---     """
-----------+--- 
-----------+---     def __init__(self, name="eer"):
-----------+---@@ -50,6 +51,9 @@ class EERMetric(BaseMetric):
-----------+---         bona_scores = scores[labels == 1]
-----------+---         spoof_scores = scores[labels == 0]
-----------+--- 
-----------+---+        if len(bona_scores) == 0 or len(spoof_scores) == 0:
-----------+---+            return 0.0
-----------+---+
-----------+---         eer, _ = self.compute_eer(bona_scores, spoof_scores)
-----------+---         return eer
-----------+--- 
-----------+---diff --git a/src/model/model.py b/src/model/model.py
-----------+---index 6d0bf94..28a4ce4 100644
-----------+------ a/src/model/model.py
-----------+---+++ b/src/model/model.py
-----------+---@@ -66,13 +66,29 @@ class LCNN(nn.Module):
-----------+--- 
-----------+---         self.MaxPool28 = nn.MaxPool2d(kernel_size=2, stride=2)
-----------+--- 
-----------+----
-----------+---         self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
-----------+---         self.fc29 = nn.Linear(32, 160)
-----------+---         self.dropout29 = nn.Dropout(dropout_p)
-----------+---         self.mfm30 = mfm_block(160)
-----------+---         self.BatchNorm31 = nn.BatchNorm1d(80)
-----------+---         self.fc32 = nn.Linear(80, num_classes)
-----------+---+        
-----------+---+        # Инициализация весов
-----------+---+        self._initialize_weights()
-----------+---+
-----------+---+    def _initialize_weights(self):
-----------+---+        """Инициализация весов для лучшего обучения"""
-----------+---+        for m in self.modules():
-----------+---+            if isinstance(m, nn.Conv2d):
-----------+---+                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
-----------+---+                if m.bias is not None:
-----------+---+                    nn.init.constant_(m.bias, 0)
-----------+---+            elif isinstance(m, nn.BatchNorm2d):
-----------+---+                nn.init.constant_(m.weight, 1)
-----------+---+                nn.init.constant_(m.bias, 0)
-----------+---+            elif isinstance(m, nn.Linear):
-----------+---+                nn.init.normal_(m.weight, 0, 0.01)
-----------+---+                nn.init.constant_(m.bias, 0)
-----------+--- 
-----------+---     def forward(self, data_object, **kwargs):
-----------+---         x = data_object
-----------+---diff --git a/src/trainer/trainer.py b/src/trainer/trainer.py
-----------+---index 1b806fb..3313fea 100644
-----------+------ a/src/trainer/trainer.py
-----------+---+++ b/src/trainer/trainer.py
-----------+---@@ -47,17 +47,17 @@ class Trainer(BaseTrainer):
-----------+---             if self.lr_scheduler is not None:
-----------+---                 self.lr_scheduler.step()
-----------+--- 
-----------+----        
-----------+---+        # Обновляем loss метрики
-----------+---         for loss_name in self.config.writer.loss_names:
-----------+---             metrics.update(loss_name, batch[loss_name].item())
-----------+--- 
-----------+----      
-----------+---+        # Обновляем EER метрику
-----------+---         if "logits" in batch:
-----------+---             scores = torch.softmax(batch["logits"], dim=1)[:, 1]
-----------+---             labels = batch["labels"]
-----------+---             metrics.update_eer(scores, labels)
-----------+--- 
-----------+----       
-----------+---+        # Обновляем остальные метрики
-----------+---         for met in metric_funcs:
-----------+---             if met.name != "eer":
-----------+---                 try:
-----------+--diff --git a/requirements.txt b/requirements.txt
-----------+--index 8aab454..1dc9376 100644
-----------+----- a/requirements.txt
-----------+--+++ b/requirements.txt
-----------+--@@ -1,37 +1,24 @@
-----------+---# Основные PyTorch зависимости
-----------+-- torch==2.2.0
-----------+-- torchvision==0.17.0
-----------+-- torchaudio==2.2.0
-----------+-- torchmetrics==1.7.4
-----------+---
-----------+---# Научные вычисления и обработка данных
-----------+-- numpy==1.26.4
-----------+-- pandas==2.3.1
-----------+-- matplotlib==3.9.4
-----------+-- scipy
-----------+---
-----------+---# Аудио обработка
-----------+-- soundfile==0.13.1
-----------+-- librosa
-----------+---
-----------+---# Логирование и эксперименты
-----------+-- wandb==0.21.0
-----------+-- comet-ml==3.50.0
-----------+-- hydra-core==1.3.2
-----------+-- omegaconf==2.3.0
-----------+---
-----------+---# Утилиты
-----------+-- tqdm==4.67.1
-----------+-- psutil==7.0.0
-----------+-- requests==2.32.4
-----------+-- pyyaml==6.0.2
-----------+---
-----------+---# Разработка и форматирование кода
-----------+-- black
-----------+-- isort
-----------+-- pre-commit
-----------+-- flake8
-----------+---
-----------+---# Дополнительные зависимости для ML
-----------+-- scikit-learn
-----------+-- seaborn
-----------+--\ No newline at end of file
----------- --diff --git a/src/configs/dataloader/default.yaml b/src/configs/dataloader/default.yaml
--------------index 86758af..902e80f 100644
-----------+--index 80fbc65..902e80f 100644
----------- ----- a/src/configs/dataloader/default.yaml
----------- --+++ b/src/configs/dataloader/default.yaml
----------- --@@ -1,4 +1,4 @@
----------- -- _target_: torch.utils.data.DataLoader
---------------batch_size: 32
-----------+---batch_size: 8
----------- --+batch_size: 16
----------- -- num_workers: 4
----------- -- pin_memory: true 
----------- --\ No newline at end of file
--------------diff --git a/src/configs/loss_function/asoftmax.yaml b/src/configs/loss_function/asoftmax.yaml
--------------index fe087a7..a96439b 100644
----------------- a/src/configs/loss_function/asoftmax.yaml
--------------+++ b/src/configs/loss_function/asoftmax.yaml
-----------+--diff --git a/src/configs/lr_scheduler/step.yaml b/src/configs/lr_scheduler/step.yaml
-----------+--index bd12a00..3c208ac 100644
-----------+----- a/src/configs/lr_scheduler/step.yaml
-----------+--+++ b/src/configs/lr_scheduler/step.yaml
----------- --@@ -1,3 +1,3 @@
-------------- _target_: src.loss.Asoftmax.AsoftMax
---------------margin: 4
---------------scale: 30 
-----------+-- _target_: torch.optim.lr_scheduler.StepLR
-----------+---step_size: 10
-----------+---gamma: 0.1 
----------- --\ No newline at end of file
--------------+margin: 2
--------------+scale: 15 
-----------+--+step_size: 20
-----------+--+gamma: 0.5 
----------- --\ No newline at end of file
----------- --diff --git a/src/configs/optimizer/adam.yaml b/src/configs/optimizer/adam.yaml
--------------index 9af2fd8..3b50a71 100644
-----------+--index 9af2fd8..1310b87 100644
----------- ----- a/src/configs/optimizer/adam.yaml
----------- --+++ b/src/configs/optimizer/adam.yaml
----------- --@@ -1,3 +1,3 @@
----------- -- _target_: torch.optim.Adam
----------- ---lr: 0.0001
--------------+lr: 0.00001
-----------+--+lr: 0.001
----------- -- weight_decay: 0.0001 
----------- --\ No newline at end of file
--------------diff --git a/src/loss/Asoftmax.py b/src/loss/Asoftmax.py
--------------index 25a74e3..6c4ee07 100644
----------------- a/src/loss/Asoftmax.py
--------------+++ b/src/loss/Asoftmax.py
--------------@@ -20,26 +20,29 @@ class AsoftMax(nn.Module):
-----------+--diff --git a/src/configs/transforms/default.yaml b/src/configs/transforms/default.yaml
-----------+--index 4aea72d..32f1775 100644
-----------+----- a/src/configs/transforms/default.yaml
-----------+--+++ b/src/configs/transforms/default.yaml
-----------+--@@ -2,7 +2,10 @@ instance_transforms:
-----------+--   data_object: ${transforms.stft}
-----------+-- 
-----------+-- stft:
-----------+---  _target_: src.transforms.stft.AudioFrontend
-----------+--+  _target_: src.transforms.stft.STFTTransform
-----------+--+  n_fft: 1024
-----------+--+  hop_length: 512
-----------+--+  win_length: 1024
-----------+-- 
-----------+-- batch_transforms:
-----------+--   train:
-----------+--diff --git a/src/datasets/base_dataset.py b/src/datasets/base_dataset.py
-----------+--index bf51c70..e75525d 100644
-----------+----- a/src/datasets/base_dataset.py
-----------+--+++ b/src/datasets/base_dataset.py
-----------+--@@ -1,6 +1,6 @@
-----------+-- import logging
-----------+-- import random
-----------+---from typing import List
-----------+--+from typing import List, Dict, Any, Optional
-----------+-- 
-----------+-- import torch
-----------+-- import torchaudio
-----------+--@@ -11,66 +11,65 @@ logger = logging.getLogger(__name__)
-----------+-- 
-----------+-- class BaseDataset(Dataset):
-----------+--     """
-----------+---    Base class for the datasets.
-----------+---
-----------+---    Given a proper index (list[dict]), allows to process different datasets
-----------+---    for the same task in the identical manner. Therefore, to work with
-----------+---    several datasets, the user only have to define index in a nested class.
-----------+--+    Base class for all datasets.
-----------+--     """
-----------+-- 
-----------+--     def __init__(
-----------+---        self, index, limit=None, shuffle_index=False, instance_transforms=None
-----------+--+        self,
-----------+--+        index: List[Dict[str, Any]],
-----------+--+        instance_transforms: Optional[Dict[str, Any]] = None,
-----------+--+        *args,
-----------+--+        **kwargs,
-----------+--     ):
-----------+--         """
-----------+--         Args:
-----------+---            index (list[dict]): list, containing dict for each element of
-----------+---                the dataset. The dict has required metadata information,
-----------+---                such as label and object path.
-----------+---            limit (int | None): if not None, limit the total number of elements
-----------+---                in the dataset to 'limit' elements.
-----------+---            shuffle_index (bool): if True, shuffle the index. Uses python
-----------+---                random package with seed 42.
-----------+---            instance_transforms (dict[Callable] | None): transforms that
-----------+---                should be applied on the instance. Depend on the
-----------+---                tensor name.
-----------+---        """
-----------+---        self._assert_index_is_valid(index)
-----------+---
-----------+---        index = self._shuffle_and_limit_index(index, limit, shuffle_index)
-----------+---        self._index: List[dict] = index
-----------+---
-----------+--+            index (List[Dict[str, Any]]): list of dictionaries, each containing
-----------+--+                the data for one sample.
-----------+--+            instance_transforms (Optional[Dict[str, Any]]): transforms to apply
-----------+--+                to instances. Depend on the tensor name.
-----------+--+        """
-----------+--+        self.index = index
-----------+--         self.instance_transforms = instance_transforms
-----------+-- 
-----------+---    def __getitem__(self, ind):
-----------+---        """
-----------+---        Get element from the index, preprocess it, and combine it
-----------+---        into a dict.
-----------+--+    def __len__(self):
-----------+--+        return len(self.index)
-----------+-- 
-----------+---        Notice that the choice of key names is defined by the template user.
-----------+---        However, they should be consistent across dataset getitem, collate_fn,
-----------+---        loss_function forward method, and model forward method.
-----------+--+    def __getitem__(self, idx):
-----------+--+        """
-----------+--+        Get item by index.
-----------+-- 
-----------+--         Args:
-----------+---            ind (int): index in the self.index list.
-----------+--+            idx (int): index of the item.
-----------+--+
----------- --         Returns:
--------------             losses (dict): dictionary loss
-----------+---            instance_data (dict): dict, containing instance
-----------+---                (a single dataset element).
-----------+--+            dict: item data.
----------- --         """
---------------       
-----------+---        data_dict = self._index[ind]
-----------+---        data_path = data_dict["path"]
-----------+---        data_object = self.load_object(data_path)
-----------+---        data_label = data_dict["label"]
-----------+--+        item = self.index[idx]
----------- --+        
--------------+        # Нормализуем logits
--------------         logits_norm = F.normalize(logits, p=2, dim=1)
---------------        prev_cos = torch.clamp(logits_norm, -1.0 + 1e-6, 1.0 - 1e-6)
--------------         
---------------        angle = torch.acos(prev_cos)
---------------        cos_m = prev_cos.clone()
--------------+        # Вычисляем косинус угла
--------------+        cos_theta = torch.clamp(logits_norm, -1.0 + 1e-6, 1.0 - 1e-6)
--------------         
--------------+        # Вычисляем угол
--------------+        theta = torch.acos(cos_theta)
--------------         
---------------        mask = torch.zeros_like(prev_cos)
--------------+        # Создаем маску для целевого класса
--------------+        mask = torch.zeros_like(cos_theta)
--------------         mask.scatter_(1, labels.unsqueeze(1), 1)
--------------         
---------------       
---------------        cos_m = torch.where(mask == 1, 
---------------                                 torch.cos(self.margin * angle), 
---------------                                 prev_cos)
--------------+        # Применяем margin только к целевому классу
--------------+        cos_theta_m = torch.where(mask == 1, 
--------------+                                 torch.cos(self.margin * theta), 
--------------+                                 cos_theta)
-----------+--+        # Применяем instance transforms
-----------+--+        if self.instance_transforms is not None:
-----------+--+            item = self._apply_instance_transforms(item)
-----------+--+        
-----------+--+        return item
-----------+-- 
-----------+---        instance_data = {"data_object": data_object, "labels": data_label}
-----------+---        instance_data = self.preprocess_data(instance_data)
-----------+--+    def _apply_instance_transforms(self, item: Dict[str, Any]) -> Dict[str, Any]:
-----------+--+        """
-----------+--+        Apply instance transforms to the item.
-----------+-- 
-----------+---        return instance_data
-----------+--+        Args:
-----------+--+            item (Dict[str, Any]): item data.
-----------+-- 
-----------+---    def __len__(self):
-----------+---        """
-----------+---        Get length of the dataset (length of the index).
-----------+--+        Returns:
-----------+--+            Dict[str, Any]: transformed item data.
-----------+--         """
-----------+---        return len(self._index)
-----------+--+        for transform_name, transform in self.instance_transforms.items():
-----------+--+            if transform_name in item:
-----------+--+                try:
-----------+--+                    item[transform_name] = transform(item[transform_name])
-----------+--+                except Exception as e:
-----------+--+                    raise
-----------+--+        
-----------+--+        return item
-----------+-- 
-----------+--     def load_object(self, path):
-----------+--         """
-----------+--@@ -126,74 +125,63 @@ class BaseDataset(Dataset):
-----------+--         the __init__ before shuffling and limiting.
-----------+-- 
-----------+--         Args:
-----------+---            index (list[dict]): list, containing dict for each element of
-----------+---                the dataset. The dict has required metadata information,
-----------+---                such as label and object path.
-----------+--+            index (list): list of records to filter.
-----------+--+
-----------+--         Returns:
-----------+---            index (list[dict]): list, containing dict for each element of
-----------+---                the dataset that satisfied the condition. The dict has
-----------+---                required metadata information, such as label and object path.
-----------+--+            list: filtered list of records.
-----------+--         """
-----------+---        # Filter logic
-----------+---        pass
-----------+--+        return index
-----------+-- 
-----------+--     @staticmethod
-----------+--     def _assert_index_is_valid(index):
-----------+--         """
-----------+---        Check the structure of the index and ensure it satisfies the desired
-----------+---        conditions.
-----------+--+        Assert that the index is valid.
-----------+-- 
-----------+--         Args:
-----------+---            index (list[dict]): list, containing dict for each element of
-----------+---                the dataset. The dict has required metadata information,
-----------+---                such as label and object path.
-----------+---        """
-----------+---        for entry in index:
-----------+---            assert "path" in entry, (
-----------+---                "Each dataset item should include field 'path'" " - path to audio file."
-----------+---            )
-----------+---            assert "label" in entry, (
-----------+---                "Each dataset item should include field 'label'"
-----------+---                " - object ground-truth label."
-----------+---            )
-----------+--+            index (list): list of records to validate.
-----------+--+        """
-----------+--+        assert isinstance(index, list), "Index should be a list"
-----------+--+        assert len(index) > 0, "Index should not be empty"
-----------+--+        for record in index:
-----------+--+            assert isinstance(record, dict), "Each record should be a dict"
-----------+--+            assert "path" in record, "Each record should have a 'path' field"
-----------+--+            assert "label" in record, "Each record should have a 'label' field"
-----------+-- 
-----------+--     @staticmethod
-----------+--     def _sort_index(index):
-----------+--         """
-----------+---        Sort index via some rules.
-----------+--+        Sort the index by some criterion.
-----------+-- 
-----------+--         This is not used in the example. The method should be called in
-----------+---        the __init__ before shuffling and limiting and after filtering.
-----------+--+        the __init__ before shuffling and limiting.
-----------+-- 
-----------+--         Args:
-----------+---            index (list[dict]): list, containing dict for each element of
-----------+---                the dataset. The dict has required metadata information,
-----------+---                such as label and object path.
-----------+--+            index (list): list of records to sort.
-----------+--+
-----------+--         Returns:
-----------+---            index (list[dict]): sorted list, containing dict for each element
-----------+---                of the dataset. The dict has required metadata information,
-----------+---                such as label and object path.
-----------+--+            list: sorted list of records.
-----------+--         """
-----------+---        return sorted(index, key=lambda x: x["KEY_FOR_SORTING"])
-----------+--+        return index
-----------+-- 
-----------+--     @staticmethod
-----------+--     def _shuffle_and_limit_index(index, limit, shuffle_index):
-----------+--         """
-----------+---        Shuffle elements in index and limit the total number of elements.
-----------+--+        Shuffle and limit the index.
-----------+--+
-----------+--+        This is not used in the example. The method should be called in
-----------+--+        the __init__ before shuffling and limiting.
-----------+-- 
-----------+--         Args:
-----------+---            index (list[dict]): list, containing dict for each element of
-----------+---                the dataset. The dict has required metadata information,
-----------+---                such as label and object path.
-----------+---            limit (int | None): if not None, limit the total number of elements
-----------+---                in the dataset to 'limit' elements.
-----------+---            shuffle_index (bool): if True, shuffle the index. Uses python
-----------+---                random package with seed 42.
-----------+--+            index (list): list of records to shuffle and limit.
-----------+--+            limit (int): maximum number of records to keep.
-----------+--+            shuffle_index (bool): whether to shuffle the index.
-----------+--+
-----------+--+        Returns:
-----------+--+            list: shuffled and limited list of records.
-----------+--         """
-----------+--         if shuffle_index:
-----------+--             random.seed(42)
-----------+--             random.shuffle(index)
-----------+---
-----------+--         if limit is not None:
-----------+--             index = index[:limit]
-----------+--         return index
-----------+--\ No newline at end of file
-----------+--diff --git a/src/datasets/collate.py b/src/datasets/collate.py
-----------+--index 4c2c81e..6cb3b10 100644
-----------+----- a/src/datasets/collate.py
-----------+--+++ b/src/datasets/collate.py
-----------+--@@ -19,6 +19,15 @@ def collate_fn(dataset_items: list[dict]):
-----------+-- 
-----------+--     # Pad audio sequences to the same length
-----------+--     audio_tensors = [elem["data_object"] for elem in dataset_items]
-----------+--+    
-----------+--+    # Handle different audio tensor shapes
-----------+--+    if len(audio_tensors) == 0:
-----------+--+        # Return empty batch
-----------+--+        result_batch["data_object"] = torch.empty(0)
-----------+--+        result_batch["labels"] = torch.empty(0, dtype=torch.long)
-----------+--+        return result_batch
-----------+--+    
-----------+--+    # Get max length for padding
-----------+--     max_length = max(audio.shape[-1] for audio in audio_tensors)
-----------+--     
-----------+--     padded_audio = []
-----------+--@@ -30,6 +39,6 @@ def collate_fn(dataset_items: list[dict]):
-----------+--         padded_audio.append(audio)
-----------+--     
-----------+--     result_batch["data_object"] = torch.stack(padded_audio)
-----------+---    result_batch["labels"] = torch.tensor([elem["labels"] for elem in dataset_items])
-----------+--+    result_batch["labels"] = torch.tensor([elem["labels"] for elem in dataset_items], dtype=torch.long)
-----------+-- 
-----------+--     return result_batch
-----------+--\ No newline at end of file
-----------+--diff --git a/src/datasets/data_utils.py b/src/datasets/data_utils.py
-----------+--index 8262ceb..63e8cce 100644
-----------+----- a/src/datasets/data_utils.py
-----------+--+++ b/src/datasets/data_utils.py
-----------+--@@ -36,6 +36,9 @@ def move_batch_transforms_to_device(batch_transforms, device):
-----------+--             tensor name.
-----------+--         device (str): device to use for batch transforms.
-----------+--     """
-----------+--+    if batch_transforms is None:
-----------+--+        return
-----------+--+        
-----------+--     for transform_type in batch_transforms.keys():
-----------+--         transforms = batch_transforms.get(transform_type)
-----------+--         if transforms is not None:
-----------+--@@ -60,6 +63,7 @@ def get_dataloaders(config, device):
-----------+--     """
-----------+--     # transforms or augmentations init
-----------+--     batch_transforms = instantiate(config.transforms.batch_transforms)
-----------+--+    
-----------+--     move_batch_transforms_to_device(batch_transforms, device)
-----------+-- 
-----------+--     # dataset partitions init
-----------+--diff --git a/src/datasets/mydataset.py b/src/datasets/mydataset.py
-----------+--index 02a09c3..94e7e12 100644
-----------+----- a/src/datasets/mydataset.py
-----------+--+++ b/src/datasets/mydataset.py
-----------+--@@ -1,5 +1,6 @@
-----------+-- import numpy as np
-----------+-- import torch
-----------+--+import torchaudio
-----------+-- from tqdm.auto import tqdm
-----------+-- 
-----------+-- from src.datasets.base_dataset import BaseDataset
-----------+--@@ -37,6 +38,50 @@ class AudioSpoofingDataset(BaseDataset):
-----------+-- 
-----------+--         super().__init__(index, instance_transforms=instance_transforms, *args, **kwargs)
-----------+-- 
-----------+--+    def __getitem__(self, idx):
-----------+--+        """
-----------+--+        Get item by index.
-----------+--+
-----------+--+        Args:
-----------+--+            idx (int): index of the item.
-----------+--+
-----------+--+        Returns:
-----------+--+            dict: item data with 'data_object' and 'labels' keys.
-----------+--+        """
-----------+--+        item = self.index[idx]
-----------+--+        
-----------+--+        # Load audio file
-----------+--+        audio_path = item["path"]
-----------+--+        label = item["label"]
-----------+--+        
-----------+--+        try:
-----------+--+            # Load audio using torchaudio
-----------+--+            waveform, sample_rate = torchaudio.load(audio_path)
-----------+--+            
-----------+--+            # Convert to mono if stereo
-----------+--+            if waveform.shape[0] > 1:
-----------+--+                waveform = torch.mean(waveform, dim=0, keepdim=True)
-----------+--+            
-----------+--+            # Create item with correct keys
-----------+--+            item_data = {
-----------+--+                "data_object": waveform,
-----------+--+                "labels": label
-----------+--+            }
-----------+--+            
-----------+--+            # Apply instance transforms
-----------+--+            if self.instance_transforms is not None:
-----------+--+                item_data = self._apply_instance_transforms(item_data)
-----------+--+            
-----------+--+            return item_data
-----------+--+            
-----------+--+        except Exception as e:
-----------+--+            # Return zero tensor as fallback
-----------+--+            fallback_waveform = torch.zeros(1, 16000)  # 1 second of silence at 16kHz
-----------+--+            return {
-----------+--+                "data_object": fallback_waveform,
-----------+--+                "labels": label
-----------+--+            }
-----------+--+
-----------+--     def _create_index(self, label_path, audio_path, out_path):
-----------+--         """
-----------+--         Args:
-----------+--@@ -47,25 +92,40 @@ class AudioSpoofingDataset(BaseDataset):
-----------+--         Returns:
-----------+--             index (list[dict]): list of dictionaries, each with "path" and "label" fields
-----------+--         """
-----------+---
-----------+--         index = []
-----------+--+        
-----------+--+        # Подсчитываем общее количество строк в файле
-----------+--+        with open(label_path, "r") as f:
-----------+--+            total_lines = sum(1 for _ in f)
-----------+--+        
-----------+--+        bonafide_count = 0
-----------+--+        spoof_count = 0
-----------+-- 
-----------+--         with open(label_path, "r") as f:
-----------+---            for line in f:
-----------+--+            for line_num, line in enumerate(tqdm(f, total=total_lines, desc="Обработка строк")):
-----------+--                 parts = line.strip().split()
-----------+--                 file_id = parts[1]
-----------+--                 class_name = parts[-1]
-----------+--                 label = 0 if class_name == "bonafide" else 1  # Fixed typo
-----------+--                 path = str(Path(audio_path) / f"{file_id}.flac")
-----------+--+                
-----------+--+                # Проверяем существование файла
-----------+--+                if not Path(path).exists():
-----------+--+                    continue
-----------+--+                
-----------+--                 index.append(
-----------+--                     {
-----------+--                         "path" : path,
-----------+--                         "label" : label
-----------+--                     }
-----------+--                 )
-----------+---        print("Separate to path and labels complete")
-----------+--+                
-----------+--+                # Подсчитываем статистику
-----------+--+                if label == 0:
-----------+--+                    bonafide_count += 1
-----------+--+                else:
-----------+--+                    spoof_count += 1
-----------+--+        
-----------+--         write_json(index, out_path)
-----------+-- 
-----------+---        print(f"Created {len(index)} entries in {out_path}")
-----------+---
-----------+--         return index
-----------+--diff --git a/src/loss/crossentropy.py b/src/loss/crossentropy.py
-----------+--index d8ad43e..677200c 100644
-----------+----- a/src/loss/crossentropy.py
-----------+--+++ b/src/loss/crossentropy.py
-----------+--@@ -1,28 +1,80 @@
-----------+-- import torch
-----------+---from torch import nn
-----------+---import torch.nn.functional as F
-----------+--+import torch.nn as nn
-----------+--+from typing import Dict, Any
-----------+--+
-----------+-- 
-----------+-- class CrossEntropyLoss(nn.Module):
-----------+--     """
-----------+---    Простой CrossEntropy loss для стабильного обучения
-----------+--+    Cross Entropy Loss for audio anti-spoofing.
-----------+--     """
-----------+-- 
-----------+---    def __init__(self):
-----------+---        super().__init__()
-----------+--+    def __init__(self, **kwargs):
-----------+--+        """
-----------+--+        Args:
-----------+--+            **kwargs: additional arguments
-----------+--+        """
-----------+--+        super(CrossEntropyLoss, self).__init__()
-----------+--+        
-----------+--+        print("🎯 Инициализация CrossEntropyLoss...")
-----------+--+        
-----------+--+        # Логируем параметры
-----------+--+        for key, value in kwargs.items():
-----------+--+            print(f"   📊 {key}: {value}")
-----------+--+        
-----------+--+        self.criterion = nn.CrossEntropyLoss()
-----------+--+        print("✅ CrossEntropyLoss инициализирован")
-----------+-- 
-----------+---    def forward(self, logits: torch.Tensor, labels: torch.Tensor, **kwargs):
-----------+--+    def forward(self, **batch) -> Dict[str, torch.Tensor]:
-----------+--         """
-----------+---        CrossEntropy loss compute
-----------+--+        Compute cross entropy loss.
----------- --         
---------------       
---------------        cos_m = cos_m * self.scale
--------------+        # Масштабируем
--------------+        cos_theta_m = cos_theta_m * self.scale
-----------+--         Args:
-----------+---            logits (Tensor): model output predictions (batch_size, num_classes)
-----------+---            labels (Tensor): ground truth labels (batch_size,)
-----------+---            **kwargs: дополнительные аргументы (игнорируются)
-----------+--+            **batch: input batch containing logits and labels
-----------+--+            
-----------+--         Returns:
-----------+---            losses (dict): dictionary loss
-----------+--+            Dict[str, torch.Tensor]: loss dictionary
-----------+--         """
-----------+--+        # Логируем входные данные (только для отладки)
-----------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
-----------+--+            print(f"   💔 CrossEntropyLoss forward: входные ключи {list(batch.keys())}")
-----------+--+            for key, value in batch.items():
-----------+--+                if isinstance(value, torch.Tensor):
-----------+--+                    print(f"      {key}: shape={value.shape}, dtype={value.dtype}")
-----------+--+        
-----------+--+        # Получаем logits и labels
-----------+--+        logits = batch['logits']
-----------+--+        labels = batch['labels']
----------- --         
---------------   
---------------        loss = F.cross_entropy(cos_m, labels)
--------------+        # Вычисляем loss
--------------+        loss = F.cross_entropy(cos_theta_m, labels)
-----------+---        # Используем обычный CrossEntropy loss для стабильности
-----------+---        loss = F.cross_entropy(logits, labels)
-----------+--+        # Проверяем размеры
-----------+--+        if logits.dim() == 1:
-----------+--+            logits = logits.unsqueeze(0)
-----------+--+        if labels.dim() == 0:
-----------+--+            labels = labels.unsqueeze(0)
----------- --         
--------------         return {"loss": loss}
--------------\ No newline at end of file
-----------+---        return {"loss": loss}
-----------+--+        # Логируем размеры
-----------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
-----------+--+            print(f"   📊 Logits: shape={logits.shape}, range=[{logits.min().item():.4f}, {logits.max().item():.4f}]")
-----------+--+            print(f"   📊 Labels: shape={labels.shape}, unique={torch.unique(labels).tolist()}")
-----------+--+        
-----------+--+        # Вычисляем потерю
-----------+--+        loss = self.criterion(logits, labels)
-----------+--+        
-----------+--+        # Логируем результат
-----------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
-----------+--+            print(f"   💔 Loss: {loss.item():.4f}")
-----------+--+        
-----------+--+        return {
-----------+--+            'loss': loss
-----------+--+        }
-----------+--+
-----------+--+    def set_debug_mode(self, debug_forward=False):
-----------+--+        """
-----------+--+        Включает режим отладки для логирования forward pass.
-----------+--+        
-----------+--+        Args:
-----------+--+            debug_forward (bool): логировать forward pass
-----------+--+        """
-----------+--+        self._debug_forward = debug_forward
-----------+--+        if debug_forward:
-----------+--+            print(f"🐛 Режим отладки включен для {self.__class__.__name__}")
-----------+--+            print(f"   💔 Debug forward: {debug_forward}")
----------- --diff --git a/src/metrics/eer.py b/src/metrics/eer.py
--------------index 61d466e..7e34321 100644
-----------+--index de45458..a9be4a6 100644
----------- ----- a/src/metrics/eer.py
----------- --+++ b/src/metrics/eer.py
--------------@@ -1,4 +1,5 @@
-------------- import numpy as np
--------------+import torch
-------------- from abc import abstractmethod
-----------+--@@ -1,88 +1,138 @@
-----------+---import numpy as np
-----------+-- import torch
-----------+---from abc import abstractmethod
-----------+---
-----------+---class BaseMetric:
-----------+---    """
-----------+---    Base class for all metrics
-----------+---    """
-----------+--+import numpy as np
-----------+--+from typing import Dict, Any
----------- -- 
-------------- class BaseMetric:
--------------@@ -17,8 +18,8 @@ class EERMetric(BaseMetric):
-----------+---    def __init__(self, name=None, *args, **kwargs):
-----------+---        self.name = name if name is not None else type(self).__name__
-----------+--+from src.metrics.base_metric import BaseMetric
-----------+-- 
-----------+---    @abstractmethod
-----------+---    def __call__(self, **batch):
-----------+---        raise NotImplementedError()
-----------+-- 
-----------+-- class EERMetric(BaseMetric):
----------- --     """
--------------     Equal Error Rate (EER) metric.
--------------     Ожидает в batch два поля:
---------------        - 'scores': numpy array или torch tensor с предсказанными скорингами
---------------        - 'labels': numpy array или torch tensor с метками (1 — bona fide, 0 — spoof)
--------------+        - 'logits': torch tensor с предсказанными logits
--------------+        - 'labels': torch tensor с метками (1 — bona fide, 0 — spoof)
-----------+---    Equal Error Rate (EER) metric.
-----------+---    Ожидает в batch два поля:
-----------+---        - 'logits': torch tensor с предсказанными logits
-----------+---        - 'labels': torch tensor с метками (1 — bona fide, 0 — spoof)
-----------+--+    Equal Error Rate (EER) metric for audio anti-spoofing.
----------- --     """
----------- -- 
--------------     def __init__(self, name="eer"):
--------------@@ -50,6 +51,9 @@ class EERMetric(BaseMetric):
--------------         bona_scores = scores[labels == 1]
--------------         spoof_scores = scores[labels == 0]
-----------+---    def __init__(self, name="eer"):
-----------+---        super().__init__(name=name)
-----------+---
-----------+---    def __call__(self, **batch):
-----------+---    
-----------+---        logits = batch["logits"]
-----------+---        labels = batch["labels"]
-----------+---
-----------+--+    def __init__(self, **kwargs):
-----------+--+        """
-----------+--+        Args:
-----------+--+            **kwargs: additional arguments
-----------+--+        """
-----------+--+        super(EERMetric, self).__init__()
-----------+--+        
-----------+--+        print("📈 Инициализация EERMetric...")
-----------+--         
-----------+---        if hasattr(logits, "detach"):
-----------+---            logits = logits.detach().cpu().numpy()
-----------+---        if hasattr(labels, "detach"):
-----------+---            labels = labels.detach().cpu().numpy()
-----------+--+        # Логируем параметры
-----------+--+        for key, value in kwargs.items():
-----------+--+            print(f"   📊 {key}: {value}")
-----------+--+        
-----------+--+        self.name = "eer"
-----------+--+        print("✅ EERMetric инициализирован")
----------- -- 
--------------+        if len(bona_scores) == 0 or len(spoof_scores) == 0:
--------------+            return 0.0
--------------+
--------------         eer, _ = self.compute_eer(bona_scores, spoof_scores)
-----------+--+    def forward(self, **batch) -> float:
-----------+--+        """
-----------+--+        Compute EER metric.
-----------+--         
-----------+---        import torch.nn.functional as F
-----------+---        if hasattr(logits, "detach"):
-----------+--+        Args:
-----------+--+            **batch: input batch containing scores and labels
-----------+--             
-----------+---            scores = F.softmax(logits, dim=-1)[:, 1]
-----------+---        else:
-----------+---            
-----------+---            logits_tensor = torch.from_numpy(logits)
-----------+---            scores_tensor = F.softmax(logits_tensor, dim=-1)
-----------+---            scores = scores_tensor[:, 1].numpy()
-----------+---
-----------+--+        Returns:
-----------+--+            float: EER value
-----------+--+        """
-----------+--+        # Логируем входные данные (только для отладки)
-----------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
-----------+--+            print(f"   📈 EERMetric forward: входные ключи {list(batch.keys())}")
-----------+--+            for key, value in batch.items():
-----------+--+                if isinstance(value, torch.Tensor):
-----------+--+                    print(f"      {key}: shape={value.shape}, dtype={value.dtype}")
-----------+--         
-----------+---        bona_scores = scores[labels == 1]
-----------+---        spoof_scores = scores[labels == 0]
-----------+---
-----------+---        if len(bona_scores) == 0 or len(spoof_scores) == 0:
-----------+--+        # Получаем scores и labels
-----------+--+        if 'scores' in batch:
-----------+--+            scores = batch['scores']
-----------+--+        elif 'logits' in batch:
-----------+--+            # Если у нас есть logits, берем вероятность второго класса (spoof)
-----------+--+            logits = batch['logits']
-----------+--+            scores = torch.softmax(logits, dim=1)[:, 1]
-----------+--+        else:
-----------+--+            print("❌ Ошибка: не найдены scores или logits в батче")
-----------+--             return 0.0
-----------+---
-----------+---        eer, _ = self.compute_eer(bona_scores, spoof_scores)
-----------+--+        
-----------+--+        labels = batch['labels']
-----------+--+        
-----------+--+        # Логируем размеры
-----------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
-----------+--+            print(f"   📊 Scores: shape={scores.shape}, range=[{scores.min().item():.4f}, {scores.max().item():.4f}]")
-----------+--+            print(f"   📊 Labels: shape={labels.shape}, unique={torch.unique(labels).tolist()}")
-----------+--+        
-----------+--+        # Вычисляем EER
-----------+--+        eer = self._compute_eer(scores, labels)
-----------+--+        
-----------+--+        # Логируем результат
-----------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
-----------+--+            print(f"   📈 EER: {eer:.4f}")
-----------+--+        
----------- --         return eer
----------- -- 
-----------+---    @staticmethod
-----------+---    def compute_det_curve(target_scores, nontarget_scores):
-----------+---        n_scores = target_scores.size + nontarget_scores.size
-----------+---        all_scores = np.concatenate((target_scores, nontarget_scores))
-----------+---        labels = np.concatenate(
-----------+---            (np.ones(target_scores.size), np.zeros(nontarget_scores.size)))
-----------+---
-----------+---        indices = np.argsort(all_scores, kind='mergesort')
-----------+---        labels = labels[indices]
-----------+---
-----------+---        tar_trial_sums = np.cumsum(labels)
-----------+---        nontarget_trial_sums = nontarget_scores.size - \
-----------+---            (np.arange(1, n_scores + 1) - tar_trial_sums)
-----------+---
-----------+---        frr = np.concatenate(
-----------+---            (np.atleast_1d(0), tar_trial_sums / target_scores.size))
-----------+---        far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums /
-----------+---                              nontarget_scores.size))
-----------+---        thresholds = np.concatenate(
-----------+---            (np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))
-----------+---        return frr, far, thresholds
-----------+--+    def _compute_eer(self, scores: torch.Tensor, labels: torch.Tensor) -> float:
-----------+--+        """
-----------+--+        Compute Equal Error Rate.
-----------+--+        
-----------+--+        Args:
-----------+--+            scores (torch.Tensor): prediction scores
-----------+--+            labels (torch.Tensor): ground truth labels
-----------+--+            
-----------+--+        Returns:
-----------+--+            float: EER value
-----------+--+        """
-----------+--+        # Конвертируем в numpy
-----------+--+        scores_np = scores.detach().cpu().numpy()
-----------+--+        labels_np = labels.detach().cpu().numpy()
-----------+--+        
-----------+--+        # Получаем уникальные пороги
-----------+--+        thresholds = np.unique(scores_np)
-----------+--+        
-----------+--+        # Вычисляем FAR и FRR для каждого порога
-----------+--+        far_values = []
-----------+--+        frr_values = []
-----------+--+        
-----------+--+        for threshold in thresholds:
-----------+--+            # FAR = FP / (FP + TN) = FP / (FP + TN)
-----------+--+            # FRR = FN / (FN + TP) = FN / (FN + TP)
-----------+--+            
-----------+--+            # Предсказания: 1 если score >= threshold, иначе 0
-----------+--+            predictions = (scores_np >= threshold).astype(int)
-----------+--+            
-----------+--+            # Вычисляем confusion matrix
-----------+--+            tp = np.sum((predictions == 1) & (labels_np == 1))
-----------+--+            tn = np.sum((predictions == 0) & (labels_np == 0))
-----------+--+            fp = np.sum((predictions == 1) & (labels_np == 0))
-----------+--+            fn = np.sum((predictions == 0) & (labels_np == 1))
-----------+--+            
-----------+--+            # Вычисляем FAR и FRR
-----------+--+            far = fp / (fp + tn) if (fp + tn) > 0 else 0
-----------+--+            frr = fn / (fn + tp) if (fn + tp) > 0 else 0
-----------+--+            
-----------+--+            far_values.append(far)
-----------+--+            frr_values.append(frr)
-----------+--+        
-----------+--+        # Находим точку, где FAR ≈ FRR
-----------+--+        far_values = np.array(far_values)
-----------+--+        frr_values = np.array(frr_values)
-----------+--+        
-----------+--+        # Находим индекс, где разность минимальна
-----------+--+        diff = np.abs(far_values - frr_values)
-----------+--+        min_idx = np.argmin(diff)
-----------+--+        
-----------+--+        # EER - это среднее FAR и FRR в этой точке
-----------+--+        eer = (far_values[min_idx] + frr_values[min_idx]) / 2
-----------+--+        
-----------+--+        return float(eer)
-----------+-- 
-----------+---    @classmethod
-----------+---    def compute_eer(cls, bona_scores, spoof_scores):
-----------+---        frr, far, thresholds = cls.compute_det_curve(bona_scores, spoof_scores)
-----------+---        abs_diffs = np.abs(frr - far)
-----------+---        min_index = np.argmin(abs_diffs)
-----------+---        eer = np.mean((frr[min_index], far[min_index]))
-----------+---        return eer, thresholds[min_index]
-----------+--\ No newline at end of file
-----------+--+    def set_debug_mode(self, debug_forward=False):
-----------+--+        """
-----------+--+        Включает режим отладки для логирования forward pass.
-----------+--+        
-----------+--+        Args:
-----------+--+            debug_forward (bool): логировать forward pass
-----------+--+        """
-----------+--+        self._debug_forward = debug_forward
-----------+--+        if debug_forward:
-----------+--+            print(f"🐛 Режим отладки включен для {self.__class__.__name__}")
-----------+--+            print(f"   📈 Debug forward: {debug_forward}")
-----------+--\ No newline at end of file
----------- --diff --git a/src/model/model.py b/src/model/model.py
--------------index 6d0bf94..28a4ce4 100644
-----------+--index 28a4ce4..6ec39da 100644
----------- ----- a/src/model/model.py
----------- --+++ b/src/model/model.py
--------------@@ -66,13 +66,29 @@ class LCNN(nn.Module):
-----------+--@@ -1,153 +1,113 @@
-----------+-- import torch
-----------+---from torch import nn
-----------+--+import torch.nn as nn
-----------+--+from typing import Dict, Any
-----------+-- 
-----------+---class mfm_block(nn.Module):
-----------+---    def __init__(self, channels):
-----------+---        super().__init__()
-----------+---        self.channels = channels
-----------+---
-----------+---    def forward(self, x):
-----------+---        partition = self.channels // 2
-----------+---        first_batch = x[:, :partition, ...]
-----------+---        second_batch = x[:, partition:, ...]
-----------+---        output = torch.maximum(first_batch, second_batch)
-----------+---        return output
-----------+-- 
-----------+-- class LCNN(nn.Module):
-----------+---    def __init__(self, in_channels=1, num_classes=2, dropout_p=0.3):
-----------+---        super().__init__()
-----------+---
-----------+---        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=5, stride=1, padding=2)
-----------+---        self.mfm2 = mfm_block(64)
-----------+---        self.dropout2 = nn.Dropout2d(dropout_p)
-----------+---        self.MaxPool3 = nn.MaxPool2d(kernel_size=2, stride=2)
-----------+---
-----------+---        self.conv4 = nn.Conv2d(32, 64, kernel_size=1, stride=1)
-----------+---        self.mfm5 = mfm_block(64)
-----------+---        self.dropout5 = nn.Dropout2d(dropout_p)
-----------+---        self.BatchNorm6 = nn.BatchNorm2d(32)
-----------+---
-----------+---        self.conv7 = nn.Conv2d(32, 96, kernel_size=3, stride=1, padding=1)
-----------+---        self.mfm8 = mfm_block(96)
-----------+---        self.dropout8 = nn.Dropout2d(dropout_p)
-----------+---
-----------+---        self.MaxPool9 = nn.MaxPool2d(kernel_size=2, stride=2)
-----------+---        self.BatchNorm10 = nn.BatchNorm2d(48)
-----------+---
-----------+---        self.conv11 = nn.Conv2d(48, 96, kernel_size=1, stride=1)
-----------+---        self.mfm12 = mfm_block(96)
-----------+---        self.dropout12 = nn.Dropout2d(dropout_p)
-----------+---        self.BatchNorm13 = nn.BatchNorm2d(48)
-----------+---
-----------+---        self.conv14 = nn.Conv2d(48, 128, kernel_size=3, stride=1, padding=1)
-----------+---        self.mfm15 = mfm_block(128)
-----------+---        self.dropout15 = nn.Dropout2d(dropout_p)
-----------+---
-----------+---        self.MaxPool16 = nn.MaxPool2d(kernel_size=2, stride=2)
-----------+---
-----------+---        self.conv17 = nn.Conv2d(64, 128, kernel_size=1, stride=1)
-----------+---        self.mfm18 = mfm_block(128)
-----------+---        self.dropout18 = nn.Dropout2d(dropout_p)
-----------+---        self.BatchNorm19 = nn.BatchNorm2d(64)
-----------+---
-----------+---        self.conv20 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
-----------+---        self.mfm21 = mfm_block(64)
-----------+---        self.dropout21 = nn.Dropout2d(dropout_p)
-----------+---        self.BatchNorm22 = nn.BatchNorm2d(32)
-----------+---
-----------+---        self.conv23 = nn.Conv2d(32, 64, kernel_size=1, stride=1)
-----------+---        self.mfm24 = mfm_block(64)
-----------+---        self.dropout24 = nn.Dropout2d(dropout_p)
-----------+---        self.BatchNorm25 = nn.BatchNorm2d(32)
-----------+---
-----------+---        self.conv26 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
-----------+---        self.mfm27 = mfm_block(64)
-----------+---        self.dropout27 = nn.Dropout2d(dropout_p)
-----------+---
-----------+---        self.MaxPool28 = nn.MaxPool2d(kernel_size=2, stride=2)
-----------+---
-----------+---        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
-----------+---        self.fc29 = nn.Linear(32, 160)
-----------+---        self.dropout29 = nn.Dropout(dropout_p)
-----------+---        self.mfm30 = mfm_block(160)
-----------+---        self.BatchNorm31 = nn.BatchNorm1d(80)
-----------+---        self.fc32 = nn.Linear(80, num_classes)
-----------+--+    """
-----------+--+    Light CNN model for audio anti-spoofing.
-----------+--+    """
-----------+--+
-----------+--+    def __init__(self, num_classes=2, **kwargs):
-----------+--+        """
-----------+--+        Args:
-----------+--+            num_classes (int): number of output classes
-----------+--+            **kwargs: additional arguments
-----------+--+        """
-----------+--+        super(LCNN, self).__init__()
-----------+--         
-----------+---        # Инициализация весов
-----------+---        self._initialize_weights()
-----------+---
-----------+---    def _initialize_weights(self):
-----------+---        """Инициализация весов для лучшего обучения"""
-----------+---        for m in self.modules():
-----------+---            if isinstance(m, nn.Conv2d):
-----------+---                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
-----------+---                if m.bias is not None:
-----------+---                    nn.init.constant_(m.bias, 0)
-----------+---            elif isinstance(m, nn.BatchNorm2d):
-----------+---                nn.init.constant_(m.weight, 1)
-----------+---                nn.init.constant_(m.bias, 0)
-----------+---            elif isinstance(m, nn.Linear):
-----------+---                nn.init.normal_(m.weight, 0, 0.01)
-----------+---                nn.init.constant_(m.bias, 0)
-----------+---
-----------+---    def forward(self, data_object, **kwargs):
-----------+---        x = data_object
-----------+---        x = self.conv1(x)
-----------+---        x = self.mfm2(x)
-----------+---        x = self.dropout2(x)
-----------+---        x = self.MaxPool3(x)
-----------+---
-----------+---        x = self.conv4(x)
-----------+---        x = self.mfm5(x)
-----------+---        x = self.dropout5(x)
-----------+---        x = self.BatchNorm6(x)
-----------+---
-----------+---        x = self.conv7(x)
-----------+---        x = self.mfm8(x)
-----------+---        x = self.dropout8(x)
-----------+---
-----------+---        x = self.MaxPool9(x)
-----------+---        x = self.BatchNorm10(x)
-----------+---
-----------+---        x = self.conv11(x)
-----------+---        x = self.mfm12(x)
-----------+---        x = self.dropout12(x)
-----------+---        x = self.BatchNorm13(x)
-----------+---
-----------+---        x = self.conv14(x)
-----------+---        x = self.mfm15(x)
-----------+---        x = self.dropout15(x)
-----------+---
-----------+---        x = self.MaxPool16(x)
-----------+---
-----------+---        x = self.conv17(x)
-----------+---        x = self.mfm18(x)
-----------+---        x = self.dropout18(x)
-----------+---        x = self.BatchNorm19(x)
-----------+---
-----------+---        x = self.conv20(x)
-----------+---        x = self.mfm21(x)
-----------+---        x = self.dropout21(x)
-----------+---        x = self.BatchNorm22(x)
-----------+---
-----------+---        x = self.conv23(x)
-----------+---        x = self.mfm24(x)
-----------+---        x = self.dropout24(x)
-----------+---        x = self.BatchNorm25(x)
-----------+---
-----------+---        x = self.conv26(x)
-----------+---        x = self.mfm27(x)
-----------+---        x = self.dropout27(x)
-----------+--+        self.num_classes = num_classes
-----------+--+        
-----------+--+        # Определяем архитектуру
-----------+--+        self.features = nn.Sequential(
-----------+--+            # Первый блок
-----------+--+            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),
-----------+--+            nn.BatchNorm2d(64),
-----------+--+            nn.ReLU(inplace=True),
-----------+--+            nn.MaxPool2d(kernel_size=2, stride=2),
-----------+--+            
-----------+--+            # Второй блок
-----------+--+            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
-----------+--+            nn.BatchNorm2d(128),
-----------+--+            nn.ReLU(inplace=True),
-----------+--+            nn.MaxPool2d(kernel_size=2, stride=2),
-----------+--+            
-----------+--+            # Третий блок
-----------+--+            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
-----------+--+            nn.BatchNorm2d(256),
-----------+--+            nn.ReLU(inplace=True),
-----------+--+            nn.MaxPool2d(kernel_size=2, stride=2),
-----------+--+            
-----------+--+            # Четвертый блок
-----------+--+            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
-----------+--+            nn.BatchNorm2d(512),
-----------+--+            nn.ReLU(inplace=True),
-----------+--+            nn.MaxPool2d(kernel_size=2, stride=2),
-----------+--+        )
-----------+--+        
-----------+--+        # Global Average Pooling
-----------+--+        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))
-----------+--+        
-----------+--+        # Классификатор
-----------+--+        self.classifier = nn.Sequential(
-----------+--+            nn.Dropout(0.5),
-----------+--+            nn.Linear(512, 256),
-----------+--+            nn.ReLU(inplace=True),
-----------+--+            nn.Dropout(0.5),
-----------+--+            nn.Linear(256, num_classes)
-----------+--+        )
-----------+--+
-----------+--+    def forward(self, **batch) -> Dict[str, torch.Tensor]:
-----------+--+        """
-----------+--+        Forward pass of the model.
-----------+--+        
-----------+--+        Args:
-----------+--+            **batch: input batch containing tensors
-----------+--+            
-----------+--+        Returns:
-----------+--+            Dict[str, torch.Tensor]: model outputs
-----------+--+        """
-----------+--+        # Получаем входные данные
-----------+--+        if 'spectrogram' in batch:
-----------+--+            x = batch['spectrogram']
-----------+--+        elif 'data_object' in batch:
-----------+--+            x = batch['data_object']
-----------+--+        else:
-----------+--+            # Берем первый тензор из батча
-----------+--+            x = next(iter(batch.values()))
-----------+--+        
-----------+--+        # Убеждаемся, что входные данные имеют правильную форму
-----------+--+        if x.dim() == 3:
-----------+--+            x = x.unsqueeze(1)  # Добавляем канал
-----------+--+        elif x.dim() == 2:
-----------+--+            x = x.unsqueeze(0).unsqueeze(0)  # Добавляем batch и канал
-----------+--+        
-----------+--+        # Проходим через слои
-----------+--+        x = self.features(x)
-----------+--+        
-----------+--+        x = self.global_avg_pool(x)
-----------+--+        x = x.view(x.size(0), -1)
-----------+--+        
-----------+--+        x = self.classifier(x)
-----------+--+        
-----------+--+        # Возвращаем выходы
-----------+--+        outputs = {
-----------+--+            'logits': x
-----------+--+        }
-----------+--+        
-----------+--+        return outputs
-----------+-- 
-----------+---        x = self.MaxPool28(x)
-----------+-- 
-----------+---        x = self.adaptive_pool(x)
-----------+---        x = x.view(x.size(0), -1)
-----------+---        x = self.fc29(x)
-----------+---        x = self.dropout29(x)
-----------+---        x = x.unsqueeze(-1).unsqueeze(-1)
-----------+---        x = self.mfm30(x)
-----------+---        x = x.squeeze(-1).squeeze(-1)
-----------+---        x = self.BatchNorm31(x)
-----------+---        logits = self.fc32(x)
-----------+---        return {"logits": logits}
-----------+--\ No newline at end of file
-----------+--+# Создаем экземпляр модели для совместимости с hydra
-----------+--+def create_model(**kwargs) -> LCNN:
-----------+--+    """
-----------+--+    Создает экземпляр модели LCNN.
-----------+--+    
-----------+--+    Args:
-----------+--+        **kwargs: параметры модели
-----------+--+        
-----------+--+    Returns:
-----------+--+        LCNN: экземпляр модели
-----------+--+    """
-----------+--+    model = LCNN(**kwargs)
-----------+--+    return model
-----------+--\ No newline at end of file
-----------+--diff --git a/src/trainer/base_trainer.py b/src/trainer/base_trainer.py
-----------+--index e35ffba..0d4e7a1 100644
-----------+----- a/src/trainer/base_trainer.py
-----------+--+++ b/src/trainer/base_trainer.py
-----------+--@@ -148,250 +148,224 @@ class BaseTrainer:
-----------+--         """
-----------+--         try:
-----------+--             self._train_process()
-----------+---        except KeyboardInterrupt as e:
-----------+---            self.logger.info("Saving model on keyboard interrupt")
-----------+---            self._save_checkpoint(self._last_epoch, save_best=False)
-----------+---            raise e
-----------+--+        except KeyboardInterrupt:
-----------+--+            self._save_checkpoint(self._last_epoch, save_best=False, only_best=True)
-----------+--+            raise
-----------+--+        except Exception as e:
-----------+--+            raise
-----------+-- 
-----------+--     def _train_process(self):
-----------+--         """
-----------+---        Full training logic:
-----------+---
-----------+---        Training model for an epoch, evaluating it on non-train partitions,
-----------+---        and monitoring the performance improvement (for early stopping
-----------+---        and saving the best checkpoint).
-----------+--+        Full training logic.
-----------+--         """
-----------+--         not_improved_count = 0
-----------+--         for epoch in range(self.start_epoch, self.epochs + 1):
-----------+--             self._last_epoch = epoch
-----------+---            result = self._train_epoch(epoch)
-----------+---
-----------+---            # save logged information into logs dict
-----------+---            logs = {"epoch": epoch}
-----------+---            logs.update(result)
-----------+--+            self._train_epoch(epoch)
-----------+-- 
-----------+---            # print logged information to the screen
-----------+---            for key, value in logs.items():
-----------+---                self.logger.info(f"    {key:15s}: {value}")
-----------+--+            # Валидируем только на val, test оставляем для инференса
-----------+--+            if "val" in self.evaluation_dataloaders:
-----------+--+                val_logs = {}
-----------+--+                dataloader = self.evaluation_dataloaders["val"]
-----------+--+                val_part_logs = self._evaluation_epoch(epoch, "val", dataloader)
-----------+--+                val_logs.update(val_part_logs)
-----------+-- 
-----------+---            # evaluate model performance according to configured metric,
-----------+---            # save best checkpoint as model_best
-----------+---            best, stop_process, not_improved_count = self._monitor_performance(
-----------+---                logs, not_improved_count
-----------+---            )
-----------+--+                # log best so far
-----------+--+                if self.mnt_mode != "off":
-----------+--+                    improved = self._monitor_performance(val_logs, not_improved_count)
-----------+--+                    if improved:
-----------+--+                        not_improved_count = 0
-----------+--+                    else:
-----------+--+                        not_improved_count += 1
-----------+-- 
-----------+---            if epoch % self.save_period == 0 or best:
-----------+---                self._save_checkpoint(epoch, save_best=best, only_best=True)
-----------+--+                if self.mnt_mode != "off" and not_improved_count > self.early_stop:
-----------+--+                    break
-----------+-- 
-----------+---            if stop_process:  # early_stop
-----------+---                break
-----------+--+            if epoch % self.save_period == 0:
-----------+--+                self._save_checkpoint(epoch, save_best=False)
-----------+-- 
-----------+--     def _train_epoch(self, epoch):
-----------+--         """
-----------+---        Training logic for an epoch, including logging and evaluation on
-----------+---        non-train partitions.
-----------+--+        Training logic for an epoch.
-----------+-- 
-----------+--         Args:
-----------+---            epoch (int): current training epoch.
-----------+---        Returns:
-----------+---            logs (dict): logs that contain the average loss and metric in
-----------+---                this epoch.
-----------+--+            epoch (int): Current epoch number.
-----------+--         """
-----------+---        self.is_train = True
-----------+--         self.model.train()
-----------+--         self.train_metrics.reset()
-----------+---        self.writer.set_step((epoch - 1) * self.epoch_len)
-----------+---        self.writer.add_scalar("epoch", epoch)
-----------+---        for batch_idx, batch in enumerate(
-----------+---            tqdm(self.train_dataloader, desc="train", total=self.epoch_len)
-----------+---        ):
-----------+--+        
-----------+--+        pbar = tqdm(self.train_dataloader, desc=f"Train Epoch {epoch}")
-----------+--+        for batch_idx, batch in enumerate(pbar):
-----------+--             try:
-----------+---                batch = self.process_batch(
-----------+---                    batch,
-----------+---                    metrics=self.train_metrics,
-----------+---                )
-----------+---            except torch.cuda.OutOfMemoryError as e:
-----------+---                if self.skip_oom:
-----------+---                    self.logger.warning("OOM on batch. Skipping batch.")
-----------+---                    torch.cuda.empty_cache()  # free some memory
-----------+--+                batch = self.process_batch(batch, self.train_metrics)
-----------+--+                self._log_batch(batch_idx, batch, "train")
-----------+--+                
-----------+--+                # Выводим лосс в консоль каждые 50 батчей
-----------+--+                if batch_idx % 50 == 0:
-----------+--+                    loss_key = self.config.writer.loss_names[0]
-----------+--+                    current_loss = self.train_metrics.avg(loss_key)
-----------+--+                    print(f"[Batch {batch_idx}] Loss: {current_loss:.6f}")
-----------+--+                
-----------+--+                # Валидация в середине эпохи
-----------+--+                if batch_idx == len(self.train_dataloader) // 2 and "val" in self.evaluation_dataloaders:
-----------+--+                    self._quick_validation(epoch, "val", self.evaluation_dataloaders["val"])
-----------+--+                    
-----------+--+            except RuntimeError as e:
-----------+--+                if "out of memory" in str(e) and self.skip_oom:
-----------+--+                    if hasattr(torch.cuda, 'empty_cache'):
-----------+--+                        torch.cuda.empty_cache()
-----------+--                     continue
-----------+--                 else:
-----------+--                     raise e
-----------+--+                    
-----------+--+        self._log_scalars(self.train_metrics)
-----------+--+
-----------+--+    def _quick_validation(self, epoch, part, dataloader):
-----------+--+        """
-----------+--+        Быстрая валидация для отображения EER в середине эпохи.
-----------+-- 
-----------+---            self.train_metrics.update("grad_norm", self._get_grad_norm())
-----------+---
-----------+---            # log current results
-----------+---            if batch_idx % self.log_step == 0:
-----------+---                self.writer.set_step((epoch - 1) * self.epoch_len + batch_idx)
-----------+---                self.logger.debug(
-----------+---                    "Train Epoch: {} {} Loss: {:.6f}".format(
-----------+---                        epoch, self._progress(batch_idx), batch["loss"].item()
-----------+---                    )
-----------+---                )
-----------+---                self.writer.add_scalar(
-----------+---                    "learning rate", self.lr_scheduler.get_last_lr()[0]
-----------+---                )
-----------+---                self._log_scalars(self.train_metrics)
-----------+---                self._log_batch(batch_idx, batch)
-----------+---                # we don't want to reset train metrics at the start of every epoch
-----------+---                # because we are interested in recent train metrics
-----------+---                last_train_metrics = self.train_metrics.result()
-----------+---                self.train_metrics.reset()
-----------+---            if batch_idx + 1 >= self.epoch_len:
-----------+---                break
-----------+---
-----------+---        logs = last_train_metrics
-----------+---
-----------+---        # Run val/test
-----------+---        for part, dataloader in self.evaluation_dataloaders.items():
-----------+---            val_logs = self._evaluation_epoch(epoch, part, dataloader)
-----------+---            logs.update(**{f"{part}_{name}": value for name, value in val_logs.items()})
-----------+---
-----------+---        return logs
-----------+--+        Args:
-----------+--+            epoch (int): Current epoch number.
-----------+--+            part (str): Name of the data part.
-----------+--+            dataloader (DataLoader): Dataloader for validation.
-----------+--+        """
-----------+--+        self.model.eval()
-----------+--+        temp_metrics = MetricTracker(
-----------+--+            *self.config.writer.loss_names,
-----------+--+            *[m.name for m in self.metrics["inference"]],
-----------+--+            writer=None,  # Не логируем в writer для быстрой валидации
-----------+--+        )
-----------+--+        
-----------+--+        with torch.no_grad():
-----------+--+            # Обрабатываем только первые несколько батчей для быстрой оценки
-----------+--+            num_batches = min(10, len(dataloader))  # Максимум 10 батчей
-----------+--+            for batch_idx, batch in enumerate(dataloader):
-----------+--+                if batch_idx >= num_batches:
-----------+--+                    break
-----------+--+                    
-----------+--+                try:
-----------+--+                    batch = self.process_batch(batch, temp_metrics)
-----------+--+                except RuntimeError as e:
-----------+--+                    if "out of memory" in str(e) and self.skip_oom:
-----------+--+                        if hasattr(torch.cuda, 'empty_cache'):
-----------+--+                            torch.cuda.empty_cache()
-----------+--+                        continue
-----------+--+                    else:
-----------+--+                        raise e
-----------+-- 
-----------+--     def _evaluation_epoch(self, epoch, part, dataloader):
-----------+--         """
-----------+---        Evaluate model on the partition after training for an epoch.
-----------+--+        Validate after training an epoch.
-----------+-- 
-----------+--         Args:
-----------+---            epoch (int): current training epoch.
-----------+---            part (str): partition to evaluate on
-----------+---            dataloader (DataLoader): dataloader for the partition.
-----------+--+            epoch (int): Current epoch number.
-----------+--+            part (str): Name of the data part.
-----------+--+            dataloader (DataLoader): Dataloader for validation.
-----------+--+
-----------+--         Returns:
-----------+---            logs (dict): logs that contain the information about evaluation.
-----------+--+            dict: Dictionary with validation logs.
-----------+--         """
-----------+---        self.is_train = False
-----------+--         self.model.eval()
-----------+--         self.evaluation_metrics.reset()
-----------+--+        
-----------+--         with torch.no_grad():
-----------+---            for batch_idx, batch in tqdm(
-----------+---                enumerate(dataloader),
-----------+---                desc=part,
-----------+---                total=len(dataloader),
-----------+---            ):
-----------+---                batch = self.process_batch(
-----------+---                    batch,
-----------+---                    metrics=self.evaluation_metrics,
-----------+---                )
-----------+---            self.writer.set_step(epoch * self.epoch_len, part)
-----------+---            self._log_scalars(self.evaluation_metrics)
-----------+---            self._log_batch(
-----------+---                batch_idx, batch, part
-----------+---            )  # log only the last batch during inference
-----------+---
-----------+--+            pbar = tqdm(dataloader, desc=f"Validation {part} Epoch {epoch}")
-----------+--+            for batch_idx, batch in enumerate(pbar):
-----------+--+                try:
-----------+--+                    batch = self.process_batch(batch, self.evaluation_metrics)
-----------+--+                    self._log_batch(batch_idx, batch, part)
-----------+--+                        
-----------+--+                except RuntimeError as e:
-----------+--+                    if "out of memory" in str(e) and self.skip_oom:
-----------+--+                        if hasattr(torch.cuda, 'empty_cache'):
-----------+--+                            torch.cuda.empty_cache()
-----------+--+                        continue
-----------+--+                    else:
-----------+--+                        raise e
-----------+--+
-----------+--+        self._log_scalars(self.evaluation_metrics)
-----------+--         return self.evaluation_metrics.result()
-----------+-- 
-----------+--     def _monitor_performance(self, logs, not_improved_count):
-----------+--         """
-----------+---        Check if there is an improvement in the metrics. Used for early
-----------+---        stopping and saving the best checkpoint.
-----------+--+        Monitor the performance and save the best model.
-----------+-- 
-----------+--         Args:
-----------+---            logs (dict): logs after training and evaluating the model for
-----------+---                an epoch.
-----------+---            not_improved_count (int): the current number of epochs without
-----------+---                improvement.
-----------+--+            logs (dict): Dictionary with validation logs.
-----------+--+            not_improved_count (int): Number of epochs without improvement.
-----------+--+
-----------+--         Returns:
-----------+---            best (bool): if True, the monitored metric has improved.
-----------+---            stop_process (bool): if True, stop the process (early stopping).
-----------+---                The metric did not improve for too much epochs.
-----------+---            not_improved_count (int): updated number of epochs without
-----------+---                improvement.
-----------+---        """
-----------+---        best = False
-----------+---        stop_process = False
-----------+---        if self.mnt_mode != "off":
-----------+---            try:
-----------+---                # check whether model performance improved or not,
-----------+---                # according to specified metric(mnt_metric)
-----------+---                if self.mnt_mode == "min":
-----------+---                    improved = logs[self.mnt_metric] <= self.mnt_best
-----------+---                elif self.mnt_mode == "max":
-----------+---                    improved = logs[self.mnt_metric] >= self.mnt_best
-----------+---                else:
-----------+---                    improved = False
-----------+---            except KeyError:
-----------+---                self.logger.warning(
-----------+---                    f"Warning: Metric '{self.mnt_metric}' is not found. "
-----------+---                    "Model performance monitoring is disabled."
-----------+---                )
-----------+---                self.mnt_mode = "off"
-----------+---                improved = False
-----------+---
-----------+---            if improved:
-----------+---                self.mnt_best = logs[self.mnt_metric]
-----------+---                not_improved_count = 0
-----------+---                best = True
-----------+---            else:
-----------+---                not_improved_count += 1
-----------+---
-----------+---            if not_improved_count >= self.early_stop:
-----------+---                self.logger.info(
-----------+---                    "Validation performance didn't improve for {} epochs. "
-----------+---                    "Training stops.".format(self.early_stop)
-----------+---                )
-----------+---                stop_process = True
-----------+---        return best, stop_process, not_improved_count
-----------+--+            bool: True if the model improved.
-----------+--+        """
-----------+--+        if self.mnt_mode == "off":
-----------+--+            return False
-----------+--+
-----------+--+        try:
-----------+--+            current = logs[self.mnt_metric]
-----------+--+        except KeyError:
-----------+--+            return False
-----------+--+
-----------+--+        if self.mnt_mode == "min":
-----------+--+            improved = current < self.mnt_best
-----------+--+        else:
-----------+--+            improved = current > self.mnt_best
-----------+--+
-----------+--+        if improved:
-----------+--+            self.mnt_best = current
-----------+--+            self._save_checkpoint(self._last_epoch, save_best=True)
-----------+--+
-----------+--+        return improved
-----------+-- 
-----------+--     def move_batch_to_device(self, batch):
-----------+--         """
-----------+---        Move all necessary tensors to the device.
-----------+--+        Move batch to device.
----------- -- 
--------------         self.MaxPool28 = nn.MaxPool2d(kernel_size=2, stride=2)
-----------+--         Args:
-----------+---            batch (dict): dict-based batch containing the data from
-----------+---                the dataloader.
-----------+--+            batch (dict): Batch to move to device.
-----------+--+
-----------+--         Returns:
-----------+---            batch (dict): dict-based batch containing the data from
-----------+---                the dataloader with some of the tensors on the device.
-----------+--+            dict: Batch on device.
-----------+--         """
-----------+---        for tensor_for_device in self.cfg_trainer.device_tensors:
-----------+---            batch[tensor_for_device] = batch[tensor_for_device].to(self.device)
-----------+--+        for k, v in batch.items():
-----------+--+            if isinstance(v, torch.Tensor):
-----------+--+                batch[k] = v.to(self.device)
-----------+--         return batch
----------- -- 
-----------+--     def transform_batch(self, batch):
-----------+--         """
-----------+---        Transforms elements in batch. Like instance transform inside the
-----------+---        BaseDataset class, but for the whole batch. Improves pipeline speed,
-----------+---        especially if used with a GPU.
----------- ---
--------------         self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
--------------         self.fc29 = nn.Linear(32, 160)
--------------         self.dropout29 = nn.Dropout(dropout_p)
--------------         self.mfm30 = mfm_block(160)
--------------         self.BatchNorm31 = nn.BatchNorm1d(80)
--------------         self.fc32 = nn.Linear(80, num_classes)
--------------+        
--------------+        # Инициализация весов
--------------+        self._initialize_weights()
-----------+---        Each tensor in a batch undergoes its own transform defined by the key.
-----------+--+        Transform batch using batch transforms.
-----------+-- 
-----------+--         Args:
-----------+---            batch (dict): dict-based batch containing the data from
-----------+---                the dataloader.
-----------+--+            batch (dict): Batch to transform.
----------- --+
--------------+    def _initialize_weights(self):
--------------+        """Инициализация весов для лучшего обучения"""
--------------+        for m in self.modules():
--------------+            if isinstance(m, nn.Conv2d):
--------------+                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
--------------+                if m.bias is not None:
--------------+                    nn.init.constant_(m.bias, 0)
--------------+            elif isinstance(m, nn.BatchNorm2d):
--------------+                nn.init.constant_(m.weight, 1)
--------------+                nn.init.constant_(m.bias, 0)
--------------+            elif isinstance(m, nn.Linear):
--------------+                nn.init.normal_(m.weight, 0, 0.01)
--------------+                nn.init.constant_(m.bias, 0)
-------------- 
--------------     def forward(self, data_object, **kwargs):
--------------         x = data_object
-----------+--         Returns:
-----------+---            batch (dict): dict-based batch containing the data from
-----------+---                the dataloader (possibly transformed via batch transform).
-----------+---        """
-----------+---        # do batch transforms on device
-----------+---        transform_type = "train" if self.is_train else "inference"
-----------+---        transforms = self.batch_transforms.get(transform_type)
-----------+---        if transforms is not None:
-----------+---            for transform_name in transforms.keys():
-----------+---                batch[transform_name] = transforms[transform_name](
-----------+---                    batch[transform_name]
-----------+---                )
-----------+--+            dict: Transformed batch.
-----------+--+        """
-----------+--+        if self.batch_transforms is not None:
-----------+--+            for transform_name, transform in self.batch_transforms.items():
-----------+--+                if transform_name in batch:
-----------+--+                    batch[transform_name] = transform(batch[transform_name])
-----------+--         return batch
-----------+-- 
-----------+--     def _clip_grad_norm(self):
-----------+--         """
-----------+---        Clips the gradient norm by the value defined in
-----------+---        config.trainer.max_grad_norm
-----------+--+        Clip gradient norm.
-----------+--         """
-----------+---        if self.config["trainer"].get("max_grad_norm", None) is not None:
-----------+--+        if self.cfg_trainer.get("grad_clip_norm") is not None:
-----------+--             clip_grad_norm_(
-----------+---                self.model.parameters(), self.config["trainer"]["max_grad_norm"]
-----------+--+                self.model.parameters(), self.cfg_trainer.grad_clip_norm
-----------+--             )
-----------+-- 
-----------+--     @torch.no_grad()
-----------+--     def _get_grad_norm(self, norm_type=2):
-----------+--         """
-----------+---        Calculates the gradient norm for logging.
-----------+--+        Get gradient norm.
-----------+-- 
-----------+--         Args:
-----------+---            norm_type (float | str | None): the order of the norm.
-----------+--+            norm_type (int): Type of norm.
-----------+--+
-----------+--         Returns:
-----------+---            total_norm (float): the calculated norm.
-----------+--+            float: Gradient norm.
-----------+--         """
-----------+--         parameters = self.model.parameters()
-----------+--         if isinstance(parameters, torch.Tensor):
-----------+--@@ -401,17 +375,14 @@ class BaseTrainer:
-----------+--             torch.stack([torch.norm(p.grad.detach(), norm_type) for p in parameters]),
-----------+--             norm_type,
-----------+--         )
-----------+---        return total_norm.item()
-----------+--+        return total_norm
-----------+-- 
-----------+--     def _progress(self, batch_idx):
-----------+--         """
-----------+---        Calculates the percentage of processed batch within the epoch.
-----------+--+        Print progress.
-----------+-- 
-----------+--         Args:
-----------+---            batch_idx (int): the current batch index.
-----------+---        Returns:
-----------+---            progress (str): contains current step and percentage
-----------+---                within the epoch.
-----------+--+            batch_idx (int): Current batch index.
-----------+--         """
-----------+--         base = "[{}/{} ({:.0f}%)]"
-----------+--         if hasattr(self.train_dataloader, "n_samples"):
-----------+--@@ -425,129 +396,106 @@ class BaseTrainer:
-----------+--     @abstractmethod
-----------+--     def _log_batch(self, batch_idx, batch, mode="train"):
-----------+--         """
-----------+---        Abstract method. Should be defined in the nested Trainer Class.
-----------+---
-----------+--         Log data from batch. Calls self.writer.add_* to log data
-----------+--         to the experiment tracker.
-----------+-- 
-----------+--         Args:
-----------+---            batch_idx (int): index of the current batch.
-----------+---            batch (dict): dict-based batch after going through
-----------+---                the 'process_batch' function.
-----------+---            mode (str): train or inference. Defines which logging
-----------+---                rules to apply.
-----------+--+            batch_idx (int): Current batch index.
-----------+--+            batch (dict): Batch data.
-----------+--+            mode (str): Mode (train or validation).
-----------+--         """
-----------+---        return NotImplementedError()
-----------+--+        pass
-----------+-- 
-----------+--     def _log_scalars(self, metric_tracker: MetricTracker):
-----------+--         """
-----------+---        Wrapper around the writer 'add_scalar' to log all metrics.
-----------+--+        Log scalars to the experiment tracker.
-----------+-- 
-----------+--         Args:
-----------+---            metric_tracker (MetricTracker): calculated metrics.
-----------+--+            metric_tracker (MetricTracker): Metric tracker.
-----------+--         """
-----------+---        if self.writer is None:
-----------+---            return
-----------+---        for metric_name in metric_tracker.keys():
-----------+---            self.writer.add_scalar(f"{metric_name}", metric_tracker.avg(metric_name))
-----------+--+        for metric_name, metric_value in metric_tracker.result().items():
-----------+--+            self.writer.add_scalar(metric_name, metric_value)
-----------+-- 
-----------+--     def _save_checkpoint(self, epoch, save_best=False, only_best=False):
-----------+--         """
-----------+---        Save the checkpoints.
-----------+--+        Save checkpoint.
-----------+-- 
-----------+--         Args:
-----------+---            epoch (int): current epoch number.
-----------+---            save_best (bool): if True, rename the saved checkpoint to 'model_best.pth'.
-----------+---            only_best (bool): if True and the checkpoint is the best, save it only as
-----------+---                'model_best.pth'(do not duplicate the checkpoint as
-----------+---                checkpoint-epochEpochNumber.pth)
-----------+--+            epoch (int): Current epoch number.
-----------+--+            save_best (bool): Whether to save the best model.
-----------+--+            only_best (bool): Whether to save only the best model.
-----------+--         """
-----------+--         arch = type(self.model).__name__
-----------+--+
-----------+--         state = {
-----------+--             "arch": arch,
-----------+--             "epoch": epoch,
-----------+--             "state_dict": self.model.state_dict(),
-----------+--             "optimizer": self.optimizer.state_dict(),
-----------+---            "lr_scheduler": self.lr_scheduler.state_dict(),
-----------+--             "monitor_best": self.mnt_best,
-----------+--             "config": self.config,
-----------+--         }
-----------+---        filename = str(self.checkpoint_dir / f"checkpoint-epoch{epoch}.pth")
-----------+---        if not (only_best and save_best):
-----------+---            torch.save(state, filename)
-----------+---            if self.config.writer.log_checkpoints:
-----------+---                self.writer.add_checkpoint(filename, str(self.checkpoint_dir.parent))
-----------+---            self.logger.info(f"Saving checkpoint: {filename} ...")
-----------+--+
-----------+--+        if self.lr_scheduler is not None:
-----------+--+            state["lr_scheduler"] = self.lr_scheduler.state_dict()
-----------+--+
-----------+--+        filename = str(self.checkpoint_dir / "checkpoint-epoch{}.pth".format(epoch))
-----------+--+        if not (self.checkpoint_dir).exists():
-----------+--+            self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
-----------+--+
-----------+--         if save_best:
-----------+--             best_path = str(self.checkpoint_dir / "model_best.pth")
-----------+--             torch.save(state, best_path)
-----------+---            if self.config.writer.log_checkpoints:
-----------+---                self.writer.add_checkpoint(best_path, str(self.checkpoint_dir.parent))
-----------+---            self.logger.info("Saving current best: model_best.pth ...")
-----------+--+            del state["optimizer"], state["lr_scheduler"], state["config"]
-----------+--+            torch.save(state, best_path + ".tmp")
-----------+--+            import os
-----------+--+            os.replace(best_path + ".tmp", best_path)
-----------+--+        elif not only_best:
-----------+--+            torch.save(state, filename)
-----------+--+            del state["optimizer"], state["lr_scheduler"], state["config"]
-----------+--+            torch.save(state, filename + ".tmp")
-----------+--+            import os
-----------+--+            os.replace(filename + ".tmp", filename)
-----------+-- 
-----------+--     def _resume_checkpoint(self, resume_path):
-----------+--         """
-----------+---        Resume from a saved checkpoint (in case of server crash, etc.).
-----------+---        The function loads state dicts for everything, including model,
-----------+---        optimizers, etc.
-----------+---
-----------+---        Notice that the checkpoint should be located in the current experiment
-----------+---        saved directory (where all checkpoints are saved in '_save_checkpoint').
-----------+--+        Resume from saved checkpoint.
-----------+-- 
-----------+--         Args:
-----------+---            resume_path (str): Path to the checkpoint to be resumed.
-----------+--+            resume_path (str): Path to checkpoint.
-----------+--         """
-----------+--         resume_path = str(resume_path)
-----------+---        self.logger.info(f"Loading checkpoint: {resume_path} ...")
-----------+---        checkpoint = torch.load(resume_path, self.device)
-----------+--+        checkpoint = torch.load(resume_path, map_location=self.device)
-----------+--         self.start_epoch = checkpoint["epoch"] + 1
-----------+--         self.mnt_best = checkpoint["monitor_best"]
-----------+-- 
-----------+--         # load architecture params from checkpoint.
-----------+--         if checkpoint["config"]["model"] != self.config["model"]:
-----------+--             self.logger.warning(
-----------+---                "Warning: Architecture configuration given in the config file is different from that "
-----------+---                "of the checkpoint. This may yield an exception when state_dict is loaded."
-----------+--+                "Warning: Architecture configuration given in config file is different from that of checkpoint. "
-----------+--+                "This may create an exception while state_dict is being loaded."
-----------+--             )
-----------+--         self.model.load_state_dict(checkpoint["state_dict"])
-----------+-- 
-----------+--         # load optimizer state from checkpoint only when optimizer type is not changed.
-----------+---        if (
-----------+---            checkpoint["config"]["optimizer"] != self.config["optimizer"]
-----------+---            or checkpoint["config"]["lr_scheduler"] != self.config["lr_scheduler"]
-----------+---        ):
-----------+--+        if checkpoint["config"]["optimizer"] != self.config["optimizer"]:
-----------+--             self.logger.warning(
-----------+---                "Warning: Optimizer or lr_scheduler given in the config file is different "
-----------+---                "from that of the checkpoint. Optimizer and scheduler parameters "
-----------+---                "are not resumed."
-----------+--+                "Warning: Optimizer or lr_scheduler given in config file is different "
-----------+--+                "from that of checkpoint. Optimizer parameters not being resumed."
-----------+--             )
-----------+--         else:
-----------+--             self.optimizer.load_state_dict(checkpoint["optimizer"])
-----------+---            self.lr_scheduler.load_state_dict(checkpoint["lr_scheduler"])
-----------+-- 
-----------+---        self.logger.info(
-----------+---            f"Checkpoint loaded. Resume training from epoch {self.start_epoch}"
-----------+---        )
-----------+--+        if self.lr_scheduler is not None and "lr_scheduler" in checkpoint:
-----------+--+            self.lr_scheduler.load_state_dict(checkpoint["lr_scheduler"])
-----------+-- 
-----------+--     def _from_pretrained(self, pretrained_path):
-----------+--         """
-----------+---        Init model with weights from pretrained pth file.
-----------+---
-----------+---        Notice that 'pretrained_path' can be any path on the disk. It is not
-----------+---        necessary to locate it in the experiment saved dir. The function
-----------+---        initializes only the model.
-----------+--+        Load pretrained model.
-----------+-- 
-----------+--         Args:
-----------+---            pretrained_path (str): path to the model state dict.
-----------+--+            pretrained_path (str): Path to pretrained model.
-----------+--         """
-----------+--         pretrained_path = str(pretrained_path)
-----------+---        if hasattr(self, "logger"):  # to support both trainer and inferencer
-----------+---            self.logger.info(f"Loading model weights from: {pretrained_path} ...")
-----------+---        else:
-----------+---            print(f"Loading model weights from: {pretrained_path} ...")
-----------+---        checkpoint = torch.load(pretrained_path, self.device)
-----------+---
-----------+---        if checkpoint.get("state_dict") is not None:
-----------+---            self.model.load_state_dict(checkpoint["state_dict"])
-----------+---        else:
-----------+---            self.model.load_state_dict(checkpoint)
-----------+--\ No newline at end of file
-----------+--+        checkpoint = torch.load(pretrained_path, map_location=self.device)
-----------+--+        self.model.load_state_dict(checkpoint["state_dict"])
-----------+--\ No newline at end of file
----------- --diff --git a/src/trainer/trainer.py b/src/trainer/trainer.py
--------------index 1b806fb..3313fea 100644
-----------+--index 3313fea..f2b2faa 100644
----------- ----- a/src/trainer/trainer.py
----------- --+++ b/src/trainer/trainer.py
--------------@@ -47,17 +47,17 @@ class Trainer(BaseTrainer):
--------------             if self.lr_scheduler is not None:
--------------                 self.lr_scheduler.step()
-------------- 
---------------        
--------------+        # Обновляем loss метрики
--------------         for loss_name in self.config.writer.loss_names:
--------------             metrics.update(loss_name, batch[loss_name].item())
-------------- 
---------------      
--------------+        # Обновляем EER метрику
--------------         if "logits" in batch:
--------------             scores = torch.softmax(batch["logits"], dim=1)[:, 1]
--------------             labels = batch["labels"]
--------------             metrics.update_eer(scores, labels)
-------------- 
---------------       
--------------+        # Обновляем остальные метрики
-----------+--@@ -61,9 +61,9 @@ class Trainer(BaseTrainer):
----------- --         for met in metric_funcs:
----------- --             if met.name != "eer":
----------- --                 try:
-------------diff --git a/requirements.txt b/requirements.txt
-------------index 8aab454..1dc9376 100644
---------------- a/requirements.txt
-------------+++ b/requirements.txt
-------------@@ -1,37 +1,24 @@
--------------# Основные PyTorch зависимости
------------- torch==2.2.0
------------- torchvision==0.17.0
------------- torchaudio==2.2.0
------------- torchmetrics==1.7.4
--------------
--------------# Научные вычисления и обработка данных
------------- numpy==1.26.4
------------- pandas==2.3.1
------------- matplotlib==3.9.4
------------- scipy
--------------
--------------# Аудио обработка
------------- soundfile==0.13.1
------------- librosa
--------------
--------------# Логирование и эксперименты
------------- wandb==0.21.0
------------- comet-ml==3.50.0
------------- hydra-core==1.3.2
------------- omegaconf==2.3.0
--------------
--------------# Утилиты
------------- tqdm==4.67.1
------------- psutil==7.0.0
------------- requests==2.32.4
------------- pyyaml==6.0.2
--------------
--------------# Разработка и форматирование кода
------------- black
------------- isort
------------- pre-commit
------------- flake8
--------------
--------------# Дополнительные зависимости для ML
------------- scikit-learn
------------- seaborn
-------------\ No newline at end of file
-------------diff --git a/src/configs/dataloader/default.yaml b/src/configs/dataloader/default.yaml
-------------index 80fbc65..902e80f 100644
---------------- a/src/configs/dataloader/default.yaml
-------------+++ b/src/configs/dataloader/default.yaml
-------------@@ -1,4 +1,4 @@
------------- _target_: torch.utils.data.DataLoader
--------------batch_size: 8
-------------+batch_size: 16
------------- num_workers: 4
------------- pin_memory: true 
-------------\ No newline at end of file
-------------diff --git a/src/configs/lr_scheduler/step.yaml b/src/configs/lr_scheduler/step.yaml
-------------index bd12a00..3c208ac 100644
---------------- a/src/configs/lr_scheduler/step.yaml
-------------+++ b/src/configs/lr_scheduler/step.yaml
-------------@@ -1,3 +1,3 @@
------------- _target_: torch.optim.lr_scheduler.StepLR
--------------step_size: 10
--------------gamma: 0.1 
-------------\ No newline at end of file
-------------+step_size: 20
-------------+gamma: 0.5 
-------------\ No newline at end of file
-------------diff --git a/src/configs/optimizer/adam.yaml b/src/configs/optimizer/adam.yaml
-------------index 9af2fd8..1310b87 100644
---------------- a/src/configs/optimizer/adam.yaml
-------------+++ b/src/configs/optimizer/adam.yaml
-------------@@ -1,3 +1,3 @@
------------- _target_: torch.optim.Adam
--------------lr: 0.0001
-------------+lr: 0.001
------------- weight_decay: 0.0001 
-------------\ No newline at end of file
-------------diff --git a/src/configs/transforms/default.yaml b/src/configs/transforms/default.yaml
-------------index 4aea72d..32f1775 100644
---------------- a/src/configs/transforms/default.yaml
-------------+++ b/src/configs/transforms/default.yaml
-------------@@ -2,7 +2,10 @@ instance_transforms:
-------------   data_object: ${transforms.stft}
------------- 
------------- stft:
--------------  _target_: src.transforms.stft.AudioFrontend
-------------+  _target_: src.transforms.stft.STFTTransform
-------------+  n_fft: 1024
-------------+  hop_length: 512
-------------+  win_length: 1024
------------- 
------------- batch_transforms:
-------------   train:
-------------diff --git a/src/datasets/base_dataset.py b/src/datasets/base_dataset.py
-------------index bf51c70..e75525d 100644
---------------- a/src/datasets/base_dataset.py
-------------+++ b/src/datasets/base_dataset.py
-------------@@ -1,6 +1,6 @@
------------- import logging
------------- import random
--------------from typing import List
-------------+from typing import List, Dict, Any, Optional
------------- 
------------- import torch
------------- import torchaudio
-------------@@ -11,66 +11,65 @@ logger = logging.getLogger(__name__)
------------- 
------------- class BaseDataset(Dataset):
-------------     """
--------------    Base class for the datasets.
--------------
--------------    Given a proper index (list[dict]), allows to process different datasets
--------------    for the same task in the identical manner. Therefore, to work with
--------------    several datasets, the user only have to define index in a nested class.
-------------+    Base class for all datasets.
-------------     """
------------- 
-------------     def __init__(
--------------        self, index, limit=None, shuffle_index=False, instance_transforms=None
-------------+        self,
-------------+        index: List[Dict[str, Any]],
-------------+        instance_transforms: Optional[Dict[str, Any]] = None,
-------------+        *args,
-------------+        **kwargs,
-------------     ):
-------------         """
-------------         Args:
--------------            index (list[dict]): list, containing dict for each element of
--------------                the dataset. The dict has required metadata information,
--------------                such as label and object path.
--------------            limit (int | None): if not None, limit the total number of elements
--------------                in the dataset to 'limit' elements.
--------------            shuffle_index (bool): if True, shuffle the index. Uses python
--------------                random package with seed 42.
--------------            instance_transforms (dict[Callable] | None): transforms that
--------------                should be applied on the instance. Depend on the
--------------                tensor name.
--------------        """
--------------        self._assert_index_is_valid(index)
--------------
--------------        index = self._shuffle_and_limit_index(index, limit, shuffle_index)
--------------        self._index: List[dict] = index
--------------
-------------+            index (List[Dict[str, Any]]): list of dictionaries, each containing
-------------+                the data for one sample.
-------------+            instance_transforms (Optional[Dict[str, Any]]): transforms to apply
-------------+                to instances. Depend on the tensor name.
-------------+        """
-------------+        self.index = index
-------------         self.instance_transforms = instance_transforms
------------- 
--------------    def __getitem__(self, ind):
--------------        """
--------------        Get element from the index, preprocess it, and combine it
--------------        into a dict.
-------------+    def __len__(self):
-------------+        return len(self.index)
------------- 
--------------        Notice that the choice of key names is defined by the template user.
--------------        However, they should be consistent across dataset getitem, collate_fn,
--------------        loss_function forward method, and model forward method.
-------------+    def __getitem__(self, idx):
-------------+        """
-------------+        Get item by index.
------------- 
-------------         Args:
--------------            ind (int): index in the self.index list.
-------------+            idx (int): index of the item.
-------------+
-------------         Returns:
--------------            instance_data (dict): dict, containing instance
--------------                (a single dataset element).
-------------+            dict: item data.
-------------         """
--------------        data_dict = self._index[ind]
--------------        data_path = data_dict["path"]
--------------        data_object = self.load_object(data_path)
--------------        data_label = data_dict["label"]
-------------+        item = self.index[idx]
-------------+        
-------------+        # Применяем instance transforms
-------------+        if self.instance_transforms is not None:
-------------+            item = self._apply_instance_transforms(item)
-------------+        
-------------+        return item
------------- 
--------------        instance_data = {"data_object": data_object, "labels": data_label}
--------------        instance_data = self.preprocess_data(instance_data)
-------------+    def _apply_instance_transforms(self, item: Dict[str, Any]) -> Dict[str, Any]:
-------------+        """
-------------+        Apply instance transforms to the item.
------------- 
--------------        return instance_data
-------------+        Args:
-------------+            item (Dict[str, Any]): item data.
------------- 
--------------    def __len__(self):
--------------        """
--------------        Get length of the dataset (length of the index).
-------------+        Returns:
-------------+            Dict[str, Any]: transformed item data.
-------------         """
--------------        return len(self._index)
-------------+        for transform_name, transform in self.instance_transforms.items():
-------------+            if transform_name in item:
-------------+                try:
-------------+                    item[transform_name] = transform(item[transform_name])
-------------+                except Exception as e:
-------------+                    raise
-------------+        
-------------+        return item
------------- 
-------------     def load_object(self, path):
-------------         """
-------------@@ -126,74 +125,63 @@ class BaseDataset(Dataset):
-------------         the __init__ before shuffling and limiting.
------------- 
-------------         Args:
--------------            index (list[dict]): list, containing dict for each element of
--------------                the dataset. The dict has required metadata information,
--------------                such as label and object path.
-------------+            index (list): list of records to filter.
-------------+
-------------         Returns:
--------------            index (list[dict]): list, containing dict for each element of
--------------                the dataset that satisfied the condition. The dict has
--------------                required metadata information, such as label and object path.
-------------+            list: filtered list of records.
-------------         """
--------------        # Filter logic
--------------        pass
-------------+        return index
------------- 
-------------     @staticmethod
-------------     def _assert_index_is_valid(index):
-------------         """
--------------        Check the structure of the index and ensure it satisfies the desired
--------------        conditions.
-------------+        Assert that the index is valid.
------------- 
-------------         Args:
--------------            index (list[dict]): list, containing dict for each element of
--------------                the dataset. The dict has required metadata information,
--------------                such as label and object path.
--------------        """
--------------        for entry in index:
--------------            assert "path" in entry, (
--------------                "Each dataset item should include field 'path'" " - path to audio file."
--------------            )
--------------            assert "label" in entry, (
--------------                "Each dataset item should include field 'label'"
--------------                " - object ground-truth label."
--------------            )
-------------+            index (list): list of records to validate.
-------------+        """
-------------+        assert isinstance(index, list), "Index should be a list"
-------------+        assert len(index) > 0, "Index should not be empty"
-------------+        for record in index:
-------------+            assert isinstance(record, dict), "Each record should be a dict"
-------------+            assert "path" in record, "Each record should have a 'path' field"
-------------+            assert "label" in record, "Each record should have a 'label' field"
------------- 
-------------     @staticmethod
-------------     def _sort_index(index):
-------------         """
--------------        Sort index via some rules.
-------------+        Sort the index by some criterion.
------------- 
-------------         This is not used in the example. The method should be called in
--------------        the __init__ before shuffling and limiting and after filtering.
-------------+        the __init__ before shuffling and limiting.
------------- 
-------------         Args:
--------------            index (list[dict]): list, containing dict for each element of
--------------                the dataset. The dict has required metadata information,
--------------                such as label and object path.
-------------+            index (list): list of records to sort.
-------------+
-------------         Returns:
--------------            index (list[dict]): sorted list, containing dict for each element
--------------                of the dataset. The dict has required metadata information,
--------------                such as label and object path.
-------------+            list: sorted list of records.
-------------         """
--------------        return sorted(index, key=lambda x: x["KEY_FOR_SORTING"])
-------------+        return index
------------- 
-------------     @staticmethod
-------------     def _shuffle_and_limit_index(index, limit, shuffle_index):
-------------         """
--------------        Shuffle elements in index and limit the total number of elements.
-------------+        Shuffle and limit the index.
-------------+
-------------+        This is not used in the example. The method should be called in
-------------+        the __init__ before shuffling and limiting.
------------- 
-------------         Args:
--------------            index (list[dict]): list, containing dict for each element of
--------------                the dataset. The dict has required metadata information,
--------------                such as label and object path.
--------------            limit (int | None): if not None, limit the total number of elements
--------------                in the dataset to 'limit' elements.
--------------            shuffle_index (bool): if True, shuffle the index. Uses python
--------------                random package with seed 42.
-------------+            index (list): list of records to shuffle and limit.
-------------+            limit (int): maximum number of records to keep.
-------------+            shuffle_index (bool): whether to shuffle the index.
-------------+
-------------+        Returns:
-------------+            list: shuffled and limited list of records.
-------------         """
-------------         if shuffle_index:
-------------             random.seed(42)
-------------             random.shuffle(index)
--------------
-------------         if limit is not None:
-------------             index = index[:limit]
-------------         return index
-------------\ No newline at end of file
-------------diff --git a/src/datasets/collate.py b/src/datasets/collate.py
-------------index 4c2c81e..6cb3b10 100644
---------------- a/src/datasets/collate.py
-------------+++ b/src/datasets/collate.py
-------------@@ -19,6 +19,15 @@ def collate_fn(dataset_items: list[dict]):
------------- 
-------------     # Pad audio sequences to the same length
-------------     audio_tensors = [elem["data_object"] for elem in dataset_items]
-------------+    
-------------+    # Handle different audio tensor shapes
-------------+    if len(audio_tensors) == 0:
-------------+        # Return empty batch
-------------+        result_batch["data_object"] = torch.empty(0)
-------------+        result_batch["labels"] = torch.empty(0, dtype=torch.long)
-------------+        return result_batch
-------------+    
-------------+    # Get max length for padding
-------------     max_length = max(audio.shape[-1] for audio in audio_tensors)
-------------     
-------------     padded_audio = []
-------------@@ -30,6 +39,6 @@ def collate_fn(dataset_items: list[dict]):
-------------         padded_audio.append(audio)
-------------     
-------------     result_batch["data_object"] = torch.stack(padded_audio)
--------------    result_batch["labels"] = torch.tensor([elem["labels"] for elem in dataset_items])
-------------+    result_batch["labels"] = torch.tensor([elem["labels"] for elem in dataset_items], dtype=torch.long)
------------- 
-------------     return result_batch
-------------\ No newline at end of file
-------------diff --git a/src/datasets/data_utils.py b/src/datasets/data_utils.py
-------------index 8262ceb..63e8cce 100644
---------------- a/src/datasets/data_utils.py
-------------+++ b/src/datasets/data_utils.py
-------------@@ -36,6 +36,9 @@ def move_batch_transforms_to_device(batch_transforms, device):
-------------             tensor name.
-------------         device (str): device to use for batch transforms.
-------------     """
-------------+    if batch_transforms is None:
-------------+        return
-------------+        
-------------     for transform_type in batch_transforms.keys():
-------------         transforms = batch_transforms.get(transform_type)
-------------         if transforms is not None:
-------------@@ -60,6 +63,7 @@ def get_dataloaders(config, device):
-------------     """
-------------     # transforms or augmentations init
-------------     batch_transforms = instantiate(config.transforms.batch_transforms)
-------------+    
-------------     move_batch_transforms_to_device(batch_transforms, device)
------------- 
-------------     # dataset partitions init
-------------diff --git a/src/datasets/mydataset.py b/src/datasets/mydataset.py
-------------index 02a09c3..94e7e12 100644
---------------- a/src/datasets/mydataset.py
-------------+++ b/src/datasets/mydataset.py
-------------@@ -1,5 +1,6 @@
------------- import numpy as np
------------- import torch
-------------+import torchaudio
------------- from tqdm.auto import tqdm
------------- 
------------- from src.datasets.base_dataset import BaseDataset
-------------@@ -37,6 +38,50 @@ class AudioSpoofingDataset(BaseDataset):
------------- 
-------------         super().__init__(index, instance_transforms=instance_transforms, *args, **kwargs)
------------- 
-------------+    def __getitem__(self, idx):
-------------+        """
-------------+        Get item by index.
-------------+
-------------+        Args:
-------------+            idx (int): index of the item.
-------------+
-------------+        Returns:
-------------+            dict: item data with 'data_object' and 'labels' keys.
-------------+        """
-------------+        item = self.index[idx]
-------------+        
-------------+        # Load audio file
-------------+        audio_path = item["path"]
-------------+        label = item["label"]
-------------+        
-------------+        try:
-------------+            # Load audio using torchaudio
-------------+            waveform, sample_rate = torchaudio.load(audio_path)
-------------+            
-------------+            # Convert to mono if stereo
-------------+            if waveform.shape[0] > 1:
-------------+                waveform = torch.mean(waveform, dim=0, keepdim=True)
-------------+            
-------------+            # Create item with correct keys
-------------+            item_data = {
-------------+                "data_object": waveform,
-------------+                "labels": label
-------------+            }
-------------+            
-------------+            # Apply instance transforms
-------------+            if self.instance_transforms is not None:
-------------+                item_data = self._apply_instance_transforms(item_data)
-------------+            
-------------+            return item_data
-------------+            
-------------+        except Exception as e:
-------------+            # Return zero tensor as fallback
-------------+            fallback_waveform = torch.zeros(1, 16000)  # 1 second of silence at 16kHz
-------------+            return {
-------------+                "data_object": fallback_waveform,
-------------+                "labels": label
-------------+            }
-------------+
-------------     def _create_index(self, label_path, audio_path, out_path):
-------------         """
-------------         Args:
-------------@@ -47,25 +92,40 @@ class AudioSpoofingDataset(BaseDataset):
-------------         Returns:
-------------             index (list[dict]): list of dictionaries, each with "path" and "label" fields
-------------         """
--------------
-------------         index = []
-------------+        
-------------+        # Подсчитываем общее количество строк в файле
-------------+        with open(label_path, "r") as f:
-------------+            total_lines = sum(1 for _ in f)
-------------+        
-------------+        bonafide_count = 0
-------------+        spoof_count = 0
------------- 
-------------         with open(label_path, "r") as f:
--------------            for line in f:
-------------+            for line_num, line in enumerate(tqdm(f, total=total_lines, desc="Обработка строк")):
-------------                 parts = line.strip().split()
-------------                 file_id = parts[1]
-------------                 class_name = parts[-1]
-------------                 label = 0 if class_name == "bonafide" else 1  # Fixed typo
-------------                 path = str(Path(audio_path) / f"{file_id}.flac")
-------------+                
-------------+                # Проверяем существование файла
-------------+                if not Path(path).exists():
-------------+                    continue
-------------+                
-------------                 index.append(
-------------                     {
-------------                         "path" : path,
-------------                         "label" : label
-------------                     }
-------------                 )
--------------        print("Separate to path and labels complete")
-------------+                
-------------+                # Подсчитываем статистику
-------------+                if label == 0:
-------------+                    bonafide_count += 1
-------------+                else:
-------------+                    spoof_count += 1
-------------+        
-------------         write_json(index, out_path)
------------- 
--------------        print(f"Created {len(index)} entries in {out_path}")
--------------
-------------         return index
-------------diff --git a/src/loss/crossentropy.py b/src/loss/crossentropy.py
-------------index d8ad43e..677200c 100644
---------------- a/src/loss/crossentropy.py
-------------+++ b/src/loss/crossentropy.py
-------------@@ -1,28 +1,80 @@
------------- import torch
--------------from torch import nn
--------------import torch.nn.functional as F
-------------+import torch.nn as nn
-------------+from typing import Dict, Any
-------------+
------------- 
------------- class CrossEntropyLoss(nn.Module):
-------------     """
--------------    Простой CrossEntropy loss для стабильного обучения
-------------+    Cross Entropy Loss for audio anti-spoofing.
-------------     """
------------- 
--------------    def __init__(self):
--------------        super().__init__()
-------------+    def __init__(self, **kwargs):
-------------+        """
-------------+        Args:
-------------+            **kwargs: additional arguments
-------------+        """
-------------+        super(CrossEntropyLoss, self).__init__()
-------------+        
-------------+        print("🎯 Инициализация CrossEntropyLoss...")
-------------+        
-------------+        # Логируем параметры
-------------+        for key, value in kwargs.items():
-------------+            print(f"   📊 {key}: {value}")
-------------+        
-------------+        self.criterion = nn.CrossEntropyLoss()
-------------+        print("✅ CrossEntropyLoss инициализирован")
------------- 
--------------    def forward(self, logits: torch.Tensor, labels: torch.Tensor, **kwargs):
-------------+    def forward(self, **batch) -> Dict[str, torch.Tensor]:
-------------         """
--------------        CrossEntropy loss compute
-------------+        Compute cross entropy loss.
-------------         
-------------         Args:
--------------            logits (Tensor): model output predictions (batch_size, num_classes)
--------------            labels (Tensor): ground truth labels (batch_size,)
--------------            **kwargs: дополнительные аргументы (игнорируются)
-------------+            **batch: input batch containing logits and labels
-------------+            
-------------         Returns:
--------------            losses (dict): dictionary loss
-------------+            Dict[str, torch.Tensor]: loss dictionary
-------------         """
-------------+        # Логируем входные данные (только для отладки)
-------------+        if hasattr(self, '_debug_forward') and self._debug_forward:
-------------+            print(f"   💔 CrossEntropyLoss forward: входные ключи {list(batch.keys())}")
-------------+            for key, value in batch.items():
-------------+                if isinstance(value, torch.Tensor):
-------------+                    print(f"      {key}: shape={value.shape}, dtype={value.dtype}")
-------------+        
-------------+        # Получаем logits и labels
-------------+        logits = batch['logits']
-------------+        labels = batch['labels']
-------------         
--------------        # Используем обычный CrossEntropy loss для стабильности
--------------        loss = F.cross_entropy(logits, labels)
-------------+        # Проверяем размеры
-------------+        if logits.dim() == 1:
-------------+            logits = logits.unsqueeze(0)
-------------+        if labels.dim() == 0:
-------------+            labels = labels.unsqueeze(0)
-------------         
--------------        return {"loss": loss}
-------------+        # Логируем размеры
-------------+        if hasattr(self, '_debug_forward') and self._debug_forward:
-------------+            print(f"   📊 Logits: shape={logits.shape}, range=[{logits.min().item():.4f}, {logits.max().item():.4f}]")
-------------+            print(f"   📊 Labels: shape={labels.shape}, unique={torch.unique(labels).tolist()}")
-------------+        
-------------+        # Вычисляем потерю
-------------+        loss = self.criterion(logits, labels)
-------------+        
-------------+        # Логируем результат
-------------+        if hasattr(self, '_debug_forward') and self._debug_forward:
-------------+            print(f"   💔 Loss: {loss.item():.4f}")
-------------+        
-------------+        return {
-------------+            'loss': loss
-------------+        }
-------------+
-------------+    def set_debug_mode(self, debug_forward=False):
-------------+        """
-------------+        Включает режим отладки для логирования forward pass.
-------------+        
-------------+        Args:
-------------+            debug_forward (bool): логировать forward pass
-------------+        """
-------------+        self._debug_forward = debug_forward
-------------+        if debug_forward:
-------------+            print(f"🐛 Режим отладки включен для {self.__class__.__name__}")
-------------+            print(f"   💔 Debug forward: {debug_forward}")
-------------diff --git a/src/metrics/eer.py b/src/metrics/eer.py
-------------index de45458..a9be4a6 100644
---------------- a/src/metrics/eer.py
-------------+++ b/src/metrics/eer.py
-------------@@ -1,88 +1,138 @@
--------------import numpy as np
------------- import torch
--------------from abc import abstractmethod
--------------
--------------class BaseMetric:
--------------    """
--------------    Base class for all metrics
--------------    """
-------------+import numpy as np
-------------+from typing import Dict, Any
------------- 
--------------    def __init__(self, name=None, *args, **kwargs):
--------------        self.name = name if name is not None else type(self).__name__
-------------+from src.metrics.base_metric import BaseMetric
------------- 
--------------    @abstractmethod
--------------    def __call__(self, **batch):
--------------        raise NotImplementedError()
------------- 
------------- class EERMetric(BaseMetric):
-------------     """
--------------    Equal Error Rate (EER) metric.
--------------    Ожидает в batch два поля:
--------------        - 'logits': torch tensor с предсказанными logits
--------------        - 'labels': torch tensor с метками (1 — bona fide, 0 — spoof)
-------------+    Equal Error Rate (EER) metric for audio anti-spoofing.
-------------     """
------------- 
--------------    def __init__(self, name="eer"):
--------------        super().__init__(name=name)
--------------
--------------    def __call__(self, **batch):
--------------    
--------------        logits = batch["logits"]
--------------        labels = batch["labels"]
--------------
-------------+    def __init__(self, **kwargs):
-------------+        """
-------------+        Args:
-------------+            **kwargs: additional arguments
-------------+        """
-------------+        super(EERMetric, self).__init__()
-------------+        
-------------+        print("📈 Инициализация EERMetric...")
-------------         
--------------        if hasattr(logits, "detach"):
--------------            logits = logits.detach().cpu().numpy()
--------------        if hasattr(labels, "detach"):
--------------            labels = labels.detach().cpu().numpy()
-------------+        # Логируем параметры
-------------+        for key, value in kwargs.items():
-------------+            print(f"   📊 {key}: {value}")
-------------+        
-------------+        self.name = "eer"
-------------+        print("✅ EERMetric инициализирован")
------------- 
-------------+    def forward(self, **batch) -> float:
-------------+        """
-------------+        Compute EER metric.
-------------         
--------------        import torch.nn.functional as F
--------------        if hasattr(logits, "detach"):
-------------+        Args:
-------------+            **batch: input batch containing scores and labels
-------------             
--------------            scores = F.softmax(logits, dim=-1)[:, 1]
--------------        else:
--------------            
--------------            logits_tensor = torch.from_numpy(logits)
--------------            scores_tensor = F.softmax(logits_tensor, dim=-1)
--------------            scores = scores_tensor[:, 1].numpy()
--------------
-------------+        Returns:
-------------+            float: EER value
-------------+        """
-------------+        # Логируем входные данные (только для отладки)
-------------+        if hasattr(self, '_debug_forward') and self._debug_forward:
-------------+            print(f"   📈 EERMetric forward: входные ключи {list(batch.keys())}")
-------------+            for key, value in batch.items():
-------------+                if isinstance(value, torch.Tensor):
-------------+                    print(f"      {key}: shape={value.shape}, dtype={value.dtype}")
-------------         
--------------        bona_scores = scores[labels == 1]
--------------        spoof_scores = scores[labels == 0]
--------------
--------------        if len(bona_scores) == 0 or len(spoof_scores) == 0:
-------------+        # Получаем scores и labels
-------------+        if 'scores' in batch:
-------------+            scores = batch['scores']
-------------+        elif 'logits' in batch:
-------------+            # Если у нас есть logits, берем вероятность второго класса (spoof)
-------------+            logits = batch['logits']
-------------+            scores = torch.softmax(logits, dim=1)[:, 1]
-------------+        else:
-------------+            print("❌ Ошибка: не найдены scores или logits в батче")
-------------             return 0.0
--------------
--------------        eer, _ = self.compute_eer(bona_scores, spoof_scores)
-------------+        
-------------+        labels = batch['labels']
-------------+        
-------------+        # Логируем размеры
-------------+        if hasattr(self, '_debug_forward') and self._debug_forward:
-------------+            print(f"   📊 Scores: shape={scores.shape}, range=[{scores.min().item():.4f}, {scores.max().item():.4f}]")
-------------+            print(f"   📊 Labels: shape={labels.shape}, unique={torch.unique(labels).tolist()}")
-------------+        
-------------+        # Вычисляем EER
-------------+        eer = self._compute_eer(scores, labels)
-------------+        
-------------+        # Логируем результат
-------------+        if hasattr(self, '_debug_forward') and self._debug_forward:
-------------+            print(f"   📈 EER: {eer:.4f}")
-------------+        
-------------         return eer
------------- 
--------------    @staticmethod
--------------    def compute_det_curve(target_scores, nontarget_scores):
--------------        n_scores = target_scores.size + nontarget_scores.size
--------------        all_scores = np.concatenate((target_scores, nontarget_scores))
--------------        labels = np.concatenate(
--------------            (np.ones(target_scores.size), np.zeros(nontarget_scores.size)))
--------------
--------------        indices = np.argsort(all_scores, kind='mergesort')
--------------        labels = labels[indices]
--------------
--------------        tar_trial_sums = np.cumsum(labels)
--------------        nontarget_trial_sums = nontarget_scores.size - \
--------------            (np.arange(1, n_scores + 1) - tar_trial_sums)
-----------+---                    metrics.update(met.name, met(**batch))
-----------+--+                    metric_value = met(**batch)
-----------+--+                    metrics.update(met.name, metric_value)
-----------+--                 except Exception as e:
-----------+---                    print(f"Ошибка в метрике {met.name}: {e}")
-----------+--                     continue
-----------+--         return batch
-----------+-- 
-----------+--@@ -72,4 +72,13 @@ class Trainer(BaseTrainer):
-----------+--         Log data from batch. Calls self.writer.add_* to log data
-----------+--         to the experiment tracker.
-----------+--         """
-----------+---        pass
-----------+--\ No newline at end of file
-----------+--+        # Логируем информацию о батче для writer
-----------+--+        if self.writer is not None:
-----------+--+            # Логируем learning rate
-----------+--+            if mode == "train" and self.lr_scheduler is not None:
-----------+--+                self.writer.add_scalar("learning_rate", self.lr_scheduler.get_last_lr()[0])
-----------+--+            
-----------+--+            # Логируем градиентную норму
-----------+--+            if mode == "train":
-----------+--+                grad_norm = self._get_grad_norm()
-----------+--+                self.writer.add_scalar("grad_norm", grad_norm)
-----------+--\ No newline at end of file
-----------+--diff --git a/src/transforms/__init__.py b/src/transforms/__init__.py
-----------+--index bea0123..1c032b1 100644
-----------+----- a/src/transforms/__init__.py
-----------+--+++ b/src/transforms/__init__.py
-----------+--@@ -1,3 +1,3 @@
-----------+-- from src.transforms.normalize import Normalize
-----------+-- from src.transforms.scale import RandomScale1D
-----------+---from src.transforms.stft import AudioFrontend
-----------+--\ No newline at end of file
-----------+--+from src.transforms.stft import STFTTransform, MelSpectrogramTransform
-----------+--\ No newline at end of file
-----------+--diff --git a/src/transforms/stft.py b/src/transforms/stft.py
-----------+--index 954ff81..f7e362f 100644
-----------+----- a/src/transforms/stft.py
-----------+--+++ b/src/transforms/stft.py
-----------+--@@ -1,37 +1,177 @@
-----------+-- import torch
-----------+-- import torch.nn as nn
-----------+--+import torchaudio
-----------+--+from typing import Dict, Any
-----------+-- 
-----------+-- 
-----------+---def audio_frontend(waveform):
-----------+--+class STFTTransform(nn.Module):
-----------+--+    """
-----------+--+    Short-Time Fourier Transform (STFT) for audio processing.
-----------+--+    """
-----------+-- 
-----------+---    n_fft = 1024
-----------+---    hop_length = 256
-----------+---    win_length = 1024
-----------+--+    def __init__(self, n_fft=1024, hop_length=512, win_length=1024, **kwargs):
-----------+--+        """
-----------+--+        Args:
-----------+--+            n_fft (int): FFT window size
-----------+--+            hop_length (int): Number of samples between successive frames
-----------+--+            win_length (int): Window size
-----------+--+            **kwargs: additional arguments
-----------+--+        """
-----------+--+        super(STFTTransform, self).__init__()
-----------+--+        
-----------+--+        print("🎵 Инициализация STFTTransform...")
-----------+--+        print(f"   📊 n_fft: {n_fft}")
-----------+--+        print(f"   📊 hop_length: {hop_length}")
-----------+--+        print(f"   📊 win_length: {win_length}")
-----------+--+        
-----------+--+        # Логируем дополнительные параметры
-----------+--+        for key, value in kwargs.items():
-----------+--+            print(f"   📊 {key}: {value}")
-----------+--+        
-----------+--+        self.n_fft = n_fft
-----------+--+        self.hop_length = hop_length
-----------+--+        self.win_length = win_length
-----------+--+        
-----------+--+        print("✅ STFTTransform инициализирован")
-----------+-- 
-----------+---    waveform = waveform.squeeze()
-----------+--+    def forward(self, audio: torch.Tensor) -> torch.Tensor:
-----------+--+        """
-----------+--+        Apply STFT to audio signal.
-----------+--+        
-----------+--+        Args:
-----------+--+            audio (torch.Tensor): input audio tensor
-----------+--+            
-----------+--+        Returns:
-----------+--+            torch.Tensor: STFT spectrogram
-----------+--+        """
-----------+--+        # Логируем входные данные (только для отладки)
-----------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
-----------+--+            print(f"   🎵 STFTTransform forward: audio shape={audio.shape}")
-----------+--+            print(f"      Audio range: [{audio.min().item():.4f}, {audio.max().item():.4f}]")
-----------+--+            print(f"      Audio dtype: {audio.dtype}")
-----------+--+        
-----------+--+        # Убеждаемся, что аудио имеет правильную форму
-----------+--+        if audio.dim() == 1:
-----------+--+            audio = audio.unsqueeze(0)  # Добавляем batch dimension
-----------+--+        elif audio.dim() == 3:
-----------+--+            audio = audio.squeeze(1)  # Убираем лишний канал
-----------+--+        
-----------+--+        # Применяем STFT
-----------+--+        stft_output = torch.stft(
-----------+--+            audio,
-----------+--+            n_fft=self.n_fft,
-----------+--+            hop_length=self.hop_length,
-----------+--+            win_length=self.win_length,
-----------+--+            return_complex=True,
-----------+--+            window=torch.hann_window(self.win_length).to(audio.device)
-----------+--+        )
-----------+--+        
-----------+--+        # Конвертируем в спектрограмму
-----------+--+        spectrogram = torch.abs(stft_output)
-----------+--+        
-----------+--+        # Логируем выходные данные
-----------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
-----------+--+            print(f"   📊 STFT output shape: {stft_output.shape}")
-----------+--+            print(f"   📊 Spectrogram shape: {spectrogram.shape}")
-----------+--+            print(f"   📊 Spectrogram range: [{spectrogram.min().item():.4f}, {spectrogram.max().item():.4f}]")
-----------+--+        
-----------+--+        return spectrogram
-----------+-- 
-----------+---    stft = torch.stft(
-----------+---        waveform,
-----------+---        n_fft=n_fft,
-----------+---        hop_length=hop_length,
-----------+---        win_length=win_length,
-----------+---        window=torch.hann_window(win_length, device=waveform.device),
-----------+---        return_complex=True
-----------+---    )
-----------+--+    def set_debug_mode(self, debug_forward=False):
-----------+--+        """
-----------+--+        Включает режим отладки для логирования forward pass.
-----------+--+        
-----------+--+        Args:
-----------+--+            debug_forward (bool): логировать forward pass
-----------+--+        """
-----------+--+        self._debug_forward = debug_forward
-----------+--+        if debug_forward:
-----------+--+            print(f"🐛 Режим отладки включен для {self.__class__.__name__}")
-----------+--+            print(f"   🎵 Debug forward: {debug_forward}")
-----------+-- 
-----------+---    magnitude = torch.abs(stft)
-----------+---    log_magnitude = torch.log(magnitude + 1e-8)
-----------+---    log_magnitude = log_magnitude.unsqueeze(0)
-----------+---    return log_magnitude
-----------+-- 
-----------+--+class MelSpectrogramTransform(nn.Module):
-----------+--+    """
-----------+--+    Mel Spectrogram transform for audio processing.
-----------+--+    """
-----------+-- 
-----------+---class AudioFrontend(nn.Module):
-----------+---    
-----------+---    def __init__(self):
-----------+---        super().__init__()
-----------+---    
-----------+---    def forward(self, waveform):
-----------+---      
-----------+--+    def __init__(self, sample_rate=16000, n_fft=1024, hop_length=512, n_mels=80, **kwargs):
-----------+--+        """
-----------+--+        Args:
-----------+--+            sample_rate (int): Audio sample rate
-----------+--+            n_fft (int): FFT window size
-----------+--+            hop_length (int): Number of samples between successive frames
-----------+--+            n_mels (int): Number of mel filter banks
-----------+--+            **kwargs: additional arguments
-----------+--+        """
-----------+--+        super(MelSpectrogramTransform, self).__init__()
-----------+--+        
-----------+--+        print("🎵 Инициализация MelSpectrogramTransform...")
-----------+--+        print(f"   📊 sample_rate: {sample_rate}")
-----------+--+        print(f"   📊 n_fft: {n_fft}")
-----------+--+        print(f"   📊 hop_length: {hop_length}")
-----------+--+        print(f"   📊 n_mels: {n_mels}")
-----------+--+        
-----------+--+        # Логируем дополнительные параметры
-----------+--+        for key, value in kwargs.items():
-----------+--+            print(f"   📊 {key}: {value}")
-----------+--+        
-----------+--+        self.sample_rate = sample_rate
-----------+--+        self.n_fft = n_fft
-----------+--+        self.hop_length = hop_length
-----------+--+        self.n_mels = n_mels
-----------+--+        
-----------+--+        # Создаем mel spectrogram transform
-----------+--+        self.mel_transform = torchaudio.transforms.MelSpectrogram(
-----------+--+            sample_rate=sample_rate,
-----------+--+            n_fft=n_fft,
-----------+--+            hop_length=hop_length,
-----------+--+            n_mels=n_mels,
-----------+--+            window_fn=torch.hann_window
-----------+--+        )
-----------+--+        
-----------+--+        print("✅ MelSpectrogramTransform инициализирован")
-----------+-- 
-----------+--+    def forward(self, audio: torch.Tensor) -> torch.Tensor:
-----------+--+        """
-----------+--+        Apply Mel Spectrogram transform to audio signal.
-----------+--+        
-----------+--+        Args:
-----------+--+            audio (torch.Tensor): input audio tensor
-----------+--+            
-----------+--+        Returns:
-----------+--+            torch.Tensor: Mel spectrogram
-----------+--+        """
-----------+--+        # Логируем входные данные (только для отладки)
-----------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
-----------+--+            print(f"   🎵 MelSpectrogramTransform forward: audio shape={audio.shape}")
-----------+--+            print(f"      Audio range: [{audio.min().item():.4f}, {audio.max().item():.4f}]")
-----------+--+            print(f"      Audio dtype: {audio.dtype}")
-----------+--+        
-----------+--+        # Убеждаемся, что аудио имеет правильную форму
-----------+--+        if audio.dim() == 1:
-----------+--+            audio = audio.unsqueeze(0)  # Добавляем batch dimension
-----------+--+        elif audio.dim() == 3:
-----------+--+            audio = audio.squeeze(1)  # Убираем лишний канал
-----------+--+        
-----------+--+        # Применяем mel spectrogram transform
-----------+--+        mel_spectrogram = self.mel_transform(audio)
-----------+--+        
-----------+--+        # Логируем выходные данные
-----------+--+        if hasattr(self, '_debug_forward') and self._debug_forward:
-----------+--+            print(f"   📊 Mel spectrogram shape: {mel_spectrogram.shape}")
-----------+--+            print(f"   📊 Mel spectrogram range: [{mel_spectrogram.min().item():.4f}, {mel_spectrogram.max().item():.4f}]")
-----------+--+        
-----------+--+        return mel_spectrogram
-----------+-- 
-----------+---        return audio_frontend(waveform)
-----------+--\ No newline at end of file
-----------+--+    def set_debug_mode(self, debug_forward=False):
-----------+--+        """
-----------+--+        Включает режим отладки для логирования forward pass.
-----------+--+        
-----------+--+        Args:
-----------+--+            debug_forward (bool): логировать forward pass
-----------+--+        """
-----------+--+        self._debug_forward = debug_forward
-----------+--+        if debug_forward:
-----------+--+            print(f"🐛 Режим отладки включен для {self.__class__.__name__}")
-----------+--+            print(f"   🎵 Debug forward: {debug_forward}")
-----------+--\ No newline at end of file
-----------+--diff --git a/train.py b/train.py
-----------+--index 90a7a4f..ea54b46 100644
-----------+----- a/train.py
-----------+--+++ b/train.py
-----------+--@@ -26,6 +26,7 @@ def main(config):
-----------+-- 
-----------+--     project_config = OmegaConf.to_container(config)
-----------+--     logger = setup_saving_and_logging(config)
-----------+--+    
-----------+--     writer = instantiate(config.writer, logger, project_config)
-----------+-- 
-----------+--     if config.trainer.device == "auto":
-----------+--@@ -34,20 +35,26 @@ def main(config):
-----------+--         device = config.trainer.device
-----------+-- 
-----------+--     # setup data_loader instances
-----------+---    # batch_transforms should be put on device
-----------+--     dataloaders, batch_transforms = get_dataloaders(config, device)
-----------+-- 
-----------+--     # build model architecture, then print to console
-----------+--     model = instantiate(config.model).to(device)
-----------+--+    
-----------+--+    # Подсчет параметров модели
-----------+--+    total_params = sum(p.numel() for p in model.parameters())
-----------+--+    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
-----------+--+    
-----------+--     logger.info(model)
-----------+-- 
-----------+--     # get function handles of loss and metrics
-----------+--     loss_function = instantiate(config.loss_function).to(device)
-----------+--+    
-----------+--     metrics = instantiate(config.metrics)
-----------+-- 
-----------+--     # build optimizer, learning rate scheduler
-----------+--     trainable_params = filter(lambda p: p.requires_grad, model.parameters())
-----------+--     optimizer = instantiate(config.optimizer, params=trainable_params)
-----------+--+    
-----------+--     lr_scheduler = instantiate(config.lr_scheduler, optimizer=optimizer)
-----------+-- 
-----------+--     # epoch_len = number of iterations for iteration-based training
-----------+-diff --git a/src/metrics/tracker.py b/src/metrics/tracker.py
-----------+-index 79712bd..e9a1d72 100644
-----------+---- a/src/metrics/tracker.py
-----------+-+++ b/src/metrics/tracker.py
-----------+-@@ -50,24 +50,51 @@ class MetricTracker:
-----------+-         self._eer_labels.extend(labels.detach().cpu().numpy())
-----------+- 
-----------+-     def compute_eer(self):
----------- --
--------------        frr = np.concatenate(
--------------            (np.atleast_1d(0), tar_trial_sums / target_scores.size))
--------------        far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums /
--------------                              nontarget_scores.size))
--------------        thresholds = np.concatenate(
--------------            (np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))
--------------        return frr, far, thresholds
-------------+    def _compute_eer(self, scores: torch.Tensor, labels: torch.Tensor) -> float:
----------- -+        """
-------------+        Compute Equal Error Rate.
-------------+        
-------------+        Args:
-------------+            scores (torch.Tensor): prediction scores
-------------+            labels (torch.Tensor): ground truth labels
-------------+            
-------------+        Returns:
-------------+            float: EER value
-----------+-+        Compute Equal Error Rate from accumulated scores and labels.
----------- -+        """
-------------+        # Конвертируем в numpy
-------------+        scores_np = scores.detach().cpu().numpy()
-------------+        labels_np = labels.detach().cpu().numpy()
-------------+        
-----------+-         if not self._eer_scores:
-----------+-             return 0.0
-----------+-         
-----------+-         scores = np.array(self._eer_scores)
-----------+-         labels = np.array(self._eer_labels)
-----------+-         
-----------+--        bona_scores = scores[labels == 1]
-----------+--        spoof_scores = scores[labels == 0]
----------- -+        # Получаем уникальные пороги
-------------+        thresholds = np.unique(scores_np)
-------------+        
-----------+-+        thresholds = np.unique(scores)
-----------+-         
-----------+--        if len(bona_scores) == 0 or len(spoof_scores) == 0:
-----------+--            return 0.0
----------- -+        # Вычисляем FAR и FRR для каждого порога
----------- -+        far_values = []
----------- -+        frr_values = []
----------- -+        
----------- -+        for threshold in thresholds:
-------------+            # FAR = FP / (FP + TN) = FP / (FP + TN)
-------------+            # FRR = FN / (FN + TP) = FN / (FN + TP)
-------------+            
----------- -+            # Предсказания: 1 если score >= threshold, иначе 0
-------------+            predictions = (scores_np >= threshold).astype(int)
-----------+-+            predictions = (scores >= threshold).astype(int)
----------- -+            
----------- -+            # Вычисляем confusion matrix
-------------+            tp = np.sum((predictions == 1) & (labels_np == 1))
-------------+            tn = np.sum((predictions == 0) & (labels_np == 0))
-------------+            fp = np.sum((predictions == 1) & (labels_np == 0))
-------------+            fn = np.sum((predictions == 0) & (labels_np == 1))
-----------+-+            tp = np.sum((predictions == 1) & (labels == 1))
-----------+-+            tn = np.sum((predictions == 0) & (labels == 0))
-----------+-+            fp = np.sum((predictions == 1) & (labels == 0))
-----------+-+            fn = np.sum((predictions == 0) & (labels == 1))
----------- -+            
----------- -+            # Вычисляем FAR и FRR
----------- -+            far = fp / (fp + tn) if (fp + tn) > 0 else 0
-----------@@ -1044,1330 +2324,345 @@ index bbf7cb1..e69de29 100644
----------- -+        
----------- -+        # EER - это среднее FAR и FRR в этой точке
----------- -+        eer = (far_values[min_idx] + frr_values[min_idx]) / 2
-------------+        
-------------+        return float(eer)
------------- 
--------------    @classmethod
--------------    def compute_eer(cls, bona_scores, spoof_scores):
--------------        frr, far, thresholds = cls.compute_det_curve(bona_scores, spoof_scores)
--------------        abs_diffs = np.abs(frr - far)
--------------        min_index = np.argmin(abs_diffs)
--------------        eer = np.mean((frr[min_index], far[min_index]))
--------------        return eer, thresholds[min_index]
-------------\ No newline at end of file
-------------+    def set_debug_mode(self, debug_forward=False):
-------------+        """
-------------+        Включает режим отладки для логирования forward pass.
-------------+        
-------------+        Args:
-------------+            debug_forward (bool): логировать forward pass
-------------+        """
-------------+        self._debug_forward = debug_forward
-------------+        if debug_forward:
-------------+            print(f"🐛 Режим отладки включен для {self.__class__.__name__}")
-------------+            print(f"   📈 Debug forward: {debug_forward}")
-------------\ No newline at end of file
-------------diff --git a/src/model/model.py b/src/model/model.py
-------------index 28a4ce4..6ec39da 100644
---------------- a/src/model/model.py
-------------+++ b/src/model/model.py
-------------@@ -1,153 +1,113 @@
------------- import torch
--------------from torch import nn
-------------+import torch.nn as nn
-------------+from typing import Dict, Any
------------- 
--------------class mfm_block(nn.Module):
--------------    def __init__(self, channels):
--------------        super().__init__()
--------------        self.channels = channels
--------------
--------------    def forward(self, x):
--------------        partition = self.channels // 2
--------------        first_batch = x[:, :partition, ...]
--------------        second_batch = x[:, partition:, ...]
--------------        output = torch.maximum(first_batch, second_batch)
--------------        return output
------------- 
------------- class LCNN(nn.Module):
--------------    def __init__(self, in_channels=1, num_classes=2, dropout_p=0.3):
--------------        super().__init__()
--------------
--------------        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=5, stride=1, padding=2)
--------------        self.mfm2 = mfm_block(64)
--------------        self.dropout2 = nn.Dropout2d(dropout_p)
--------------        self.MaxPool3 = nn.MaxPool2d(kernel_size=2, stride=2)
--------------
--------------        self.conv4 = nn.Conv2d(32, 64, kernel_size=1, stride=1)
--------------        self.mfm5 = mfm_block(64)
--------------        self.dropout5 = nn.Dropout2d(dropout_p)
--------------        self.BatchNorm6 = nn.BatchNorm2d(32)
--------------
--------------        self.conv7 = nn.Conv2d(32, 96, kernel_size=3, stride=1, padding=1)
--------------        self.mfm8 = mfm_block(96)
--------------        self.dropout8 = nn.Dropout2d(dropout_p)
--------------
--------------        self.MaxPool9 = nn.MaxPool2d(kernel_size=2, stride=2)
--------------        self.BatchNorm10 = nn.BatchNorm2d(48)
--------------
--------------        self.conv11 = nn.Conv2d(48, 96, kernel_size=1, stride=1)
--------------        self.mfm12 = mfm_block(96)
--------------        self.dropout12 = nn.Dropout2d(dropout_p)
--------------        self.BatchNorm13 = nn.BatchNorm2d(48)
--------------
--------------        self.conv14 = nn.Conv2d(48, 128, kernel_size=3, stride=1, padding=1)
--------------        self.mfm15 = mfm_block(128)
--------------        self.dropout15 = nn.Dropout2d(dropout_p)
--------------
--------------        self.MaxPool16 = nn.MaxPool2d(kernel_size=2, stride=2)
--------------
--------------        self.conv17 = nn.Conv2d(64, 128, kernel_size=1, stride=1)
--------------        self.mfm18 = mfm_block(128)
--------------        self.dropout18 = nn.Dropout2d(dropout_p)
--------------        self.BatchNorm19 = nn.BatchNorm2d(64)
--------------
--------------        self.conv20 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
--------------        self.mfm21 = mfm_block(64)
--------------        self.dropout21 = nn.Dropout2d(dropout_p)
--------------        self.BatchNorm22 = nn.BatchNorm2d(32)
--------------
--------------        self.conv23 = nn.Conv2d(32, 64, kernel_size=1, stride=1)
--------------        self.mfm24 = mfm_block(64)
--------------        self.dropout24 = nn.Dropout2d(dropout_p)
--------------        self.BatchNorm25 = nn.BatchNorm2d(32)
--------------
--------------        self.conv26 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
--------------        self.mfm27 = mfm_block(64)
--------------        self.dropout27 = nn.Dropout2d(dropout_p)
--------------
--------------        self.MaxPool28 = nn.MaxPool2d(kernel_size=2, stride=2)
--------------
--------------        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))
--------------        self.fc29 = nn.Linear(32, 160)
--------------        self.dropout29 = nn.Dropout(dropout_p)
--------------        self.mfm30 = mfm_block(160)
--------------        self.BatchNorm31 = nn.BatchNorm1d(80)
--------------        self.fc32 = nn.Linear(80, num_classes)
-------------+    """
-------------+    Light CNN model for audio anti-spoofing.
-------------+    """
-------------+
-------------+    def __init__(self, num_classes=2, **kwargs):
-------------+        """
-------------+        Args:
-------------+            num_classes (int): number of output classes
-------------+            **kwargs: additional arguments
-------------+        """
-------------+        super(LCNN, self).__init__()
----------- -         
--------------        # Инициализация весов
--------------        self._initialize_weights()
--------------
--------------    def _initialize_weights(self):
--------------        """Инициализация весов для лучшего обучения"""
--------------        for m in self.modules():
--------------            if isinstance(m, nn.Conv2d):
--------------                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
--------------                if m.bias is not None:
--------------                    nn.init.constant_(m.bias, 0)
--------------            elif isinstance(m, nn.BatchNorm2d):
--------------                nn.init.constant_(m.weight, 1)
--------------                nn.init.constant_(m.bias, 0)
--------------            elif isinstance(m, nn.Linear):
--------------                nn.init.normal_(m.weight, 0, 0.01)
--------------                nn.init.constant_(m.bias, 0)
--------------
--------------    def forward(self, data_object, **kwargs):
--------------        x = data_object
--------------        x = self.conv1(x)
--------------        x = self.mfm2(x)
--------------        x = self.dropout2(x)
--------------        x = self.MaxPool3(x)
--------------
--------------        x = self.conv4(x)
--------------        x = self.mfm5(x)
--------------        x = self.dropout5(x)
--------------        x = self.BatchNorm6(x)
--------------
--------------        x = self.conv7(x)
--------------        x = self.mfm8(x)
--------------        x = self.dropout8(x)
--------------
--------------        x = self.MaxPool9(x)
--------------        x = self.BatchNorm10(x)
--------------
--------------        x = self.conv11(x)
--------------        x = self.mfm12(x)
--------------        x = self.dropout12(x)
--------------        x = self.BatchNorm13(x)
--------------
--------------        x = self.conv14(x)
--------------        x = self.mfm15(x)
--------------        x = self.dropout15(x)
--------------
--------------        x = self.MaxPool16(x)
--------------
--------------        x = self.conv17(x)
--------------        x = self.mfm18(x)
--------------        x = self.dropout18(x)
--------------        x = self.BatchNorm19(x)
--------------
--------------        x = self.conv20(x)
--------------        x = self.mfm21(x)
--------------        x = self.dropout21(x)
--------------        x = self.BatchNorm22(x)
--------------
--------------        x = self.conv23(x)
--------------        x = self.mfm24(x)
--------------        x = self.dropout24(x)
--------------        x = self.BatchNorm25(x)
--------------
--------------        x = self.conv26(x)
--------------        x = self.mfm27(x)
--------------        x = self.dropout27(x)
-------------+        self.num_classes = num_classes
-------------+        
-------------+        # Определяем архитектуру
-------------+        self.features = nn.Sequential(
-------------+            # Первый блок
-------------+            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),
-------------+            nn.BatchNorm2d(64),
-------------+            nn.ReLU(inplace=True),
-------------+            nn.MaxPool2d(kernel_size=2, stride=2),
-------------+            
-------------+            # Второй блок
-------------+            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
-------------+            nn.BatchNorm2d(128),
-------------+            nn.ReLU(inplace=True),
-------------+            nn.MaxPool2d(kernel_size=2, stride=2),
-------------+            
-------------+            # Третий блок
-------------+            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
-------------+            nn.BatchNorm2d(256),
-------------+            nn.ReLU(inplace=True),
-------------+            nn.MaxPool2d(kernel_size=2, stride=2),
-------------+            
-------------+            # Четвертый блок
-------------+            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
-------------+            nn.BatchNorm2d(512),
-------------+            nn.ReLU(inplace=True),
-------------+            nn.MaxPool2d(kernel_size=2, stride=2),
-------------+        )
-------------+        
-------------+        # Global Average Pooling
-------------+        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))
-------------+        
-------------+        # Классификатор
-------------+        self.classifier = nn.Sequential(
-------------+            nn.Dropout(0.5),
-------------+            nn.Linear(512, 256),
-------------+            nn.ReLU(inplace=True),
-------------+            nn.Dropout(0.5),
-------------+            nn.Linear(256, num_classes)
-------------+        )
-------------+
-------------+    def forward(self, **batch) -> Dict[str, torch.Tensor]:
-------------+        """
-------------+        Forward pass of the model.
-------------+        
-------------+        Args:
-------------+            **batch: input batch containing tensors
-------------+            
-------------+        Returns:
-------------+            Dict[str, torch.Tensor]: model outputs
-------------+        """
-------------+        # Получаем входные данные
-------------+        if 'spectrogram' in batch:
-------------+            x = batch['spectrogram']
-------------+        elif 'data_object' in batch:
-------------+            x = batch['data_object']
-------------+        else:
-------------+            # Берем первый тензор из батча
-------------+            x = next(iter(batch.values()))
-------------+        
-------------+        # Убеждаемся, что входные данные имеют правильную форму
-------------+        if x.dim() == 3:
-------------+            x = x.unsqueeze(1)  # Добавляем канал
-------------+        elif x.dim() == 2:
-------------+            x = x.unsqueeze(0).unsqueeze(0)  # Добавляем batch и канал
-------------+        
-------------+        # Проходим через слои
-------------+        x = self.features(x)
-------------+        
-------------+        x = self.global_avg_pool(x)
-------------+        x = x.view(x.size(0), -1)
-------------+        
-------------+        x = self.classifier(x)
-------------+        
-------------+        # Возвращаем выходы
-------------+        outputs = {
-------------+            'logits': x
-------------+        }
-------------+        
-------------+        return outputs
------------- 
--------------        x = self.MaxPool28(x)
-----------+--        # Вычисляем EER
-----------+--        from src.metrics.eer import EERMetric
-----------+--        eer_metric = EERMetric()
-----------+--        eer, _ = eer_metric.compute_eer(bona_scores, spoof_scores)
-----------+--        return eer
-----------+-+        return float(eer)
----------- - 
--------------        x = self.adaptive_pool(x)
--------------        x = x.view(x.size(0), -1)
--------------        x = self.fc29(x)
--------------        x = self.dropout29(x)
--------------        x = x.unsqueeze(-1).unsqueeze(-1)
--------------        x = self.mfm30(x)
--------------        x = x.squeeze(-1).squeeze(-1)
--------------        x = self.BatchNorm31(x)
--------------        logits = self.fc32(x)
--------------        return {"logits": logits}
-------------\ No newline at end of file
-------------+# Создаем экземпляр модели для совместимости с hydra
-------------+def create_model(**kwargs) -> LCNN:
-------------+    """
-------------+    Создает экземпляр модели LCNN.
-------------+    
-------------+    Args:
-------------+        **kwargs: параметры модели
-------------+        
-------------+    Returns:
-------------+        LCNN: экземпляр модели
-------------+    """
-------------+    model = LCNN(**kwargs)
-------------+    return model
-------------\ No newline at end of file
-----------+-     def avg(self, key):
-----------+-         """
----------- -diff --git a/src/trainer/base_trainer.py b/src/trainer/base_trainer.py
-------------index e35ffba..0d4e7a1 100644
-----------+-index 0d4e7a1..9f6663a 100644
----------- ---- a/src/trainer/base_trainer.py
----------- -+++ b/src/trainer/base_trainer.py
-------------@@ -148,250 +148,224 @@ class BaseTrainer:
-------------         """
-------------         try:
-------------             self._train_process()
--------------        except KeyboardInterrupt as e:
--------------            self.logger.info("Saving model on keyboard interrupt")
--------------            self._save_checkpoint(self._last_epoch, save_best=False)
--------------            raise e
-------------+        except KeyboardInterrupt:
-------------+            self._save_checkpoint(self._last_epoch, save_best=False, only_best=True)
-------------+            raise
-------------+        except Exception as e:
-------------+            raise
------------- 
-------------     def _train_process(self):
-------------         """
--------------        Full training logic:
--------------
--------------        Training model for an epoch, evaluating it on non-train partitions,
--------------        and monitoring the performance improvement (for early stopping
--------------        and saving the best checkpoint).
-------------+        Full training logic.
-------------         """
-------------         not_improved_count = 0
-------------         for epoch in range(self.start_epoch, self.epochs + 1):
-------------             self._last_epoch = epoch
--------------            result = self._train_epoch(epoch)
--------------
--------------            # save logged information into logs dict
--------------            logs = {"epoch": epoch}
--------------            logs.update(result)
-------------+            self._train_epoch(epoch)
------------- 
--------------            # print logged information to the screen
--------------            for key, value in logs.items():
--------------                self.logger.info(f"    {key:15s}: {value}")
-------------+            # Валидируем только на val, test оставляем для инференса
-------------+            if "val" in self.evaluation_dataloaders:
-------------+                val_logs = {}
-------------+                dataloader = self.evaluation_dataloaders["val"]
-------------+                val_part_logs = self._evaluation_epoch(epoch, "val", dataloader)
-------------+                val_logs.update(val_part_logs)
------------- 
--------------            # evaluate model performance according to configured metric,
--------------            # save best checkpoint as model_best
--------------            best, stop_process, not_improved_count = self._monitor_performance(
--------------                logs, not_improved_count
--------------            )
-------------+                # log best so far
-------------+                if self.mnt_mode != "off":
-------------+                    improved = self._monitor_performance(val_logs, not_improved_count)
-------------+                    if improved:
-------------+                        not_improved_count = 0
-------------+                    else:
-------------+                        not_improved_count += 1
------------- 
--------------            if epoch % self.save_period == 0 or best:
--------------                self._save_checkpoint(epoch, save_best=best, only_best=True)
-------------+                if self.mnt_mode != "off" and not_improved_count > self.early_stop:
-------------+                    break
------------- 
--------------            if stop_process:  # early_stop
--------------                break
-------------+            if epoch % self.save_period == 0:
-------------+                self._save_checkpoint(epoch, save_best=False)
------------- 
-------------     def _train_epoch(self, epoch):
-------------         """
--------------        Training logic for an epoch, including logging and evaluation on
--------------        non-train partitions.
-------------+        Training logic for an epoch.
------------- 
-------------         Args:
--------------            epoch (int): current training epoch.
--------------        Returns:
--------------            logs (dict): logs that contain the average loss and metric in
--------------                this epoch.
-------------+            epoch (int): Current epoch number.
-------------         """
--------------        self.is_train = True
-----------+-@@ -194,6 +194,10 @@ class BaseTrainer:
----------- -         self.model.train()
----------- -         self.train_metrics.reset()
--------------        self.writer.set_step((epoch - 1) * self.epoch_len)
--------------        self.writer.add_scalar("epoch", epoch)
--------------        for batch_idx, batch in enumerate(
--------------            tqdm(self.train_dataloader, desc="train", total=self.epoch_len)
--------------        ):
-----------+-         
-----------+-+        # Получаем количество батчей для определения середины эпохи
-----------+-+        total_batches = len(self.train_dataloader)
-----------+-+        mid_epoch_batch = total_batches // 2
----------- -+        
-------------+        pbar = tqdm(self.train_dataloader, desc=f"Train Epoch {epoch}")
-------------+        for batch_idx, batch in enumerate(pbar):
-----------+-         pbar = tqdm(self.train_dataloader, desc=f"Train Epoch {epoch}")
-----------+-         for batch_idx, batch in enumerate(pbar):
----------- -             try:
--------------                batch = self.process_batch(
--------------                    batch,
--------------                    metrics=self.train_metrics,
--------------                )
--------------            except torch.cuda.OutOfMemoryError as e:
--------------                if self.skip_oom:
--------------                    self.logger.warning("OOM on batch. Skipping batch.")
--------------                    torch.cuda.empty_cache()  # free some memory
-------------+                batch = self.process_batch(batch, self.train_metrics)
-------------+                self._log_batch(batch_idx, batch, "train")
-------------+                
-------------+                # Выводим лосс в консоль каждые 50 батчей
-------------+                if batch_idx % 50 == 0:
-------------+                    loss_key = self.config.writer.loss_names[0]
-------------+                    current_loss = self.train_metrics.avg(loss_key)
-------------+                    print(f"[Batch {batch_idx}] Loss: {current_loss:.6f}")
-------------+                
-------------+                # Валидация в середине эпохи
-------------+                if batch_idx == len(self.train_dataloader) // 2 and "val" in self.evaluation_dataloaders:
-------------+                    self._quick_validation(epoch, "val", self.evaluation_dataloaders["val"])
-------------+                    
-------------+            except RuntimeError as e:
-------------+                if "out of memory" in str(e) and self.skip_oom:
-------------+                    if hasattr(torch.cuda, 'empty_cache'):
-------------+                        torch.cuda.empty_cache()
-------------                     continue
-------------                 else:
-------------                     raise e
-------------+                    
-------------+        self._log_scalars(self.train_metrics)
-------------+
-------------+    def _quick_validation(self, epoch, part, dataloader):
-------------+        """
-------------+        Быстрая валидация для отображения EER в середине эпохи.
------------- 
--------------            self.train_metrics.update("grad_norm", self._get_grad_norm())
--------------
--------------            # log current results
--------------            if batch_idx % self.log_step == 0:
--------------                self.writer.set_step((epoch - 1) * self.epoch_len + batch_idx)
--------------                self.logger.debug(
--------------                    "Train Epoch: {} {} Loss: {:.6f}".format(
--------------                        epoch, self._progress(batch_idx), batch["loss"].item()
--------------                    )
--------------                )
--------------                self.writer.add_scalar(
--------------                    "learning rate", self.lr_scheduler.get_last_lr()[0]
--------------                )
--------------                self._log_scalars(self.train_metrics)
--------------                self._log_batch(batch_idx, batch)
--------------                # we don't want to reset train metrics at the start of every epoch
--------------                # because we are interested in recent train metrics
--------------                last_train_metrics = self.train_metrics.result()
--------------                self.train_metrics.reset()
--------------            if batch_idx + 1 >= self.epoch_len:
--------------                break
--------------
--------------        logs = last_train_metrics
--------------
--------------        # Run val/test
--------------        for part, dataloader in self.evaluation_dataloaders.items():
--------------            val_logs = self._evaluation_epoch(epoch, part, dataloader)
--------------            logs.update(**{f"{part}_{name}": value for name, value in val_logs.items()})
--------------
--------------        return logs
-------------+        Args:
-------------+            epoch (int): Current epoch number.
-------------+            part (str): Name of the data part.
-------------+            dataloader (DataLoader): Dataloader for validation.
-------------+        """
-------------+        self.model.eval()
-------------+        temp_metrics = MetricTracker(
-------------+            *self.config.writer.loss_names,
-------------+            *[m.name for m in self.metrics["inference"]],
-------------+            writer=None,  # Не логируем в writer для быстрой валидации
-------------+        )
-------------+        
-------------+        with torch.no_grad():
-------------+            # Обрабатываем только первые несколько батчей для быстрой оценки
-------------+            num_batches = min(10, len(dataloader))  # Максимум 10 батчей
-------------+            for batch_idx, batch in enumerate(dataloader):
-------------+                if batch_idx >= num_batches:
-------------+                    break
-----------+-@@ -206,9 +210,18 @@ class BaseTrainer:
-----------+-                     current_loss = self.train_metrics.avg(loss_key)
-----------+-                     print(f"[Batch {batch_idx}] Loss: {current_loss:.6f}")
-----------+-                 
-----------+--                # Валидация в середине эпохи
-----------+--                if batch_idx == len(self.train_dataloader) // 2 and "val" in self.evaluation_dataloaders:
-----------+--                    self._quick_validation(epoch, "val", self.evaluation_dataloaders["val"])
-----------+-+                # Валидация в середине эпохи (если val_period = 1)
-----------+-+                if batch_idx == mid_epoch_batch and "val" in self.evaluation_dataloaders:
-----------+-+                    print(f"\n--- Валидация в середине эпохи {epoch} ---")
-----------+-+                    val_logs = {}
-----------+-+                    dataloader = self.evaluation_dataloaders["val"]
-----------+-+                    val_part_logs = self._evaluation_epoch(epoch, "val", dataloader)
-----------+-+                    val_logs.update(val_part_logs)
----------- -+                    
-------------+                try:
-------------+                    batch = self.process_batch(batch, temp_metrics)
-------------+                except RuntimeError as e:
-------------+                    if "out of memory" in str(e) and self.skip_oom:
-------------+                        if hasattr(torch.cuda, 'empty_cache'):
-------------+                            torch.cuda.empty_cache()
-------------+                        continue
-------------+                    else:
-------------+                        raise e
------------- 
-------------     def _evaluation_epoch(self, epoch, part, dataloader):
-------------         """
--------------        Evaluate model on the partition after training for an epoch.
-------------+        Validate after training an epoch.
------------- 
-------------         Args:
--------------            epoch (int): current training epoch.
--------------            part (str): partition to evaluate on
--------------            dataloader (DataLoader): dataloader for the partition.
-------------+            epoch (int): Current epoch number.
-------------+            part (str): Name of the data part.
-------------+            dataloader (DataLoader): Dataloader for validation.
-------------+
-------------         Returns:
--------------            logs (dict): logs that contain the information about evaluation.
-------------+            dict: Dictionary with validation logs.
-------------         """
--------------        self.is_train = False
-------------         self.model.eval()
-------------         self.evaluation_metrics.reset()
-------------+        
-------------         with torch.no_grad():
--------------            for batch_idx, batch in tqdm(
--------------                enumerate(dataloader),
--------------                desc=part,
--------------                total=len(dataloader),
--------------            ):
--------------                batch = self.process_batch(
--------------                    batch,
--------------                    metrics=self.evaluation_metrics,
--------------                )
--------------            self.writer.set_step(epoch * self.epoch_len, part)
--------------            self._log_scalars(self.evaluation_metrics)
--------------            self._log_batch(
--------------                batch_idx, batch, part
--------------            )  # log only the last batch during inference
--------------
-------------+            pbar = tqdm(dataloader, desc=f"Validation {part} Epoch {epoch}")
-------------+            for batch_idx, batch in enumerate(pbar):
-------------+                try:
-------------+                    batch = self.process_batch(batch, self.evaluation_metrics)
-------------+                    self._log_batch(batch_idx, batch, part)
-------------+                        
-------------+                except RuntimeError as e:
-------------+                    if "out of memory" in str(e) and self.skip_oom:
-------------+                        if hasattr(torch.cuda, 'empty_cache'):
-------------+                            torch.cuda.empty_cache()
-------------+                        continue
-------------+                    else:
-------------+                        raise e
-------------+
-------------+        self._log_scalars(self.evaluation_metrics)
-------------         return self.evaluation_metrics.result()
------------- 
-------------     def _monitor_performance(self, logs, not_improved_count):
-------------         """
--------------        Check if there is an improvement in the metrics. Used for early
--------------        stopping and saving the best checkpoint.
-------------+        Monitor the performance and save the best model.
------------- 
-------------         Args:
--------------            logs (dict): logs after training and evaluating the model for
--------------                an epoch.
--------------            not_improved_count (int): the current number of epochs without
--------------                improvement.
-------------+            logs (dict): Dictionary with validation logs.
-------------+            not_improved_count (int): Number of epochs without improvement.
-------------+
-------------         Returns:
--------------            best (bool): if True, the monitored metric has improved.
--------------            stop_process (bool): if True, stop the process (early stopping).
--------------                The metric did not improve for too much epochs.
--------------            not_improved_count (int): updated number of epochs without
--------------                improvement.
-----------+-+                    # Выводим метрики в консоль
-----------+-+                    for metric_name, metric_value in val_logs.items():
-----------+-+                        print(f"    {metric_name}: {metric_value:.6f}")
-----------+-+                    print("--- Конец валидации ---\n")
-----------+-                     
-----------+-             except RuntimeError as e:
-----------+-                 if "out of memory" in str(e) and self.skip_oom:
-----------+-@@ -220,39 +233,6 @@ class BaseTrainer:
-----------+-                     
-----------+-         self._log_scalars(self.train_metrics)
-----------+- 
-----------+--    def _quick_validation(self, epoch, part, dataloader):
----------- --        """
--------------        best = False
--------------        stop_process = False
--------------        if self.mnt_mode != "off":
--------------            try:
--------------                # check whether model performance improved or not,
--------------                # according to specified metric(mnt_metric)
--------------                if self.mnt_mode == "min":
--------------                    improved = logs[self.mnt_metric] <= self.mnt_best
--------------                elif self.mnt_mode == "max":
--------------                    improved = logs[self.mnt_metric] >= self.mnt_best
--------------                else:
--------------                    improved = False
--------------            except KeyError:
--------------                self.logger.warning(
--------------                    f"Warning: Metric '{self.mnt_metric}' is not found. "
--------------                    "Model performance monitoring is disabled."
--------------                )
--------------                self.mnt_mode = "off"
--------------                improved = False
--------------
--------------            if improved:
--------------                self.mnt_best = logs[self.mnt_metric]
--------------                not_improved_count = 0
--------------                best = True
--------------            else:
--------------                not_improved_count += 1
-----------+--        Быстрая валидация для отображения EER в середине эпохи.
----------- --
--------------            if not_improved_count >= self.early_stop:
--------------                self.logger.info(
--------------                    "Validation performance didn't improve for {} epochs. "
--------------                    "Training stops.".format(self.early_stop)
--------------                )
--------------                stop_process = True
--------------        return best, stop_process, not_improved_count
-------------+            bool: True if the model improved.
-------------+        """
-------------+        if self.mnt_mode == "off":
-------------+            return False
-------------+
-------------+        try:
-------------+            current = logs[self.mnt_metric]
-------------+        except KeyError:
-------------+            return False
-------------+
-------------+        if self.mnt_mode == "min":
-------------+            improved = current < self.mnt_best
-------------+        else:
-------------+            improved = current > self.mnt_best
-------------+
-------------+        if improved:
-------------+            self.mnt_best = current
-------------+            self._save_checkpoint(self._last_epoch, save_best=True)
-------------+
-------------+        return improved
------------- 
-------------     def move_batch_to_device(self, batch):
-------------         """
--------------        Move all necessary tensors to the device.
-------------+        Move batch to device.
------------- 
-------------         Args:
--------------            batch (dict): dict-based batch containing the data from
--------------                the dataloader.
-------------+            batch (dict): Batch to move to device.
-------------+
-------------         Returns:
--------------            batch (dict): dict-based batch containing the data from
--------------                the dataloader with some of the tensors on the device.
-------------+            dict: Batch on device.
-------------         """
--------------        for tensor_for_device in self.cfg_trainer.device_tensors:
--------------            batch[tensor_for_device] = batch[tensor_for_device].to(self.device)
-------------+        for k, v in batch.items():
-------------+            if isinstance(v, torch.Tensor):
-------------+                batch[k] = v.to(self.device)
-------------         return batch
------------- 
-------------     def transform_batch(self, batch):
-------------         """
--------------        Transforms elements in batch. Like instance transform inside the
--------------        BaseDataset class, but for the whole batch. Improves pipeline speed,
--------------        especially if used with a GPU.
--------------
--------------        Each tensor in a batch undergoes its own transform defined by the key.
-------------+        Transform batch using batch transforms.
------------- 
-------------         Args:
--------------            batch (dict): dict-based batch containing the data from
--------------                the dataloader.
-------------+            batch (dict): Batch to transform.
-------------+
-------------         Returns:
--------------            batch (dict): dict-based batch containing the data from
--------------                the dataloader (possibly transformed via batch transform).
-----------+--        Args:
-----------+--            epoch (int): Current epoch number.
-----------+--            part (str): Name of the data part.
-----------+--            dataloader (DataLoader): Dataloader for validation.
----------- --        """
--------------        # do batch transforms on device
--------------        transform_type = "train" if self.is_train else "inference"
--------------        transforms = self.batch_transforms.get(transform_type)
--------------        if transforms is not None:
--------------            for transform_name in transforms.keys():
--------------                batch[transform_name] = transforms[transform_name](
--------------                    batch[transform_name]
--------------                )
-------------+            dict: Transformed batch.
-------------+        """
-------------+        if self.batch_transforms is not None:
-------------+            for transform_name, transform in self.batch_transforms.items():
-------------+                if transform_name in batch:
-------------+                    batch[transform_name] = transform(batch[transform_name])
-------------         return batch
------------- 
-------------     def _clip_grad_norm(self):
-------------         """
--------------        Clips the gradient norm by the value defined in
--------------        config.trainer.max_grad_norm
-------------+        Clip gradient norm.
-------------         """
--------------        if self.config["trainer"].get("max_grad_norm", None) is not None:
-------------+        if self.cfg_trainer.get("grad_clip_norm") is not None:
-------------             clip_grad_norm_(
--------------                self.model.parameters(), self.config["trainer"]["max_grad_norm"]
-------------+                self.model.parameters(), self.cfg_trainer.grad_clip_norm
-------------             )
------------- 
-------------     @torch.no_grad()
-------------     def _get_grad_norm(self, norm_type=2):
-------------         """
--------------        Calculates the gradient norm for logging.
-------------+        Get gradient norm.
------------- 
-------------         Args:
--------------            norm_type (float | str | None): the order of the norm.
-------------+            norm_type (int): Type of norm.
-------------+
-------------         Returns:
--------------            total_norm (float): the calculated norm.
-------------+            float: Gradient norm.
-------------         """
-------------         parameters = self.model.parameters()
-------------         if isinstance(parameters, torch.Tensor):
-------------@@ -401,17 +375,14 @@ class BaseTrainer:
-------------             torch.stack([torch.norm(p.grad.detach(), norm_type) for p in parameters]),
-------------             norm_type,
-------------         )
--------------        return total_norm.item()
-------------+        return total_norm
------------- 
-------------     def _progress(self, batch_idx):
-------------         """
--------------        Calculates the percentage of processed batch within the epoch.
-------------+        Print progress.
------------- 
-------------         Args:
--------------            batch_idx (int): the current batch index.
--------------        Returns:
--------------            progress (str): contains current step and percentage
--------------                within the epoch.
-------------+            batch_idx (int): Current batch index.
-------------         """
-------------         base = "[{}/{} ({:.0f}%)]"
-------------         if hasattr(self.train_dataloader, "n_samples"):
-------------@@ -425,129 +396,106 @@ class BaseTrainer:
-------------     @abstractmethod
-------------     def _log_batch(self, batch_idx, batch, mode="train"):
-------------         """
--------------        Abstract method. Should be defined in the nested Trainer Class.
--------------
-------------         Log data from batch. Calls self.writer.add_* to log data
-------------         to the experiment tracker.
------------- 
-------------         Args:
--------------            batch_idx (int): index of the current batch.
--------------            batch (dict): dict-based batch after going through
--------------                the 'process_batch' function.
--------------            mode (str): train or inference. Defines which logging
--------------                rules to apply.
-------------+            batch_idx (int): Current batch index.
-------------+            batch (dict): Batch data.
-------------+            mode (str): Mode (train or validation).
-------------         """
--------------        return NotImplementedError()
-------------+        pass
------------- 
-------------     def _log_scalars(self, metric_tracker: MetricTracker):
-------------         """
--------------        Wrapper around the writer 'add_scalar' to log all metrics.
-------------+        Log scalars to the experiment tracker.
------------- 
-------------         Args:
--------------            metric_tracker (MetricTracker): calculated metrics.
-------------+            metric_tracker (MetricTracker): Metric tracker.
-------------         """
--------------        if self.writer is None:
--------------            return
--------------        for metric_name in metric_tracker.keys():
--------------            self.writer.add_scalar(f"{metric_name}", metric_tracker.avg(metric_name))
-------------+        for metric_name, metric_value in metric_tracker.result().items():
-------------+            self.writer.add_scalar(metric_name, metric_value)
------------- 
-------------     def _save_checkpoint(self, epoch, save_best=False, only_best=False):
-------------         """
--------------        Save the checkpoints.
-------------+        Save checkpoint.
------------- 
-------------         Args:
--------------            epoch (int): current epoch number.
--------------            save_best (bool): if True, rename the saved checkpoint to 'model_best.pth'.
--------------            only_best (bool): if True and the checkpoint is the best, save it only as
--------------                'model_best.pth'(do not duplicate the checkpoint as
--------------                checkpoint-epochEpochNumber.pth)
-------------+            epoch (int): Current epoch number.
-------------+            save_best (bool): Whether to save the best model.
-------------+            only_best (bool): Whether to save only the best model.
-------------         """
-------------         arch = type(self.model).__name__
-------------+
-------------         state = {
-------------             "arch": arch,
-------------             "epoch": epoch,
-------------             "state_dict": self.model.state_dict(),
-------------             "optimizer": self.optimizer.state_dict(),
--------------            "lr_scheduler": self.lr_scheduler.state_dict(),
-------------             "monitor_best": self.mnt_best,
-------------             "config": self.config,
-------------         }
--------------        filename = str(self.checkpoint_dir / f"checkpoint-epoch{epoch}.pth")
--------------        if not (only_best and save_best):
--------------            torch.save(state, filename)
--------------            if self.config.writer.log_checkpoints:
--------------                self.writer.add_checkpoint(filename, str(self.checkpoint_dir.parent))
--------------            self.logger.info(f"Saving checkpoint: {filename} ...")
-------------+
-------------+        if self.lr_scheduler is not None:
-------------+            state["lr_scheduler"] = self.lr_scheduler.state_dict()
-------------+
-------------+        filename = str(self.checkpoint_dir / "checkpoint-epoch{}.pth".format(epoch))
-------------+        if not (self.checkpoint_dir).exists():
-------------+            self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
-------------+
-------------         if save_best:
-------------             best_path = str(self.checkpoint_dir / "model_best.pth")
-------------             torch.save(state, best_path)
--------------            if self.config.writer.log_checkpoints:
--------------                self.writer.add_checkpoint(best_path, str(self.checkpoint_dir.parent))
--------------            self.logger.info("Saving current best: model_best.pth ...")
-------------+            del state["optimizer"], state["lr_scheduler"], state["config"]
-------------+            torch.save(state, best_path + ".tmp")
-------------+            import os
-------------+            os.replace(best_path + ".tmp", best_path)
-------------+        elif not only_best:
-------------+            torch.save(state, filename)
-------------+            del state["optimizer"], state["lr_scheduler"], state["config"]
-------------+            torch.save(state, filename + ".tmp")
-------------+            import os
-------------+            os.replace(filename + ".tmp", filename)
------------- 
-------------     def _resume_checkpoint(self, resume_path):
-------------         """
--------------        Resume from a saved checkpoint (in case of server crash, etc.).
--------------        The function loads state dicts for everything, including model,
--------------        optimizers, etc.
--------------
--------------        Notice that the checkpoint should be located in the current experiment
--------------        saved directory (where all checkpoints are saved in '_save_checkpoint').
-------------+        Resume from saved checkpoint.
------------- 
-------------         Args:
--------------            resume_path (str): Path to the checkpoint to be resumed.
-------------+            resume_path (str): Path to checkpoint.
-------------         """
-------------         resume_path = str(resume_path)
--------------        self.logger.info(f"Loading checkpoint: {resume_path} ...")
--------------        checkpoint = torch.load(resume_path, self.device)
-------------+        checkpoint = torch.load(resume_path, map_location=self.device)
-------------         self.start_epoch = checkpoint["epoch"] + 1
-------------         self.mnt_best = checkpoint["monitor_best"]
------------- 
-------------         # load architecture params from checkpoint.
-------------         if checkpoint["config"]["model"] != self.config["model"]:
-------------             self.logger.warning(
--------------                "Warning: Architecture configuration given in the config file is different from that "
--------------                "of the checkpoint. This may yield an exception when state_dict is loaded."
-------------+                "Warning: Architecture configuration given in config file is different from that of checkpoint. "
-------------+                "This may create an exception while state_dict is being loaded."
-------------             )
-------------         self.model.load_state_dict(checkpoint["state_dict"])
------------- 
-------------         # load optimizer state from checkpoint only when optimizer type is not changed.
--------------        if (
--------------            checkpoint["config"]["optimizer"] != self.config["optimizer"]
--------------            or checkpoint["config"]["lr_scheduler"] != self.config["lr_scheduler"]
--------------        ):
-------------+        if checkpoint["config"]["optimizer"] != self.config["optimizer"]:
-------------             self.logger.warning(
--------------                "Warning: Optimizer or lr_scheduler given in the config file is different "
--------------                "from that of the checkpoint. Optimizer and scheduler parameters "
--------------                "are not resumed."
-------------+                "Warning: Optimizer or lr_scheduler given in config file is different "
-------------+                "from that of checkpoint. Optimizer parameters not being resumed."
-------------             )
-------------         else:
-------------             self.optimizer.load_state_dict(checkpoint["optimizer"])
--------------            self.lr_scheduler.load_state_dict(checkpoint["lr_scheduler"])
------------- 
--------------        self.logger.info(
--------------            f"Checkpoint loaded. Resume training from epoch {self.start_epoch}"
-----------+--        self.model.eval()
-----------+--        temp_metrics = MetricTracker(
-----------+--            *self.config.writer.loss_names,
-----------+--            *[m.name for m in self.metrics["inference"]],
-----------+--            writer=None,  # Не логируем в writer для быстрой валидации
----------- --        )
-------------+        if self.lr_scheduler is not None and "lr_scheduler" in checkpoint:
-------------+            self.lr_scheduler.load_state_dict(checkpoint["lr_scheduler"])
------------- 
-------------     def _from_pretrained(self, pretrained_path):
-------------         """
--------------        Init model with weights from pretrained pth file.
--------------
--------------        Notice that 'pretrained_path' can be any path on the disk. It is not
--------------        necessary to locate it in the experiment saved dir. The function
--------------        initializes only the model.
-------------+        Load pretrained model.
------------- 
-------------         Args:
--------------            pretrained_path (str): path to the model state dict.
-------------+            pretrained_path (str): Path to pretrained model.
-------------         """
-------------         pretrained_path = str(pretrained_path)
--------------        if hasattr(self, "logger"):  # to support both trainer and inferencer
--------------            self.logger.info(f"Loading model weights from: {pretrained_path} ...")
--------------        else:
--------------            print(f"Loading model weights from: {pretrained_path} ...")
--------------        checkpoint = torch.load(pretrained_path, self.device)
-----------+--        
-----------+--        with torch.no_grad():
-----------+--            # Обрабатываем только первые несколько батчей для быстрой оценки
-----------+--            num_batches = min(10, len(dataloader))  # Максимум 10 батчей
-----------+--            for batch_idx, batch in enumerate(dataloader):
-----------+--                if batch_idx >= num_batches:
-----------+--                    break
-----------+--                    
-----------+--                try:
-----------+--                    batch = self.process_batch(batch, temp_metrics)
-----------+--                except RuntimeError as e:
-----------+--                    if "out of memory" in str(e) and self.skip_oom:
-----------+--                        if hasattr(torch.cuda, 'empty_cache'):
-----------+--                            torch.cuda.empty_cache()
-----------+--                        continue
-----------+--                    else:
-----------+--                        raise e
----------- --
--------------        if checkpoint.get("state_dict") is not None:
--------------            self.model.load_state_dict(checkpoint["state_dict"])
--------------        else:
--------------            self.model.load_state_dict(checkpoint)
-------------\ No newline at end of file
-------------+        checkpoint = torch.load(pretrained_path, map_location=self.device)
-------------+        self.model.load_state_dict(checkpoint["state_dict"])
-------------\ No newline at end of file
-------------diff --git a/src/trainer/trainer.py b/src/trainer/trainer.py
-------------index 3313fea..f2b2faa 100644
---------------- a/src/trainer/trainer.py
-------------+++ b/src/trainer/trainer.py
-------------@@ -61,9 +61,9 @@ class Trainer(BaseTrainer):
-------------         for met in metric_funcs:
-------------             if met.name != "eer":
-------------                 try:
--------------                    metrics.update(met.name, met(**batch))
-------------+                    metric_value = met(**batch)
-------------+                    metrics.update(met.name, metric_value)
-------------                 except Exception as e:
--------------                    print(f"Ошибка в метрике {met.name}: {e}")
-------------                     continue
-------------         return batch
------------- 
-------------@@ -72,4 +72,13 @@ class Trainer(BaseTrainer):
-------------         Log data from batch. Calls self.writer.add_* to log data
-------------         to the experiment tracker.
-----------+-     def _evaluation_epoch(self, epoch, part, dataloader):
----------- -         """
--------------        pass
-------------\ No newline at end of file
-------------+        # Логируем информацию о батче для writer
-------------+        if self.writer is not None:
-------------+            # Логируем learning rate
-------------+            if mode == "train" and self.lr_scheduler is not None:
-------------+                self.writer.add_scalar("learning_rate", self.lr_scheduler.get_last_lr()[0])
-------------+            
-------------+            # Логируем градиентную норму
-------------+            if mode == "train":
-------------+                grad_norm = self._get_grad_norm()
-------------+                self.writer.add_scalar("grad_norm", grad_norm)
-------------\ No newline at end of file
-------------diff --git a/src/transforms/__init__.py b/src/transforms/__init__.py
-------------index bea0123..1c032b1 100644
---------------- a/src/transforms/__init__.py
-------------+++ b/src/transforms/__init__.py
-------------@@ -1,3 +1,3 @@
------------- from src.transforms.normalize import Normalize
------------- from src.transforms.scale import RandomScale1D
--------------from src.transforms.stft import AudioFrontend
-------------\ No newline at end of file
-------------+from src.transforms.stft import STFTTransform, MelSpectrogramTransform
-------------\ No newline at end of file
-------------diff --git a/src/transforms/stft.py b/src/transforms/stft.py
-------------index 954ff81..f7e362f 100644
---------------- a/src/transforms/stft.py
-------------+++ b/src/transforms/stft.py
-------------@@ -1,37 +1,177 @@
------------- import torch
------------- import torch.nn as nn
-------------+import torchaudio
-------------+from typing import Dict, Any
------------- 
------------- 
--------------def audio_frontend(waveform):
-------------+class STFTTransform(nn.Module):
-------------+    """
-------------+    Short-Time Fourier Transform (STFT) for audio processing.
-------------+    """
------------- 
--------------    n_fft = 1024
--------------    hop_length = 256
--------------    win_length = 1024
-------------+    def __init__(self, n_fft=1024, hop_length=512, win_length=1024, **kwargs):
-------------+        """
-------------+        Args:
-------------+            n_fft (int): FFT window size
-------------+            hop_length (int): Number of samples between successive frames
-------------+            win_length (int): Window size
-------------+            **kwargs: additional arguments
-------------+        """
-------------+        super(STFTTransform, self).__init__()
-------------+        
-------------+        print("🎵 Инициализация STFTTransform...")
-------------+        print(f"   📊 n_fft: {n_fft}")
-------------+        print(f"   📊 hop_length: {hop_length}")
-------------+        print(f"   📊 win_length: {win_length}")
-------------+        
-------------+        # Логируем дополнительные параметры
-------------+        for key, value in kwargs.items():
-------------+            print(f"   📊 {key}: {value}")
-------------+        
-------------+        self.n_fft = n_fft
-------------+        self.hop_length = hop_length
-------------+        self.win_length = win_length
-------------+        
-------------+        print("✅ STFTTransform инициализирован")
------------- 
--------------    waveform = waveform.squeeze()
-------------+    def forward(self, audio: torch.Tensor) -> torch.Tensor:
-------------+        """
-------------+        Apply STFT to audio signal.
-------------+        
-------------+        Args:
-------------+            audio (torch.Tensor): input audio tensor
-------------+            
-------------+        Returns:
-------------+            torch.Tensor: STFT spectrogram
-------------+        """
-------------+        # Логируем входные данные (только для отладки)
-------------+        if hasattr(self, '_debug_forward') and self._debug_forward:
-------------+            print(f"   🎵 STFTTransform forward: audio shape={audio.shape}")
-------------+            print(f"      Audio range: [{audio.min().item():.4f}, {audio.max().item():.4f}]")
-------------+            print(f"      Audio dtype: {audio.dtype}")
-------------+        
-------------+        # Убеждаемся, что аудио имеет правильную форму
-------------+        if audio.dim() == 1:
-------------+            audio = audio.unsqueeze(0)  # Добавляем batch dimension
-------------+        elif audio.dim() == 3:
-------------+            audio = audio.squeeze(1)  # Убираем лишний канал
-------------+        
-------------+        # Применяем STFT
-------------+        stft_output = torch.stft(
-------------+            audio,
-------------+            n_fft=self.n_fft,
-------------+            hop_length=self.hop_length,
-------------+            win_length=self.win_length,
-------------+            return_complex=True,
-------------+            window=torch.hann_window(self.win_length).to(audio.device)
-------------+        )
-------------+        
-------------+        # Конвертируем в спектрограмму
-------------+        spectrogram = torch.abs(stft_output)
-------------+        
-------------+        # Логируем выходные данные
-------------+        if hasattr(self, '_debug_forward') and self._debug_forward:
-------------+            print(f"   📊 STFT output shape: {stft_output.shape}")
-------------+            print(f"   📊 Spectrogram shape: {spectrogram.shape}")
-------------+            print(f"   📊 Spectrogram range: [{spectrogram.min().item():.4f}, {spectrogram.max().item():.4f}]")
-------------+        
-------------+        return spectrogram
------------- 
--------------    stft = torch.stft(
--------------        waveform,
--------------        n_fft=n_fft,
--------------        hop_length=hop_length,
--------------        win_length=win_length,
--------------        window=torch.hann_window(win_length, device=waveform.device),
--------------        return_complex=True
--------------    )
-------------+    def set_debug_mode(self, debug_forward=False):
-------------+        """
-------------+        Включает режим отладки для логирования forward pass.
-------------+        
-------------+        Args:
-------------+            debug_forward (bool): логировать forward pass
-------------+        """
-------------+        self._debug_forward = debug_forward
-------------+        if debug_forward:
-------------+            print(f"🐛 Режим отладки включен для {self.__class__.__name__}")
-------------+            print(f"   🎵 Debug forward: {debug_forward}")
------------- 
--------------    magnitude = torch.abs(stft)
--------------    log_magnitude = torch.log(magnitude + 1e-8)
--------------    log_magnitude = log_magnitude.unsqueeze(0)
--------------    return log_magnitude
------------- 
-------------+class MelSpectrogramTransform(nn.Module):
-------------+    """
-------------+    Mel Spectrogram transform for audio processing.
-------------+    """
------------- 
--------------class AudioFrontend(nn.Module):
--------------    
--------------    def __init__(self):
--------------        super().__init__()
--------------    
--------------    def forward(self, waveform):
--------------      
-------------+    def __init__(self, sample_rate=16000, n_fft=1024, hop_length=512, n_mels=80, **kwargs):
-------------+        """
-------------+        Args:
-------------+            sample_rate (int): Audio sample rate
-------------+            n_fft (int): FFT window size
-------------+            hop_length (int): Number of samples between successive frames
-------------+            n_mels (int): Number of mel filter banks
-------------+            **kwargs: additional arguments
-------------+        """
-------------+        super(MelSpectrogramTransform, self).__init__()
-------------+        
-------------+        print("🎵 Инициализация MelSpectrogramTransform...")
-------------+        print(f"   📊 sample_rate: {sample_rate}")
-------------+        print(f"   📊 n_fft: {n_fft}")
-------------+        print(f"   📊 hop_length: {hop_length}")
-------------+        print(f"   📊 n_mels: {n_mels}")
-------------+        
-------------+        # Логируем дополнительные параметры
-------------+        for key, value in kwargs.items():
-------------+            print(f"   📊 {key}: {value}")
-------------+        
-------------+        self.sample_rate = sample_rate
-------------+        self.n_fft = n_fft
-------------+        self.hop_length = hop_length
-------------+        self.n_mels = n_mels
-------------+        
-------------+        # Создаем mel spectrogram transform
-------------+        self.mel_transform = torchaudio.transforms.MelSpectrogram(
-------------+            sample_rate=sample_rate,
-------------+            n_fft=n_fft,
-------------+            hop_length=hop_length,
-------------+            n_mels=n_mels,
-------------+            window_fn=torch.hann_window
-------------+        )
-------------+        
-------------+        print("✅ MelSpectrogramTransform инициализирован")
------------- 
-------------+    def forward(self, audio: torch.Tensor) -> torch.Tensor:
-------------+        """
-------------+        Apply Mel Spectrogram transform to audio signal.
-------------+        
-------------+        Args:
-------------+            audio (torch.Tensor): input audio tensor
-------------+            
-------------+        Returns:
-------------+            torch.Tensor: Mel spectrogram
-------------+        """
-------------+        # Логируем входные данные (только для отладки)
-------------+        if hasattr(self, '_debug_forward') and self._debug_forward:
-------------+            print(f"   🎵 MelSpectrogramTransform forward: audio shape={audio.shape}")
-------------+            print(f"      Audio range: [{audio.min().item():.4f}, {audio.max().item():.4f}]")
-------------+            print(f"      Audio dtype: {audio.dtype}")
-------------+        
-------------+        # Убеждаемся, что аудио имеет правильную форму
-------------+        if audio.dim() == 1:
-------------+            audio = audio.unsqueeze(0)  # Добавляем batch dimension
-------------+        elif audio.dim() == 3:
-------------+            audio = audio.squeeze(1)  # Убираем лишний канал
-------------+        
-------------+        # Применяем mel spectrogram transform
-------------+        mel_spectrogram = self.mel_transform(audio)
-------------+        
-------------+        # Логируем выходные данные
-------------+        if hasattr(self, '_debug_forward') and self._debug_forward:
-------------+            print(f"   📊 Mel spectrogram shape: {mel_spectrogram.shape}")
-------------+            print(f"   📊 Mel spectrogram range: [{mel_spectrogram.min().item():.4f}, {mel_spectrogram.max().item():.4f}]")
-------------+        
-------------+        return mel_spectrogram
------------- 
--------------        return audio_frontend(waveform)
-------------\ No newline at end of file
-------------+    def set_debug_mode(self, debug_forward=False):
-------------+        """
-------------+        Включает режим отладки для логирования forward pass.
-------------+        
-------------+        Args:
-------------+            debug_forward (bool): логировать forward pass
-------------+        """
-------------+        self._debug_forward = debug_forward
-------------+        if debug_forward:
-------------+            print(f"🐛 Режим отладки включен для {self.__class__.__name__}")
-------------+            print(f"   🎵 Debug forward: {debug_forward}")
-------------\ No newline at end of file
-------------diff --git a/train.py b/train.py
-------------index 90a7a4f..ea54b46 100644
---------------- a/train.py
-------------+++ b/train.py
-------------@@ -26,6 +26,7 @@ def main(config):
------------- 
-------------     project_config = OmegaConf.to_container(config)
-------------     logger = setup_saving_and_logging(config)
-------------+    
-------------     writer = instantiate(config.writer, logger, project_config)
------------- 
-------------     if config.trainer.device == "auto":
-------------@@ -34,20 +35,26 @@ def main(config):
-------------         device = config.trainer.device
------------- 
-------------     # setup data_loader instances
--------------    # batch_transforms should be put on device
-------------     dataloaders, batch_transforms = get_dataloaders(config, device)
------------- 
-------------     # build model architecture, then print to console
-------------     model = instantiate(config.model).to(device)
-------------+    
-------------+    # Подсчет параметров модели
-------------+    total_params = sum(p.numel() for p in model.parameters())
-------------+    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
-------------+    
-------------     logger.info(model)
------------- 
-------------     # get function handles of loss and metrics
-------------     loss_function = instantiate(config.loss_function).to(device)
-------------+    
-------------     metrics = instantiate(config.metrics)
------------- 
-------------     # build optimizer, learning rate scheduler
-------------     trainable_params = filter(lambda p: p.requires_grad, model.parameters())
-------------     optimizer = instantiate(config.optimizer, params=trainable_params)
-------------+    
-------------     lr_scheduler = instantiate(config.lr_scheduler, optimizer=optimizer)
------------- 
-------------     # epoch_len = number of iterations for iteration-based training
------------diff --git a/src/metrics/tracker.py b/src/metrics/tracker.py
------------index 79712bd..e9a1d72 100644
--------------- a/src/metrics/tracker.py
------------+++ b/src/metrics/tracker.py
------------@@ -50,24 +50,51 @@ class MetricTracker:
------------         self._eer_labels.extend(labels.detach().cpu().numpy())
-----------+-         Validate after training an epoch.
-----------+diff --git a/src/datasets/data_utils.py b/src/datasets/data_utils.py
-----------+index 63e8cce..5a004ee 100644
-----------+--- a/src/datasets/data_utils.py
-----------++++ b/src/datasets/data_utils.py
-----------+@@ -46,7 +46,7 @@ def move_batch_transforms_to_device(batch_transforms, device):
-----------+                 transforms[transform_name] = transforms[transform_name].to(device)
-----------+ 
-----------+ 
-----------+-def get_dataloaders(config, device):
-----------++def get_dataloaders(config, device, debug_mode=False):
-----------+     """
-----------+     Create dataloaders for each of the dataset partitions.
-----------+     Also creates instance and batch transforms.
-----------+@@ -54,6 +54,7 @@ def get_dataloaders(config, device):
-----------+     Args:
-----------+         config (DictConfig): hydra experiment config.
-----------+         device (str): device to use for batch transforms.
-----------++        debug_mode (bool): if True, create minimal dataloaders for debugging.
-----------+     Returns:
-----------+         dataloaders (dict[DataLoader]): dict containing dataloader for a
-----------+             partition defined by key.
-----------+@@ -71,22 +72,51 @@ def get_dataloaders(config, device):
-----------  
------------     def compute_eer(self):
-----------+     # dataloaders init
-----------+     dataloaders = {}
-----------++    debug_subset = None  # Сохраняем один subset для всех разделов
-----------++    
-----------+     for dataset_partition in config.datasets.keys():
-----------+         dataset = datasets[dataset_partition]
----------- -
------------+        """
------------+        Compute Equal Error Rate from accumulated scores and labels.
------------+        """
------------         if not self._eer_scores:
------------             return 0.0
------------         
------------         scores = np.array(self._eer_scores)
------------         labels = np.array(self._eer_labels)
------------         
-------------        bona_scores = scores[labels == 1]
-------------        spoof_scores = scores[labels == 0]
------------+        # Получаем уникальные пороги
------------+        thresholds = np.unique(scores)
------------         
-------------        if len(bona_scores) == 0 or len(spoof_scores) == 0:
-------------            return 0.0
------------+        # Вычисляем FAR и FRR для каждого порога
------------+        far_values = []
------------+        frr_values = []
------------+        
------------+        for threshold in thresholds:
------------+            # Предсказания: 1 если score >= threshold, иначе 0
------------+            predictions = (scores >= threshold).astype(int)
------------+            
------------+            # Вычисляем confusion matrix
------------+            tp = np.sum((predictions == 1) & (labels == 1))
------------+            tn = np.sum((predictions == 0) & (labels == 0))
------------+            fp = np.sum((predictions == 1) & (labels == 0))
------------+            fn = np.sum((predictions == 0) & (labels == 1))
------------+            
------------+            # Вычисляем FAR и FRR
------------+            far = fp / (fp + tn) if (fp + tn) > 0 else 0
------------+            frr = fn / (fn + tp) if (fn + tp) > 0 else 0
------------+            
------------+            far_values.append(far)
------------+            frr_values.append(frr)
-----------+-        assert config.dataloader.batch_size <= len(dataset), (
-----------+-            f"The batch size ({config.dataloader.batch_size}) cannot "
----------- +        
------------+        # Находим точку, где FAR ≈ FRR
------------+        far_values = np.array(far_values)
------------+        frr_values = np.array(frr_values)
-----------++        # Для отладки все разделы используют одни и те же данные из train
-----------++        if debug_mode:
-----------++            from torch.utils.data import Subset
-----------++            if debug_subset is None:
-----------++                # Создаем subset только один раз из первого датасета (обычно train)
-----------++                debug_subset_indices = range(min(4, len(dataset)))
-----------++                debug_subset = Subset(dataset, debug_subset_indices)
-----------++                print(f"🔧 Debug mode: используем {len(debug_subset)} образцов для всех разделов")
-----------++            dataset = debug_subset
-----------++
-----------++        # Для отладки изменяем параметры даталоадера
-----------++        if debug_mode:
-----------++            batch_size = min(2, len(dataset))
-----------++            num_workers = 0
-----------++            pin_memory = False
-----------++        else:
-----------++            batch_size = config.dataloader.batch_size
-----------++            num_workers = getattr(config.dataloader, 'num_workers', 4)
-----------++            pin_memory = getattr(config.dataloader, 'pin_memory', True)
-----------++
-----------++        assert batch_size <= len(dataset), (
-----------++            f"The batch size ({batch_size}) cannot "
-----------+             f"be larger than the dataset length ({len(dataset)})"
-----------+         )
-----------+ 
-----------+         partition_dataloader = instantiate(
-----------+             config.dataloader,
-----------+             dataset=dataset,
-----------++            batch_size=batch_size,
-----------++            num_workers=num_workers,
-----------++            pin_memory=pin_memory,
-----------+             collate_fn=collate_fn,
-----------+-            drop_last=(dataset_partition == "train"),
-----------+-            shuffle=(dataset_partition == "train"),
-----------++            drop_last=False,  # В debug режиме не отбрасываем данные
-----------++            shuffle=False,    # В debug режиме не перемешиваем для воспроизводимости
-----------+             worker_init_fn=set_worker_seed,
-----------+         )
----------- +        
------------+        # Находим индекс, где разность минимальна
------------+        diff = np.abs(far_values - frr_values)
------------+        min_idx = np.argmin(diff)
-----------+         dataloaders[dataset_partition] = partition_dataloader
----------- +        
------------+        # EER - это среднее FAR и FRR в этой точке
------------+        eer = (far_values[min_idx] + frr_values[min_idx]) / 2
------------         
-------------        # Вычисляем EER
-------------        from src.metrics.eer import EERMetric
-------------        eer_metric = EERMetric()
-------------        eer, _ = eer_metric.compute_eer(bona_scores, spoof_scores)
-------------        return eer
------------+        return float(eer)
-----------++        if debug_mode:
-----------++            print(f"📁 {dataset_partition}: {len(dataset)} образцов, batch_size={batch_size}")
-----------  
------------     def avg(self, key):
-----------+     return dataloaders, batch_transforms
-----------+\ No newline at end of file
-----------+diff --git a/src/datasets/mydataset.py b/src/datasets/mydataset.py
-----------+index 94e7e12..e5d6aa7 100644
-----------+--- a/src/datasets/mydataset.py
-----------++++ b/src/datasets/mydataset.py
-----------+@@ -15,7 +15,7 @@ class AudioSpoofingDataset(BaseDataset):
-----------+ 
-----------+     def __init__(
-----------+         self, name="train", label_path=None, audio_path=None, out_path=None, 
-----------+-        instance_transforms=None, *args, **kwargs
-----------++        instance_transforms=None, max_samples=None, *args, **kwargs
-----------+     ):
-----------+         """
-----------+         Args:
-----------+@@ -24,11 +24,13 @@ class AudioSpoofingDataset(BaseDataset):
-----------+             audio_path (str): path to the directory with .flac files
-----------+             out_path (str): where to save index.json
-----------+             instance_transforms (dict): transforms to apply to instances
-----------++            max_samples (int): maximum number of samples for debugging (None for all)
-----------          """
-----------+         self.name = name
-----------+         self.label_path = label_path
-----------+         self.audio_path = audio_path
-----------+         self.out_path = out_path
-----------++        self.max_samples = max_samples
-----------+         
-----------+         # Create index if it doesn't exist
-----------+         if Path(out_path).exists():
-----------+@@ -36,6 +38,10 @@ class AudioSpoofingDataset(BaseDataset):
-----------+         else:
-----------+             index = self._create_index(label_path, audio_path, out_path)
-----------+ 
-----------++        # Ограничиваем размер датасета для отладки
-----------++        if max_samples is not None:
-----------++            index = index[:max_samples]
-----------++
-----------+         super().__init__(index, instance_transforms=instance_transforms, *args, **kwargs)
-----------+ 
-----------+     def __getitem__(self, idx):
----------- diff --git a/src/trainer/base_trainer.py b/src/trainer/base_trainer.py
------------index 0d4e7a1..9f6663a 100644
-----------+index de03b18..15a1282 100644
----------- --- a/src/trainer/base_trainer.py
----------- +++ b/src/trainer/base_trainer.py
------------@@ -194,6 +194,10 @@ class BaseTrainer:
------------         self.model.train()
------------         self.train_metrics.reset()
------------         
------------+        # Получаем количество батчей для определения середины эпохи
------------+        total_batches = len(self.train_dataloader)
------------+        mid_epoch_batch = total_batches // 2
------------+        
------------         pbar = tqdm(self.train_dataloader, desc=f"Train Epoch {epoch}")
------------         for batch_idx, batch in enumerate(pbar):
------------             try:
------------@@ -206,9 +210,18 @@ class BaseTrainer:
------------                     current_loss = self.train_metrics.avg(loss_key)
------------                     print(f"[Batch {batch_idx}] Loss: {current_loss:.6f}")
-----------+@@ -172,8 +172,9 @@ class BaseTrainer:
-----------+                 
-----------+                 # Дополнительно логируем финальные метрики валидации в конце эпохи
-----------+                 if self.writer is not None:
-----------++                    self.writer.set_step(epoch, "val")
-----------+                     for metric_name, metric_value in val_logs.items():
-----------+-                        self.writer.add_scalar(f"val_{metric_name}_final", metric_value, epoch)
-----------++                        self.writer.add_scalar(f"val_{metric_name}_final", metric_value)
-----------+                 
-----------+                 # Выводим финальные метрики валидации в консоль
-----------+                 print(f"    Финальная валидация эпохи {epoch}:")
-----------+@@ -223,16 +224,20 @@ class BaseTrainer:
-----------+                     
-----------+                     # Логируем train_loss в CometML каждые 50 батчей
-----------+                     if self.writer is not None:
-----------+-                        self.writer.add_scalar("train_loss_batch", current_loss, batch_idx)
-----------++                        self.writer.set_step(batch_idx, "train")
-----------++                        self.writer.add_scalar("train_loss_batch", current_loss)
-----------                  
-------------                # Валидация в середине эпохи
-------------                if batch_idx == len(self.train_dataloader) // 2 and "val" in self.evaluation_dataloaders:
-------------                    self._quick_validation(epoch, "val", self.evaluation_dataloaders["val"])
------------+                # Валидация в середине эпохи (если val_period = 1)
------------+                if batch_idx == mid_epoch_batch and "val" in self.evaluation_dataloaders:
------------+                    print(f"\n--- Валидация в середине эпохи {epoch} ---")
------------+                    val_logs = {}
------------+                    dataloader = self.evaluation_dataloaders["val"]
------------+                    val_part_logs = self._evaluation_epoch(epoch, "val", dataloader)
------------+                    val_logs.update(val_part_logs)
------------+                    
------------+                    # Выводим метрики в консоль
------------+                    for metric_name, metric_value in val_logs.items():
------------+                        print(f"    {metric_name}: {metric_value:.6f}")
------------+                    print("--- Конец валидации ---\n")
-----------+                 # Валидация в середине эпохи (если val_period = 1)
-----------+                 if batch_idx == mid_epoch_batch and "val" in self.evaluation_dataloaders:
-----------+                     # Сохраняем текущий режим
-----------+                     was_training = self.is_train
-----------++                    was_model_training = self.model.training
-----------+                     
-----------+-                    # Устанавливаем режим валидации
-----------+-                    self.is_train = False
-----------+-                    self.model.eval()
-----------++                    # В debug режиме пропускаем валидацию в середине эпохи для упрощения
-----------++                    debug_mode = getattr(self.config, 'debug_mode', False)
-----------++                    if debug_mode:
-----------++                        print("🔧 Debug mode: пропускаем валидацию в середине эпохи")
-----------++                        continue
-----------+                     
-----------+                     # Создаем временный MetricTracker для валидации в середине эпохи
-----------+                     mid_epoch_metrics = MetricTracker(
-----------+@@ -251,8 +256,9 @@ class BaseTrainer:
-----------+                     
-----------+                     # Дополнительно логируем валидационные метрики в середине эпохи
-----------+                     if self.writer is not None:
-----------++                        self.writer.set_step(batch_idx, "val")
-----------+                         for metric_name, metric_value in val_logs.items():
-----------+-                            self.writer.add_scalar(f"val_{metric_name}_mid_epoch", metric_value, batch_idx)
-----------++                            self.writer.add_scalar(f"val_{metric_name}_mid_epoch", metric_value)
-----------+                     
-----------+                     # Выводим метрики валидации в консоль
-----------+                     print(f"    Валидация в середине эпохи {epoch}:")
-----------+@@ -261,8 +267,8 @@ class BaseTrainer:
-----------+                     print()
-----------+                     
-----------+                     # Возвращаем режим обучения
-----------+-                    self.is_train = True
-----------+-                    self.model.train()
-----------++                    self.is_train = was_training
-----------++                    self.model.train(was_model_training)
-----------                      
-----------              except RuntimeError as e:
-----------                  if "out of memory" in str(e) and self.skip_oom:
------------@@ -220,39 +233,6 @@ class BaseTrainer:
------------                     
------------         self._log_scalars(self.train_metrics)
-----------+@@ -276,8 +282,9 @@ class BaseTrainer:
-----------+         
-----------+         # Дополнительно логируем финальные метрики тренировки
-----------+         if self.writer is not None:
-----------++            self.writer.set_step(epoch, "train")
-----------+             for metric_name, metric_value in self.train_metrics.result().items():
-----------+-                self.writer.add_scalar(f"train_{metric_name}_epoch", metric_value, epoch)
-----------++                self.writer.add_scalar(f"train_{metric_name}_epoch", metric_value)
-----------  
-------------    def _quick_validation(self, epoch, part, dataloader):
-------------        """
-------------        Быстрая валидация для отображения EER в середине эпохи.
-------------
-------------        Args:
-------------            epoch (int): Current epoch number.
-------------            part (str): Name of the data part.
-------------            dataloader (DataLoader): Dataloader for validation.
-------------        """
-------------        self.model.eval()
-------------        temp_metrics = MetricTracker(
-------------            *self.config.writer.loss_names,
-------------            *[m.name for m in self.metrics["inference"]],
-------------            writer=None,  # Не логируем в writer для быстрой валидации
-------------        )
-------------        
-------------        with torch.no_grad():
-------------            # Обрабатываем только первые несколько батчей для быстрой оценки
-------------            num_batches = min(10, len(dataloader))  # Максимум 10 батчей
-------------            for batch_idx, batch in enumerate(dataloader):
-------------                if batch_idx >= num_batches:
-------------                    break
-------------                    
-------------                try:
-------------                    batch = self.process_batch(batch, temp_metrics)
-------------                except RuntimeError as e:
-------------                    if "out of memory" in str(e) and self.skip_oom:
-------------                        if hasattr(torch.cuda, 'empty_cache'):
-------------                            torch.cuda.empty_cache()
-------------                        continue
-------------                    else:
-------------                        raise e
-------------
-----------      def _evaluation_epoch(self, epoch, part, dataloader):
-----------          """
------------         Validate after training an epoch.
-----------+@@ -291,12 +298,26 @@ class BaseTrainer:
-----------+         Returns:
-----------+             dict: Dictionary with validation logs.
-----------+         """
-----------+-        # Устанавливаем режим валидации
-----------+-        self.is_train = False
-----------+-        self.model.eval()
-----------++        # Проверяем, включен ли debug_mode (One Batch Test)
-----------++        debug_mode = getattr(self.config, 'debug_mode', False)
-----------++        
-----------++        if debug_mode:
-----------++            # В режиме отладки валидация тоже должна "обучаться" для переобучения
-----------++            print(f"🔧 Debug mode: валидация в режиме обучения для переобучения")
-----------++            self.is_train = True  # Оставляем в режиме обучения
-----------++            self.model.train()    # Модель в режиме обучения
-----------++            use_gradients = True  # Разрешаем градиенты
-----------++        else:
-----------++            # Обычный режим валидации
-----------++            self.is_train = False
-----------++            self.model.eval()
-----------++            use_gradients = False
-----------++        
-----------+         self.evaluation_metrics.reset()
-----------+         
-----------+-        with torch.no_grad():
-----------++        context_manager = torch.no_grad() if not use_gradients else torch.enable_grad()
-----------++        
-----------++        with context_manager:
-----------+             pbar = tqdm(dataloader, desc=f"Validation {part} Epoch {epoch}")
-----------+             for batch_idx, batch in enumerate(pbar):
-----------+                 try:
-----------+@@ -311,14 +332,16 @@ class BaseTrainer:
-----------+                     else:
-----------+                         raise e
-----------+ 
-----------+-        # Возвращаем режим обучения
-----------+-        self.is_train = True
-----------++        # Возвращаем режим обучения (если не debug)
-----------++        if not debug_mode:
-----------++            self.is_train = True
-----------+         self._log_scalars(self.evaluation_metrics)
-----------+         
-----------+         # Дополнительно логируем финальные метрики валидации
-----------+         if self.writer is not None:
-----------++            self.writer.set_step(epoch, "val")
-----------+             for metric_name, metric_value in self.evaluation_metrics.result().items():
-----------+-                self.writer.add_scalar(f"val_{metric_name}_epoch", metric_value, epoch)
-----------++                self.writer.add_scalar(f"val_{metric_name}_epoch", metric_value)
-----------+                 
-----------+         return self.evaluation_metrics.result()
-----------+ 
-----------+diff --git a/train.py b/train.py
-----------+index ea54b46..4060e3c 100644
-----------+--- a/train.py
-----------++++ b/train.py
-----------+@@ -35,7 +35,8 @@ def main(config):
-----------+         device = config.trainer.device
-----------+ 
-----------+     # setup data_loader instances
-----------+-    dataloaders, batch_transforms = get_dataloaders(config, device)
-----------++    debug_mode = getattr(config, 'debug_mode', False)
-----------++    dataloaders, batch_transforms = get_dataloaders(config, device, debug_mode)
-----------+ 
-----------+     # build model architecture, then print to console
-----------+     model = instantiate(config.model).to(device)
-----------diff --git a/src/configs/baseline.yaml b/src/configs/baseline.yaml
-----------index 40903a9..1947c72 100644
-------------- a/src/configs/baseline.yaml
-----------+++ b/src/configs/baseline.yaml
-----------@@ -13,5 +13,5 @@ defaults:
----------- 
----------- data_path: ${oc.env:DATA_PATH,data}
----------- project_name: anti-spoofing
------------run_name: anti-spoofing-experiment
-----------+run_name: baseline-experiment
----------- 
-----------diff --git a/src/configs/writer/cometml.yaml b/src/configs/writer/cometml.yaml
-----------index 8675b47..451af75 100644
-------------- a/src/configs/writer/cometml.yaml
-----------+++ b/src/configs/writer/cometml.yaml
-----------@@ -2,7 +2,7 @@ _target_: src.logger.cometml.CometMLWriter
----------- project_name: "anti-spoofing"
----------- workspace: null
----------- run_id: null
------------run_name: "inference-test"
-----------+run_name: "training-experiment"
----------- mode: "online"
----------- loss_names: ["loss"]
----------- log_checkpoints: False
-----------diff --git a/src/datasets/data_utils.py b/src/datasets/data_utils.py
-----------index 63e8cce..5a004ee 100644
-------------- a/src/datasets/data_utils.py
-----------+++ b/src/datasets/data_utils.py
-----------@@ -46,7 +46,7 @@ def move_batch_transforms_to_device(batch_transforms, device):
-----------                 transforms[transform_name] = transforms[transform_name].to(device)
----------- 
----------- 
------------def get_dataloaders(config, device):
-----------+def get_dataloaders(config, device, debug_mode=False):
-----------     """
-----------     Create dataloaders for each of the dataset partitions.
-----------     Also creates instance and batch transforms.
-----------@@ -54,6 +54,7 @@ def get_dataloaders(config, device):
-----------     Args:
-----------         config (DictConfig): hydra experiment config.
-----------         device (str): device to use for batch transforms.
-----------+        debug_mode (bool): if True, create minimal dataloaders for debugging.
-----------     Returns:
-----------         dataloaders (dict[DataLoader]): dict containing dataloader for a
-----------             partition defined by key.
-----------@@ -71,22 +72,51 @@ def get_dataloaders(config, device):
----------- 
-----------     # dataloaders init
-----------     dataloaders = {}
-----------+    debug_subset = None  # Сохраняем один subset для всех разделов
-----------+    
-----------     for dataset_partition in config.datasets.keys():
-----------         dataset = datasets[dataset_partition]
------------
------------        assert config.dataloader.batch_size <= len(dataset), (
------------            f"The batch size ({config.dataloader.batch_size}) cannot "
-----------+        
-----------+        # Для отладки все разделы используют одни и те же данные из train
-----------+        if debug_mode:
-----------+            from torch.utils.data import Subset
-----------+            if debug_subset is None:
-----------+                # Создаем subset только один раз из первого датасета (обычно train)
-----------+                debug_subset_indices = range(min(4, len(dataset)))
-----------+                debug_subset = Subset(dataset, debug_subset_indices)
-----------+                print(f"🔧 Debug mode: используем {len(debug_subset)} образцов для всех разделов")
-----------+            dataset = debug_subset
-----------+
-----------+        # Для отладки изменяем параметры даталоадера
-----------+        if debug_mode:
-----------+            batch_size = min(2, len(dataset))
-----------+            num_workers = 0
-----------+            pin_memory = False
-----------+        else:
-----------+            batch_size = config.dataloader.batch_size
-----------+            num_workers = getattr(config.dataloader, 'num_workers', 4)
-----------+            pin_memory = getattr(config.dataloader, 'pin_memory', True)
-----------+
-----------+        assert batch_size <= len(dataset), (
-----------+            f"The batch size ({batch_size}) cannot "
-----------             f"be larger than the dataset length ({len(dataset)})"
-----------         )
----------- 
-----------         partition_dataloader = instantiate(
-----------             config.dataloader,
-----------             dataset=dataset,
-----------+            batch_size=batch_size,
-----------+            num_workers=num_workers,
-----------+            pin_memory=pin_memory,
-----------             collate_fn=collate_fn,
------------            drop_last=(dataset_partition == "train"),
------------            shuffle=(dataset_partition == "train"),
-----------+            drop_last=False,  # В debug режиме не отбрасываем данные
-----------+            shuffle=False,    # В debug режиме не перемешиваем для воспроизводимости
-----------             worker_init_fn=set_worker_seed,
-----------         )
-----------+        
-----------         dataloaders[dataset_partition] = partition_dataloader
-----------+        
-----------+        if debug_mode:
-----------+            print(f"📁 {dataset_partition}: {len(dataset)} образцов, batch_size={batch_size}")
----------- 
-----------     return dataloaders, batch_transforms
-----------\ No newline at end of file
-----------diff --git a/src/datasets/mydataset.py b/src/datasets/mydataset.py
-----------index 94e7e12..e5d6aa7 100644
-------------- a/src/datasets/mydataset.py
-----------+++ b/src/datasets/mydataset.py
-----------@@ -15,7 +15,7 @@ class AudioSpoofingDataset(BaseDataset):
----------- 
-----------     def __init__(
-----------         self, name="train", label_path=None, audio_path=None, out_path=None, 
------------        instance_transforms=None, *args, **kwargs
-----------+        instance_transforms=None, max_samples=None, *args, **kwargs
-----------     ):
-----------         """
-----------         Args:
-----------@@ -24,11 +24,13 @@ class AudioSpoofingDataset(BaseDataset):
-----------             audio_path (str): path to the directory with .flac files
-----------             out_path (str): where to save index.json
-----------             instance_transforms (dict): transforms to apply to instances
-----------+            max_samples (int): maximum number of samples for debugging (None for all)
-----------         """
-----------         self.name = name
-----------         self.label_path = label_path
-----------         self.audio_path = audio_path
-----------         self.out_path = out_path
-----------+        self.max_samples = max_samples
-----------         
-----------         # Create index if it doesn't exist
-----------         if Path(out_path).exists():
-----------@@ -36,6 +38,10 @@ class AudioSpoofingDataset(BaseDataset):
-----------         else:
-----------             index = self._create_index(label_path, audio_path, out_path)
----------- 
-----------+        # Ограничиваем размер датасета для отладки
-----------+        if max_samples is not None:
-----------+            index = index[:max_samples]
-----------+
-----------         super().__init__(index, instance_transforms=instance_transforms, *args, **kwargs)
----------- 
-----------     def __getitem__(self, idx):
-----------diff --git a/src/logger/utils.py b/src/logger/utils.py
-----------index c465f41..2795052 100644
-------------- a/src/logger/utils.py
-----------+++ b/src/logger/utils.py
-----------@@ -4,7 +4,7 @@ import matplotlib.pyplot as plt
----------- import PIL
----------- from torchvision.transforms import ToTensor
----------- 
------------plt.switch_backend("agg")  # fix RuntimeError: main thread is not in main loop
-----------+plt.switch_backend("agg")
----------- 
----------- 
----------- def plot_images(imgs, config):
-----------diff --git a/src/trainer/base_trainer.py b/src/trainer/base_trainer.py
-----------index de03b18..c827e0b 100644
-------------- a/src/trainer/base_trainer.py
-----------+++ b/src/trainer/base_trainer.py
-----------@@ -170,16 +170,17 @@ class BaseTrainer:
-----------                 val_part_logs = self._evaluation_epoch(epoch, "val", dataloader)
-----------                 val_logs.update(val_part_logs)
-----------                 
------------                # Дополнительно логируем финальные метрики валидации в конце эпохи
------------                if self.writer is not None:
------------                    for metric_name, metric_value in val_logs.items():
------------                        self.writer.add_scalar(f"val_{metric_name}_final", metric_value, epoch)
------------                
-----------                 # Выводим финальные метрики валидации в консоль
------------                print(f"    Финальная валидация эпохи {epoch}:")
-----------+                print(f"\n📊 Финальные метрики валидации эпохи {epoch}:")
-----------                 for metric_name, metric_value in val_logs.items():
------------                    print(f"        {metric_name}: {metric_value:.6f}")
-----------+                    print(f"    val_{metric_name}: {metric_value:.6f}")
-----------                 print()
-----------+                
-----------+                # Дополнительно логируем финальные метрики валидации в конце эпохи
-----------+                if self.writer is not None:
-----------+                    self.writer.set_step(epoch, "val")
-----------+                    for metric_name, metric_value in val_logs.items():
-----------+                        self.writer.add_scalar(f"val_{metric_name}_epoch", metric_value)
----------- 
-----------                 # log best so far
-----------                 if self.mnt_mode != "off":
-----------@@ -215,24 +216,34 @@ class BaseTrainer:
-----------                 batch = self.process_batch(batch, self.train_metrics)
-----------                 self._log_batch(batch_idx, batch, "train")
-----------                 
------------                # Выводим лосс в консоль каждые 50 батчей
------------                if batch_idx % 50 == 0:
-----------+                # Выводим лосс в консоль каждые log_step батчей
-----------+                if batch_idx % self.log_step == 0:
-----------                     loss_key = self.config.writer.loss_names[0]
-----------                     current_loss = self.train_metrics.avg(loss_key)
------------                    print(f"[Batch {batch_idx}] Loss: {current_loss:.6f}")
-----------+                    current_eer = self.train_metrics.avg("eer") if self.train_metrics._eer_scores else 0.0
-----------                     
------------                    # Логируем train_loss в CometML каждые 50 батчей
-----------+                    print(f"[Epoch {epoch}, Batch {batch_idx}] Loss: {current_loss:.6f}, EER: {current_eer:.6f}")
-----------+                    
-----------+                    # Логируем метрики в CometML каждые log_step батчей
-----------                     if self.writer is not None:
------------                        self.writer.add_scalar("train_loss_batch", current_loss, batch_idx)
-----------+                        # Вычисляем общий шаг как epoch * num_batches + batch_idx
-----------+                        global_step = (epoch - 1) * len(self.train_dataloader) + batch_idx
-----------+                        self.writer.set_step(global_step, "train")
-----------+                        self.writer.add_scalar("train_loss_batch", current_loss)
-----------+                        if self.train_metrics._eer_scores:
-----------+                            self.writer.add_scalar("train_eer_batch", current_eer)
-----------                 
-----------                 # Валидация в середине эпохи (если val_period = 1)
-----------                 if batch_idx == mid_epoch_batch and "val" in self.evaluation_dataloaders:
-----------                     # Сохраняем текущий режим
-----------                     was_training = self.is_train
-----------+                    was_model_training = self.model.training
-----------                     
------------                    # Устанавливаем режим валидации
------------                    self.is_train = False
------------                    self.model.eval()
-----------+                    # В debug режиме пропускаем валидацию в середине эпохи для упрощения
-----------+                    debug_mode = getattr(self.config, 'debug_mode', False)
-----------+                    if debug_mode:
-----------+                        print("🔧 Debug mode: пропускаем валидацию в середине эпохи")
-----------+                        continue
-----------                     
-----------                     # Создаем временный MetricTracker для валидации в середине эпохи
-----------                     mid_epoch_metrics = MetricTracker(
-----------@@ -251,8 +262,9 @@ class BaseTrainer:
-----------                     
-----------                     # Дополнительно логируем валидационные метрики в середине эпохи
-----------                     if self.writer is not None:
-----------+                        self.writer.set_step(batch_idx, "val")
-----------                         for metric_name, metric_value in val_logs.items():
------------                            self.writer.add_scalar(f"val_{metric_name}_mid_epoch", metric_value, batch_idx)
-----------+                            self.writer.add_scalar(f"val_{metric_name}_mid_epoch", metric_value)
-----------                     
-----------                     # Выводим метрики валидации в консоль
-----------                     print(f"    Валидация в середине эпохи {epoch}:")
-----------@@ -261,8 +273,8 @@ class BaseTrainer:
-----------                     print()
-----------                     
-----------                     # Возвращаем режим обучения
------------                    self.is_train = True
------------                    self.model.train()
-----------+                    self.is_train = was_training
-----------+                    self.model.train(was_model_training)
-----------                     
-----------             except RuntimeError as e:
-----------                 if "out of memory" in str(e) and self.skip_oom:
-----------@@ -275,9 +287,15 @@ class BaseTrainer:
-----------         self._log_scalars(self.train_metrics)
-----------         
-----------         # Дополнительно логируем финальные метрики тренировки
-----------+        train_results = self.train_metrics.result()
-----------+        print(f"\n📊 Финальные метрики тренировки эпохи {epoch}:")
-----------+        for metric_name, metric_value in train_results.items():
-----------+            print(f"    train_{metric_name}: {metric_value:.6f}")
-----------+        
-----------         if self.writer is not None:
------------            for metric_name, metric_value in self.train_metrics.result().items():
------------                self.writer.add_scalar(f"train_{metric_name}_epoch", metric_value, epoch)
-----------+            self.writer.set_step(epoch, "train")
-----------+            for metric_name, metric_value in train_results.items():
-----------+                self.writer.add_scalar(f"train_{metric_name}_epoch", metric_value)
----------- 
-----------     def _evaluation_epoch(self, epoch, part, dataloader):
-----------         """
-----------@@ -291,12 +309,26 @@ class BaseTrainer:
-----------         Returns:
-----------             dict: Dictionary with validation logs.
-----------         """
------------        # Устанавливаем режим валидации
------------        self.is_train = False
------------        self.model.eval()
-----------+        # Проверяем, включен ли debug_mode (One Batch Test)
-----------+        debug_mode = getattr(self.config, 'debug_mode', False)
-----------+        
-----------+        if debug_mode:
-----------+            # В режиме отладки валидация тоже должна "обучаться" для переобучения
-----------+            print(f"🔧 Debug mode: валидация в режиме обучения для переобучения")
-----------+            self.is_train = True  # Оставляем в режиме обучения
-----------+            self.model.train()    # Модель в режиме обучения
-----------+            use_gradients = True  # Разрешаем градиенты
-----------+        else:
-----------+            # Обычный режим валидации
-----------+            self.is_train = False
-----------+            self.model.eval()
-----------+            use_gradients = False
-----------+        
-----------         self.evaluation_metrics.reset()
-----------         
------------        with torch.no_grad():
-----------+        context_manager = torch.no_grad() if not use_gradients else torch.enable_grad()
-----------+        
-----------+        with context_manager:
-----------             pbar = tqdm(dataloader, desc=f"Validation {part} Epoch {epoch}")
-----------             for batch_idx, batch in enumerate(pbar):
-----------                 try:
-----------@@ -311,14 +343,12 @@ class BaseTrainer:
-----------                     else:
-----------                         raise e
----------- 
------------        # Возвращаем режим обучения
------------        self.is_train = True
------------        self._log_scalars(self.evaluation_metrics)
-----------+        # Возвращаем режим обучения (если не debug)
-----------+        if not debug_mode:
-----------+            self.is_train = True
-----------         
------------        # Дополнительно логируем финальные метрики валидации
------------        if self.writer is not None:
------------            for metric_name, metric_value in self.evaluation_metrics.result().items():
------------                self.writer.add_scalar(f"val_{metric_name}_epoch", metric_value, epoch)
-----------+        # Логируем метрики валидации (основной способ)
-----------+        self._log_scalars(self.evaluation_metrics)
-----------                 
-----------         return self.evaluation_metrics.result()
----------- 
-----------@@ -449,6 +479,9 @@ class BaseTrainer:
-----------         Args:
-----------             metric_tracker (MetricTracker): Metric tracker.
-----------         """
-----------+        if self.writer is None:
-----------+            return
-----------+            
-----------         for metric_name, metric_value in metric_tracker.result().items():
-----------             # Добавляем префикс в зависимости от типа метрик
-----------             if metric_tracker == self.train_metrics:
-----------diff --git a/src/trainer/inferencer.py b/src/trainer/inferencer.py
-----------index 06185a3..2dc68a0 100644
-------------- a/src/trainer/inferencer.py
-----------+++ b/src/trainer/inferencer.py
-----------@@ -60,14 +60,14 @@ class Inferencer(BaseTrainer):
-----------         self.model = model
-----------         self.batch_transforms = batch_transforms
----------- 
------------        # define dataloaders
-----------+       
-----------         self.evaluation_dataloaders = {k: v for k, v in dataloaders.items()}
----------- 
------------        # path definition
-----------+      
----------- 
-----------         self.save_path = save_path
----------- 
------------        # define metrics
-----------+      
-----------         self.metrics = metrics
-----------         self.writer = writer
-----------         if self.metrics is not None:
-----------@@ -79,7 +79,7 @@ class Inferencer(BaseTrainer):
-----------             self.evaluation_metrics = None
----------- 
-----------         if not skip_model_load:
------------            # init model
-----------+           
-----------             self._from_pretrained(config.inferencer.get("from_pretrained"))
----------- 
-----------     def run_inference(self):
-----------@@ -128,15 +128,13 @@ class Inferencer(BaseTrainer):
-----------             for met in self.metrics["inference"]:
-----------                 metrics.update(met.name, met(**batch))
----------- 
------------        # Some saving logic. This is an example
------------        # Use if you need to save predictions on disk
-----------+    
----------- 
-----------         batch_size = batch["logits"].shape[0]
-----------         current_id = batch_idx * batch_size
----------- 
-----------         for i in range(batch_size):
------------            # clone because of
------------            # https://github.com/pytorch/pytorch/issues/1995
-----------+         
-----------             logits = batch["logits"][i].clone()
-----------             label = batch["labels"][i].clone()
-----------             pred_label = logits.argmax(dim=-1)
-----------@@ -149,7 +147,7 @@ class Inferencer(BaseTrainer):
-----------             }
----------- 
-----------             if self.save_path is not None:
------------                # you can use safetensors or other lib here
-----------+             
-----------                 torch.save(output, self.save_path / part / f"output_{output_id}.pth")
----------- 
-----------         return batch
-----------@@ -189,7 +187,7 @@ class Inferencer(BaseTrainer):
----------- 
-----------         results = self.evaluation_metrics.result()
-----------         
------------        # Логируем финальные метрики в CometML
-----------+      
-----------         if self.writer is not None:
-----------             for metric_name, metric_value in results.items():
-----------                 self.writer.add_scalar(f"inference_{part}_{metric_name}", metric_value, 0)
-----------diff --git a/train.py b/train.py
-----------index ea54b46..57b9354 100644
-------------- a/train.py
-----------+++ b/train.py
-----------@@ -35,7 +35,8 @@ def main(config):
-----------         device = config.trainer.device
----------- 
-----------     # setup data_loader instances
------------    dataloaders, batch_transforms = get_dataloaders(config, device)
-----------+    debug_mode = getattr(config, 'debug_mode', False)
-----------+    dataloaders, batch_transforms = get_dataloaders(config, device, debug_mode)
----------- 
-----------     # build model architecture, then print to console
-----------     model = instantiate(config.model).to(device)
-----------@@ -44,7 +45,23 @@ def main(config):
-----------     total_params = sum(p.numel() for p in model.parameters())
-----------     trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
-----------     
-----------+    print(f"\n📊 Информация о модели:")
-----------+    print(f"🔢 Общее количество параметров: {total_params:,}")
-----------+    print(f"🎯 Обучаемых параметров: {trainable_params:,}")
-----------+    print(f"📁 Размеры датасетов:")
-----------+    for partition, dataloader in dataloaders.items():
-----------+        print(f"    {partition}: {len(dataloader.dataset)} образцов, batch_size={dataloader.batch_size}")
-----------+    print()
-----------+    
-----------     logger.info(model)
-----------+    
-----------+    # Логируем параметры модели в CometML
-----------+    if writer is not None:
-----------+        writer.exp.log_parameters({
-----------+            "total_params": total_params,
-----------+            "trainable_params": trainable_params,
-----------+            "model_name": config.model._target_.split('.')[-1],
-----------+        })
----------- 
-----------     # get function handles of loss and metrics
-----------     loss_function = instantiate(config.loss_function).to(device)
---------diff --git a/one_batch_test.py b/one_batch_test.py
---------deleted file mode 100644
---------index 4fe3755..0000000
------------ a/one_batch_test.py
---------+++ /dev/null
---------@@ -1,123 +0,0 @@
----------import warnings
----------import hydra
----------import torch
----------from hydra.utils import instantiate
----------from omegaconf import OmegaConf
----------
----------from src.datasets.data_utils import get_dataloaders
----------from src.trainer import Trainer
----------from src.utils.init_utils import set_random_seed, setup_saving_and_logging
----------
----------warnings.filterwarnings("ignore", category=UserWarning)
----------
----------@hydra.main(version_base=None, config_path="src/configs", config_name="baseline")
----------def main(config):
----------    """
----------    One Batch Test script. Tests if the model can overfit on a small batch.
----------    This is useful for debugging the training pipeline.
----------    """
----------    print("🔍 Запуск One Batch Test...")
----------    print("📊 Ожидаем переобучение на маленьком датасете")
----------    
----------    # Устанавливаем seed для воспроизводимости
----------    set_random_seed(config.trainer.seed)
----------    
----------    # Добавляем debug_mode в конфигурацию
----------    OmegaConf.set_struct(config, False)
----------    config.debug_mode = True
----------    # Увеличиваем количество эпох для переобучения
----------    config.trainer.n_epochs = 100
----------    # Чаще логируем
----------    config.trainer.log_step = 1
----------    # Отключаем early stopping
----------    config.trainer.early_stop = 200
----------    OmegaConf.set_struct(config, True)
----------    
----------    # Настройка логирования
----------    project_config = OmegaConf.to_container(config)
----------    logger = setup_saving_and_logging(config)
----------    writer = instantiate(config.writer, logger, project_config)
----------    
----------    # Определяем устройство
----------    if config.trainer.device == "auto":
----------        device = "cuda" if torch.cuda.is_available() else "cpu"
----------    else:
----------        device = config.trainer.device
----------    
----------    print(f"🖥️  Используем устройство: {device}")
----------    
----------    # Создаем мини-даталоадеры (debug_mode=True)
----------    dataloaders, batch_transforms = get_dataloaders(config, device, debug_mode=True)
----------    
----------    # Проверяем, что все разделы используют одни и те же данные
----------    print("\n📊 Проверка данных в One Batch Test:")
----------    train_batch = next(iter(dataloaders["train"]))
----------    val_batch = next(iter(dataloaders["val"]))
----------    
----------    print(f"📝 Train batch shape: {train_batch['data_object'].shape}")
----------    print(f"📝 Val batch shape: {val_batch['data_object'].shape}")
----------    print(f"📝 Train labels: {train_batch['labels']}")
----------    print(f"📝 Val labels: {val_batch['labels']}")
----------    
----------    # Проверяем, идентичны ли данные
----------    data_identical = torch.equal(train_batch['data_object'], val_batch['data_object'])
----------    labels_identical = torch.equal(train_batch['labels'], val_batch['labels'])
----------    
----------    print(f"✅ Данные идентичны: {data_identical}")
----------    print(f"✅ Метки идентичны: {labels_identical}")
----------    
----------    if not (data_identical and labels_identical):
----------        print("⚠️  ВНИМАНИЕ: Данные train и val не идентичны!")
----------    else:
----------        print("🎯 Отлично: Train и Val используют одинаковые данные")
----------    
----------    # Создаем модель
----------    model = instantiate(config.model).to(device)
----------    
----------    # Подсчет параметров
----------    total_params = sum(p.numel() for p in model.parameters())
----------    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
----------    print(f"🔢 Общее количество параметров: {total_params:,}")
----------    print(f"🎯 Обучаемых параметров: {trainable_params:,}")
----------    
----------    # Создаем функцию потерь и метрики
----------    loss_function = instantiate(config.loss_function).to(device)
----------    metrics = instantiate(config.metrics)
----------    
----------    # Создаем оптимизатор и планировщик
----------    trainable_params_iter = filter(lambda p: p.requires_grad, model.parameters())
----------    optimizer = instantiate(config.optimizer, params=trainable_params_iter)
----------    lr_scheduler = instantiate(config.lr_scheduler, optimizer=optimizer)
----------    
----------    # Создаем тренер
----------    trainer = Trainer(
----------        model=model,
----------        criterion=loss_function,
----------        metrics=metrics,
----------        optimizer=optimizer,
----------        lr_scheduler=lr_scheduler,
----------        config=config,
----------        device=device,
----------        dataloaders=dataloaders,
----------        epoch_len=None,
----------        logger=logger,
----------        writer=writer,
----------        batch_transforms=batch_transforms,
----------        skip_oom=config.trainer.get("skip_oom", True),
----------    )
----------    
----------    print("🚀 Начинаем One Batch Test...")
----------    print("📈 Ожидаемое поведение:")
----------    print("   - Loss должен монотонно уменьшаться")
----------    print("   - Через 50-100 эпох loss должен быть < 0.01")
----------    print("   - Accuracy должна стремиться к 100%")
----------    print("   - EER должна стремиться к 0%")
----------    print("-" * 50)
----------    
----------    # Запускаем обучение
----------    trainer.train()
----------    
----------    print("✅ One Batch Test завершен!")
----------
----------if __name__ == "__main__":
----------    main() 
---------\ No newline at end of file
---------diff --git a/src/model/model.py b/src/model/model.py
---------index 6ec39da..181862d 100644
------------ a/src/model/model.py
---------+++ b/src/model/model.py
---------@@ -56,6 +56,25 @@ class LCNN(nn.Module):
---------             nn.Dropout(0.5),
---------             nn.Linear(256, num_classes)
---------         )
---------+        
---------+        # ДОБАВЛЯЕМ ПРАВИЛЬНУЮ ИНИЦИАЛИЗАЦИЮ ВЕСОВ
---------+        self._init_weights()
---------+
---------+    def _init_weights(self):
---------+        """Инициализация весов модели"""
---------+        print("🔧 Инициализирую веса модели...")
---------+        for m in self.modules():
---------+            if isinstance(m, nn.Conv2d):
---------+                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
---------+                if m.bias is not None:
---------+                    nn.init.constant_(m.bias, 0)
---------+            elif isinstance(m, nn.BatchNorm2d):
---------+                nn.init.constant_(m.weight, 1)
---------+                nn.init.constant_(m.bias, 0)
---------+            elif isinstance(m, nn.Linear):
---------+                nn.init.normal_(m.weight, 0, 0.01)
---------+                nn.init.constant_(m.bias, 0)
---------+        print("✅ Веса инициализированы")
--------- 
---------     def forward(self, **batch) -> Dict[str, torch.Tensor]:
---------         """
---------diff --git a/src/trainer/base_trainer_fixed.py b/src/trainer/base_trainer_fixed.py
---------deleted file mode 100644
---------index 0519ecb..0000000
------------ a/src/trainer/base_trainer_fixed.py
---------+++ /dev/null
---------@@ -1 +0,0 @@
---------- 
---------\ No newline at end of file
---------diff --git a/src/trainer/trainer.py b/src/trainer/trainer.py
---------index b5c2173..bacd019 100644
------------ a/src/trainer/trainer.py
---------+++ b/src/trainer/trainer.py
---------@@ -55,8 +55,38 @@ class Trainer(BaseTrainer):
--------- 
---------         # Обновляем EER метрику
---------         if "logits" in batch:
----------            scores = torch.softmax(batch["logits"], dim=1)[:, 1]
---------+            logits = batch["logits"]
---------             labels = batch["labels"]
---------+            
---------+            # Подробная диагностика логитов
---------+            if not self.is_train:  # Валидация
---------+                print(f"🔍 ЛОГИТЫ - shape: {logits.shape}")
---------+                print(f"🔍 ЛОГИТЫ - min: {logits.min().item():.6f}, max: {logits.max().item():.6f}")
---------+                print(f"🔍 ЛОГИТЫ - mean: {logits.mean().item():.6f}, std: {logits.std().item():.6f}")
---------+                print(f"🔍 ЛОГИТЫ первые 5: {logits[:5].detach().cpu().numpy()}")
---------+                
---------+            scores = torch.softmax(logits, dim=1)[:, 1]
---------+            
---------+            # Диагностика для валидации
---------+            if not self.is_train:  # Это валидация
---------+                unique_labels = torch.unique(labels)
---------+                score_stats = {
---------+                    'min': scores.min().item(),
---------+                    'max': scores.max().item(), 
---------+                    'mean': scores.mean().item(),
---------+                    'std': scores.std().item()
---------+                }
---------+                print(f"🔍 VAL ДИАГНОСТИКА - Labels: {unique_labels.tolist()}")
---------+                print(f"🔍 SCORES - min={score_stats['min']:.6f}, max={score_stats['max']:.6f}")
---------+                print(f"🔍 SCORES - mean={score_stats['mean']:.6f}, std={score_stats['std']:.6f}")
---------+                print(f"🔍 SCORES первые 10: {scores[:10].detach().cpu().numpy()}")
---------+                print(f"🔍 LABELS первые 10: {labels[:10].detach().cpu().numpy()}")
---------+                
---------+                # Проверяем распределение классов
---------+                class_0_count = (labels == 0).sum().item()
---------+                class_1_count = (labels == 1).sum().item()
---------+                print(f"🔍 РАСПРЕДЕЛЕНИЕ - класс 0: {class_0_count}, класс 1: {class_1_count}")
---------+            
---------             metrics.update_eer(scores, labels)
--------- 
---------         # Обновляем остальные метрики
---------diff --git a/src/trainer/trainer_fixed.py b/src/trainer/trainer_fixed.py
---------deleted file mode 100644
---------index 2010b3b..0000000
------------ a/src/trainer/trainer_fixed.py
---------+++ /dev/null
---------@@ -1,112 +0,0 @@
----------from src.metrics.tracker import MetricTracker
----------from src.trainer.base_trainer import BaseTrainer
----------import torch
----------
----------class Trainer(BaseTrainer):
----------    """
----------    ИСПРАВЛЕННАЯ версия Trainer class.
----------    """
----------
----------    def process_batch(self, batch, metrics: MetricTracker):
----------        """
----------        Обработка батча с исправлениями.
----------        """
----------        # Перемещаем данные на устройство
----------        batch = self.move_batch_to_device(batch)
----------        batch = self.transform_batch(batch)
----------
----------        # Определяем метрики в зависимости от режима
----------        metric_funcs = self.metrics["inference"]
----------        if self.is_train:
----------            metric_funcs = self.metrics["train"]
----------            self.optimizer.zero_grad()
----------
----------        # Forward pass через модель
----------        outputs = self.model(**batch)
----------        batch.update(outputs)
----------
----------        # Вычисляем loss
----------        all_losses = self.criterion(**batch)
----------        batch.update(all_losses)
----------
----------        # ОБУЧЕНИЕ ТОЛЬКО В ТРЕНИРОВОЧНОМ РЕЖИМЕ
----------        if self.is_train:
----------            # Проверяем, что loss корректный
----------            if torch.isnan(batch["loss"]) or torch.isinf(batch["loss"]):
----------                print(f"⚠️ WARNING: Некорректный loss обнаружен: {batch['loss'].item()}")
----------                return batch
----------            
----------            # Backward pass
----------            batch["loss"].backward()
----------            
----------            # ОТКЛЮЧЕН GRADIENT CLIPPING
----------            # self._clip_grad_norm()  # ← ОТКЛЮЧЕНО
----------            
----------            # Проверяем градиенты
----------            grad_norm = self._get_grad_norm()
----------            if torch.isnan(grad_norm) or torch.isinf(grad_norm):
----------                print(f"⚠️ WARNING: Некорректные градиенты: {grad_norm}")
----------                return batch
----------            
----------            # Обновляем параметры
----------            self.optimizer.step()
----------            
----------            # LR SCHEDULER ВЫЗЫВАЕТСЯ В КОНЦЕ ЭПОХИ, НЕ ЗДЕСЬ!
----------            # if self.lr_scheduler is not None:
----------            #     self.lr_scheduler.step()  # ← УБРАНО! Это была главная ошибка!
----------
----------        # Обновляем loss метрики
----------        for loss_name in self.config.writer.loss_names:
----------            if loss_name in batch:
----------                loss_value = batch[loss_name].item()
----------                if not (torch.isnan(torch.tensor(loss_value)) or torch.isinf(torch.tensor(loss_value))):
----------                    metrics.update(loss_name, loss_value)
----------
----------        # Обновляем EER метрику
----------        if "logits" in batch:
----------            try:
----------                logits = batch["logits"]
----------                labels = batch["labels"]
----------                
----------                # Проверяем корректность logits
----------                if torch.isnan(logits).any() or torch.isinf(logits).any():
----------                    print(f"⚠️ WARNING: Некорректные logits")
----------                else:
----------                    scores = torch.softmax(logits, dim=1)[:, 1]
----------                    metrics.update_eer(scores, labels)
----------            except Exception as e:
----------                print(f"⚠️ WARNING: Ошибка при вычислении EER: {e}")
----------
----------        # Обновляем остальные метрики
----------        for met in metric_funcs:
----------            if met.name != "eer":
----------                try:
----------                    metric_value = met(**batch)
----------                    if not (torch.isnan(torch.tensor(metric_value)) or torch.isinf(torch.tensor(metric_value))):
----------                        metrics.update(met.name, metric_value)
----------                except Exception as e:
----------                    continue
----------
----------        return batch
----------
----------    def _log_batch(self, batch_idx, batch, mode="train"):
----------        """
----------        Логирование батча с дополнительными проверками.
----------        """
----------        if self.writer is not None:
----------            # Логируем learning rate
----------            if mode == "train" and self.lr_scheduler is not None:
----------                try:
----------                    current_lr = self.lr_scheduler.get_last_lr()[0]
----------                    self.writer.add_scalar("learning_rate", current_lr)
----------                except:
----------                    pass
----------            
----------            # Логируем градиентную норму
----------            if mode == "train":
----------                try:
----------                    grad_norm = self._get_grad_norm()
----------                    if not (torch.isnan(grad_norm) or torch.isinf(grad_norm)):
----------                        self.writer.add_scalar("grad_norm", grad_norm.item())
----------                except:
----------                    pass 
---------\ No newline at end of file
---------diff --git a/test_fixes.py b/test_fixes.py
---------deleted file mode 100644
---------index bd158bd..0000000
------------ a/test_fixes.py
---------+++ /dev/null
---------@@ -1,122 +0,0 @@
----------"""
----------Тестовый скрипт для проверки исправлений в коде.
----------"""
----------import warnings
----------import hydra
----------import torch
----------from hydra.utils import instantiate
----------from omegaconf import OmegaConf
----------
----------from src.datasets.data_utils import get_dataloaders
----------from src.utils.init_utils import set_random_seed, setup_saving_and_logging
----------
----------warnings.filterwarnings("ignore", category=UserWarning)
----------
----------# Используем исправленный тренер
----------from src.trainer.trainer_fixed import Trainer
----------
----------@hydra.main(version_base=None, config_path="src/configs", config_name="baseline")
----------def main(config):
----------    """
----------    Тест исправлений:
----------    1. LR scheduler вызывается в конце эпохи
----------    2. Gradient clipping отключен
----------    3. Добавлены проверки на NaN/Inf
----------    4. Улучшенное логирование
----------    """
----------    print("🔧 Тестируем исправления...")
----------    
----------    # Устанавливаем seed
----------    set_random_seed(config.trainer.seed)
----------    
----------    # Модифицируем конфигурацию для теста
----------    OmegaConf.set_struct(config, False)
----------    config.trainer.n_epochs = 3  # Только 3 эпохи для теста
----------    config.trainer.log_step = 10  # Чаще логируем
----------    config.optimizer.lr = 0.001  # Безопасный LR
----------    config.writer.run_name = "fixes-test"
----------    OmegaConf.set_struct(config, True)
----------    
----------    # Настройка логирования
----------    project_config = OmegaConf.to_container(config)
----------    logger = setup_saving_and_logging(config)
----------    writer = instantiate(config.writer, logger, project_config)
----------    
----------    # Определяем устройство
----------    device = "cuda" if torch.cuda.is_available() else "cpu"
----------    print(f"🖥️  Устройство: {device}")
----------    
----------    # Создаем даталоадеры
----------    dataloaders, batch_transforms = get_dataloaders(config, device, debug_mode=False)
----------    
----------    # Создаем модель
----------    model = instantiate(config.model).to(device)
----------    print(f"🔢 Параметров в модели: {sum(p.numel() for p in model.parameters()):,}")
----------    
----------    # Создаем компоненты
----------    loss_function = instantiate(config.loss_function).to(device)
----------    metrics = instantiate(config.metrics)
----------    
----------    # Создаем оптимизатор и планировщик
----------    trainable_params = filter(lambda p: p.requires_grad, model.parameters())
----------    optimizer = instantiate(config.optimizer, params=trainable_params)
----------    lr_scheduler = instantiate(config.lr_scheduler, optimizer=optimizer)
----------    
----------    print(f"📉 Начальный LR: {lr_scheduler.get_last_lr()[0]}")
----------    print(f"📅 LR scheduler: уменьшение каждые {config.lr_scheduler.step_size} эпох на {config.lr_scheduler.gamma}")
----------    
----------    # Создаем ИСПРАВЛЕННЫЙ тренер
----------    trainer = Trainer(
----------        model=model,
----------        criterion=loss_function,
----------        metrics=metrics,
----------        optimizer=optimizer,
----------        lr_scheduler=lr_scheduler,
----------        config=config,
----------        device=device,
----------        dataloaders=dataloaders,
----------        epoch_len=None,
----------        logger=logger,
----------        writer=writer,
----------        batch_transforms=batch_transforms,
----------        skip_oom=True,
----------    )
----------    
----------    print("\n🚀 Запускаем тест с исправлениями...")
----------    print("🔧 Исправления:")
----------    print("   ✅ LR scheduler перенесен в конец эпохи")
----------    print("   ✅ Gradient clipping отключен")
----------    print("   ✅ Добавлены проверки на NaN/Inf")
----------    print("   ✅ Улучшенное логирование")
----------    print("-" * 50)
----------    
----------    # Тестируем один батч для проверки
----------    print("\n🧪 Тест одного батча:")
----------    train_dataloader = dataloaders["train"]
----------    batch = next(iter(train_dataloader))
----------    
----------    # Проверяем размеры данных
----------    print(f"📊 Размер батча: {batch['data_object'].shape}")
----------    print(f"📊 Метки: {batch['labels'].shape}, уникальные: {torch.unique(batch['labels'])}")
----------    
----------    # Тестируем forward pass
----------    model.eval()
----------    with torch.no_grad():
----------        batch = trainer.move_batch_to_device(batch)
----------        batch = trainer.transform_batch(batch)
----------        outputs = model(**batch)
----------        loss_dict = loss_function(**{**batch, **outputs})
----------        
----------        print(f"📊 Logits shape: {outputs['logits'].shape}")
----------        print(f"📊 Loss: {loss_dict['loss'].item():.6f}")
----------        print(f"📊 Logits range: [{outputs['logits'].min().item():.4f}, {outputs['logits'].max().item():.4f}]")
----------    
----------    print("\n✅ Тест одного батча прошел успешно!")
----------    
----------    # Запускаем полное обучение
----------    trainer.train()
----------    
----------    print("\n✅ Тест исправлений завершен!")
----------
----------if __name__ == "__main__":
----------    main() 
---------\ No newline at end of file
-------diff --git a/src/transforms/normalize.py b/src/transforms/normalize.py
-------index 38aa0d3..9e03473 100644
---------- a/src/transforms/normalize.py
-------+++ b/src/transforms/normalize.py
-------@@ -8,15 +8,15 @@ class Normalize(nn.Module):
------- 
-------     def __init__(self, mean, std):
-------         super().__init__()
--------        self.mean = torch.tensor(mean).view(1, -1, 1, 1)
--------        self.std = torch.tensor(std).view(1, -1, 1, 1)
-------+        self.mean = torch.tensor(mean)
-------+        self.std = torch.tensor(std)
------- 
-------     def forward(self, x):
-------         """
-------         Применяет нормализацию.
-------         
-------         Args:
--------            x (torch.Tensor): входной тензор [batch_size, channels, height, width]
-------+            x (torch.Tensor): входной тензор любой размерности
-------             
-------         Returns:
-------             torch.Tensor: нормализованный тензор
-------@@ -25,4 +25,15 @@ class Normalize(nn.Module):
-------         mean = self.mean.to(device)
-------         std = self.std.to(device)
-------         
-------+        # Адаптируем размерности mean и std под входной тензор
-------+        if x.dim() == 4:  # [batch, channels, height, width]
-------+            mean = mean.view(1, -1, 1, 1)
-------+            std = std.view(1, -1, 1, 1)
-------+        elif x.dim() == 3:  # [batch, freq, time] - наш случай после STFT
-------+            mean = mean.view(1, 1, 1) if len(mean) == 1 else mean.view(1, -1, 1)
-------+            std = std.view(1, 1, 1) if len(std) == 1 else std.view(1, -1, 1)
-------+        elif x.dim() == 2:  # [batch, features]
-------+            mean = mean.view(1, -1)
-------+            std = std.view(1, -1)
-------+        
-------         return (x - mean) / std
-------\ No newline at end of file
------diff --git a/src/trainer/base_trainer.py b/src/trainer/base_trainer.py
------index ff77b50..e27829d 100644
--------- a/src/trainer/base_trainer.py
------+++ b/src/trainer/base_trainer.py
------@@ -496,13 +496,14 @@ class BaseTrainer:
------                 the dataloader (possibly transformed via batch transform).
------         """
------         # do batch transforms on device
-------        transform_type = "train" if self.is_train else "inference"
-------        transforms = self.batch_transforms.get(transform_type)
-------        if transforms is not None:
-------            for transform_name in transforms.keys():
-------                batch[transform_name] = transforms[transform_name](
-------                    batch[transform_name]
-------                )
------+        if self.batch_transforms is not None:
------+            transform_type = "train" if self.is_train else "inference"
------+            transforms = self.batch_transforms.get(transform_type)
------+            if transforms is not None:
------+                for transform_name in transforms.keys():
------+                    batch[transform_name] = transforms[transform_name](
------+                        batch[transform_name]
------+                    )
------         return batch
------ 
------     def _clip_grad_norm(self):
-----diff --git a/src/metrics/tracker.py b/src/metrics/tracker.py
-----index d353d72..4d349a5 100644
-------- a/src/metrics/tracker.py
-----+++ b/src/metrics/tracker.py
-----@@ -33,8 +33,10 @@ class MetricTracker:
-----         for col in self._data.columns:
-----             self._data[col].values[:] = 0
-----         
-----+        # Сброс EER данных
-----         self._eer_scores = []
-----         self._eer_labels = []
-----+        print(f"🔄 MetricTracker сброшен. EER lists очищены.")
----- 
-----     def update(self, key, value, n=1):
-----         
-----@@ -44,24 +46,61 @@ class MetricTracker:
-----         self._data.loc[key, "average"] = self._data.total[key] / self._data.counts[key]
----- 
-----     def update_eer(self, scores, labels):
------     
------
------        self._eer_scores.extend(scores.detach().cpu().numpy())
------        self._eer_labels.extend(labels.detach().cpu().numpy())
-----+        """
-----+        Update EER scores and labels.
-----+        
-----+        Args:
-----+            scores (torch.Tensor): prediction scores
-----+            labels (torch.Tensor): ground truth labels
-----+        """
-----+        if scores.numel() == 0 or labels.numel() == 0:
-----+            print(f"⚠️ update_eer: получены пустые тензоры")
-----+            return
-----+            
-----+        # Конвертируем в numpy
-----+        scores_np = scores.detach().cpu().numpy().flatten()
-----+        labels_np = labels.detach().cpu().numpy().flatten()
-----+        
-----+        # Проверяем что размеры совпадают
-----+        if len(scores_np) != len(labels_np):
-----+            print(f"⚠️ update_eer: размеры не совпадают scores={len(scores_np)}, labels={len(labels_np)}")
-----+            return
-----+        
-----+        # Проверяем валидность данных
-----+        if np.any(np.isnan(scores_np)) or np.any(np.isinf(scores_np)):
-----+            print(f"⚠️ update_eer: некорректные scores (nan/inf)")
-----+            return
-----+            
-----+        # Добавляем данные
-----+        self._eer_scores.extend(scores_np)
-----+        self._eer_labels.extend(labels_np)
----- 
-----     def compute_eer(self):
-----         """
-----         Compute Equal Error Rate from accumulated scores and labels.
-----         """
------        if not self._eer_scores:
-----+        if not self._eer_scores or len(self._eer_scores) == 0:
-----+            print(f"⚠️ compute_eer: нет данных для вычисления EER")
-----             return 0.0
-----         
-----         scores = np.array(self._eer_scores)
-----         labels = np.array(self._eer_labels)
-----         
------
-----+        print(f"🧮 Вычисляем EER: {len(scores)} семплов")
-----+        print(f"    Уникальные labels: {np.unique(labels)}")
-----+        print(f"    Scores range: {scores.min():.4f} - {scores.max():.4f}")
-----+        
-----+        # Проверяем что есть оба класса
-----+        unique_labels = np.unique(labels)
-----+        if len(unique_labels) < 2:
-----+            print(f"⚠️ compute_eer: только один класс {unique_labels}")
-----+            return 0.0
-----+        
-----         # Получаем уникальные пороги
-----         thresholds = np.unique(scores)
-----+        if len(thresholds) < 2:
-----+            print(f"⚠️ compute_eer: все scores одинаковые")
-----+            return 0.5  # Random baseline
-----         
-----         # Вычисляем FAR и FRR для каждого порога
-----         far_values = []
-----@@ -95,6 +134,8 @@ class MetricTracker:
-----         # EER - это среднее FAR и FRR в этой точке
-----         eer = (far_values[min_idx] + frr_values[min_idx]) / 2
-----         
-----+        print(f"✅ EER вычислен: {eer:.6f} (FAR={far_values[min_idx]:.6f}, FRR={frr_values[min_idx]:.6f})")
-----+        
-----         return float(eer)
----- 
-----     def avg(self, key):
-----@@ -119,8 +160,8 @@ class MetricTracker:
-----                 for each metric name.
-----         """
-----         result = dict(self._data.average)
------        if self._eer_scores:
------            result['eer'] = self.compute_eer()
-----+        # Всегда включаем EER в результат
-----+        result['eer'] = self.compute_eer()
-----         return result
----- 
-----     def keys(self):
-----diff --git a/src/model/model.py b/src/model/model.py
-----index cc6e4f7..9a74bb0 100644
-------- a/src/model/model.py
-----+++ b/src/model/model.py
-----@@ -93,12 +93,16 @@ class LCNN(nn.Module):
-----             # Берем первый тензор из батча
-----             x = next(iter(batch.values()))
-----         
-----+        print(f"🔍 Модель получила: x.shape={x.shape}")
-----+        
-----         # Убеждаемся, что входные данные имеют правильную форму
-----         if x.dim() == 3:
-----             x = x.unsqueeze(1)  # Добавляем канал
-----         elif x.dim() == 2:
-----             x = x.unsqueeze(0).unsqueeze(0)  # Добавляем batch и канал
-----         
-----+        print(f"🔍 После обработки: x.shape={x.shape}")
-----+        
-----         # Проходим через слои
-----         x = self.features(x)
-----         
-----@@ -107,6 +111,8 @@ class LCNN(nn.Module):
-----         
-----         x = self.classifier(x)
-----         
-----+        print(f"🔍 Логиты: x.shape={x.shape}, range=[{x.min().item():.3f}, {x.max().item():.3f}]")
-----+        
-----         # Возвращаем выходы
-----         outputs = {
-----             'logits': x
-----diff --git a/src/trainer/base_trainer.py b/src/trainer/base_trainer.py
-----index e27829d..a9582de 100644
-------- a/src/trainer/base_trainer.py
-----+++ b/src/trainer/base_trainer.py
-----@@ -240,6 +240,7 @@ class BaseTrainer:
-----                 batch = self.process_batch(
-----                     batch,
-----                     metrics=self.train_metrics,
-----+                    metric_funcs=self.metrics["train"],
-----                 )
-----             except torch.cuda.OutOfMemoryError as e:
-----                 if self.skip_oom:
-----@@ -337,6 +338,7 @@ class BaseTrainer:
-----                 batch = self.process_batch(
-----                     batch,
-----                     metrics=self.evaluation_metrics,
-----+                    metric_funcs=self.metrics["inference"],
-----                 )
-----             # Логирование по шагам валидации убрано - происходит в _run_validation
-----             # с правильными префиксами и step значениями
-----diff --git a/src/trainer/trainer.py b/src/trainer/trainer.py
-----index 0f5996d..4bf8b2e 100644
-------- a/src/trainer/trainer.py
-----+++ b/src/trainer/trainer.py
-----@@ -7,43 +7,32 @@ class Trainer(BaseTrainer):
-----     Trainer class. Defines the logic of batch logging and processing.
-----     """
----- 
------    def process_batch(self, batch, metrics: MetricTracker):
-----+    def process_batch(self, batch, metrics: MetricTracker, metric_funcs):
-----         """
------        Run batch through the model, compute metrics, compute loss,
------        and do training step (during training stage).
------
------        The function expects that criterion aggregates all losses
------        (if there are many) into a single one defined in the 'loss' key.
-----+        Run batch through the model, compute metrics, and update the tracker.
----- 
-----         Args:
-----             batch (dict): dict-based batch containing the data from
-----                 the dataloader.
------            metrics (MetricTracker): MetricTracker object that computes
------                and aggregates the metrics. The metrics depend on the type of
------                the partition (train or inference).
-----+            metrics (MetricTracker): tracker that aggregates metrics
-----+                over the dataset.
-----+            metric_funcs (list): functions that computes metrics.
-----+
-----         Returns:
-----             batch (dict): dict-based batch containing the data from
------                the dataloader (possibly transformed via batch transform),
------                model outputs, and losses.
-----+                the dataloader (possibly transformed via batch transform).
-----         """
-----         batch = self.move_batch_to_device(batch)
------        batch = self.transform_batch(batch)  # transform batch on device -- faster
------
------
------
------        metric_funcs = self.metrics["inference"]
-----+        batch = self.transform_batch(batch)
-----+        
-----+        # Подготовка для обучения
-----         if self.is_train:
------            metric_funcs = self.metrics["train"]
-----             self.optimizer.zero_grad()
-----+        
-----+        batch.update(self.model(**batch))
-----+        batch.update(self.criterion(**batch))
----- 
------        outputs = self.model(**batch)
------        batch.update(outputs)
------
------
------        all_losses = self.criterion(**batch)
------        batch.update(all_losses)
------
------
-----+        # Обратное распространение и обновление весов
-----         if self.is_train:
-----             batch["loss"].backward()
-----             self._clip_grad_norm()
-----@@ -51,25 +40,38 @@ class Trainer(BaseTrainer):
-----             if self.lr_scheduler is not None:
-----                 self.lr_scheduler.step()
----- 
------       
-----+        # Update loss metrics
-----         for loss_name in self.config.writer.loss_names:
-----             metrics.update(loss_name, batch[loss_name].item())
----- 
------        
------        if "logits" in batch:
------            scores = torch.softmax(batch["logits"], dim=1)[:, 1]
-----+        # ИСПРАВЛЕННОЕ ВЫЧИСЛЕНИЕ EER
-----+        if "logits" in batch and "labels" in batch:
-----+            logits = batch["logits"]
-----             labels = batch["labels"]
-----             
------            metrics.update_eer(scores, labels)
------
------      
-----+            # Убеждаемся что размеры корректны
-----+            if logits.dim() == 2 and logits.size(1) >= 2:
-----+                # Получаем вероятности для класса spoof (класс 1)
-----+                scores = torch.softmax(logits, dim=1)[:, 1]
-----+                
-----+                # Проверяем что есть данные
-----+                if scores.numel() > 0 and labels.numel() > 0:
-----+                    metrics.update_eer(scores, labels)
-----+                else:
-----+                    print(f"⚠️ Пустые данные для EER: scores.numel()={scores.numel()}, labels.numel()={labels.numel()}")
-----+            else:
-----+                print(f"⚠️ Неправильные размеры logits: {logits.shape}")
-----+        else:
-----+            print(f"⚠️ Отсутствуют необходимые ключи: logits={('logits' in batch)}, labels={('labels' in batch)}")
-----+
-----+        # Update other metrics
-----         for met in metric_funcs:
-----             if met.name != "eer":
-----                 try:
-----                     metrics.update(met.name, met(**batch))
-----                 except Exception as e:
------                    print(f"Ошибка в метрике {met.name}: {e}")
------                    continue
-----+                    print(f"⚠️ Ошибка в метрике {met.name}: {e}")
-----+
-----         return batch
----- 
-----     def _log_batch(self, batch_idx, batch, mode="train"):
----diff --git a/requirements.txt b/requirements.txt
----index 1dc9376..30ddb0c 100644
------- a/requirements.txt
----+++ b/requirements.txt
----@@ -1,24 +1,11 @@
----+omegaconf==2.3.0
----+wandb==0.16.2
---- torch==2.2.0
-----torchvision==0.17.0
---- torchaudio==2.2.0
-----torchmetrics==1.7.4
---- numpy==1.26.4
-----pandas==2.3.1
-----matplotlib==3.9.4
-----scipy
-----soundfile==0.13.1
-----librosa
-----wandb==0.21.0
-----comet-ml==3.50.0
-----hydra-core==1.3.2
-----omegaconf==2.3.0
-----tqdm==4.67.1
-----psutil==7.0.0
-----requests==2.32.4
-----pyyaml==6.0.2
-----black
-----isort
-----pre-commit
-----flake8
-----scikit-learn
-----seaborn
----\ No newline at end of file
----+pandas==2.1.4
----+matplotlib==3.8.2
----+librosa==0.10.1
----+soundfile==0.12.1
----+accelerate==0.26.1
----+tqdm==4.66.1
----\ No newline at end of file
----diff --git a/src/configs/model/lcnn.yaml b/src/configs/model/lcnn.yaml
----index 50557f2..787dbc6 100644
------- a/src/configs/model/lcnn.yaml
----+++ b/src/configs/model/lcnn.yaml
----@@ -1,2 +1,3 @@
---- _target_: src.model.model.LCNN
-----num_classes: 2 
----\ No newline at end of file
----+num_classes: 2
----+dropout_rate: 0.3  # Dropout для регуляризации модели 
----\ No newline at end of file
----diff --git a/src/configs/transforms/default.yaml b/src/configs/transforms/default.yaml
----index 32f1775..57a378d 100644
------- a/src/configs/transforms/default.yaml
----+++ b/src/configs/transforms/default.yaml
----@@ -3,9 +3,9 @@ instance_transforms:
---- 
---- stft:
----   _target_: src.transforms.stft.STFTTransform
-----  n_fft: 1024
-----  hop_length: 512
-----  win_length: 1024
----+  n_fft: 1724  # Для получения 863 freq bins (1724//2 + 1 = 863)
----+  hop_length: 256  # Для лучшего временного разрешения
----+  win_length: 1724
---- 
---- batch_transforms:
----   train:
----diff --git a/src/datasets/base_dataset.py b/src/datasets/base_dataset.py
----index e75525d..4b4bfc0 100644
------- a/src/datasets/base_dataset.py
----+++ b/src/datasets/base_dataset.py
----@@ -67,7 +67,8 @@ class BaseDataset(Dataset):
----                 try:
----                     item[transform_name] = transform(item[transform_name])
----                 except Exception as e:
-----                    raise
----+                    print(f"⚠️ Ошибка в трансформе {transform_name}: {e}")
----+                    continue
----         
----         return item
---- 
----diff --git a/src/datasets/collate.py b/src/datasets/collate.py
----index 6cb3b10..4e5d6ef 100644
------- a/src/datasets/collate.py
----+++ b/src/datasets/collate.py
----@@ -17,28 +17,42 @@ def collate_fn(dataset_items: list[dict]):
---- 
----     result_batch = {}
---- 
-----    # Pad audio sequences to the same length
-----    audio_tensors = [elem["data_object"] for elem in dataset_items]
----+    # Обработка данных (может быть аудио или спектрограммы после STFT)
----+    data_tensors = [elem["data_object"] for elem in dataset_items]
----     
-----    # Handle different audio tensor shapes
-----    if len(audio_tensors) == 0:
----+    # Handle different tensor shapes
----+    if len(data_tensors) == 0:
----         # Return empty batch
----         result_batch["data_object"] = torch.empty(0)
----         result_batch["labels"] = torch.empty(0, dtype=torch.long)
----         return result_batch
----     
-----    # Get max length for padding
-----    max_length = max(audio.shape[-1] for audio in audio_tensors)
----+    # Проверяем размерности - если 2D, то это спектрограммы, если 1D/2D - аудио
----+    first_tensor = data_tensors[0]
----     
-----    padded_audio = []
-----    for audio in audio_tensors:
-----        if audio.shape[-1] < max_length:
-----            # Pad with zeros
-----            padding = max_length - audio.shape[-1]
-----            audio = F.pad(audio, (0, padding))
-----        padded_audio.append(audio)
----+    if first_tensor.dim() >= 2 and first_tensor.shape[0] > 100:  # Спектрограмма
----+        # Для спектрограмм - padding по временной оси (последняя размерность)
----+        max_time = max(data.shape[-1] for data in data_tensors)
----+        
----+        padded_data = []
----+        for data in data_tensors:
----+            if data.shape[-1] < max_time:
----+                # Pad по времени
----+                padding = max_time - data.shape[-1]
----+                data = F.pad(data, (0, padding))
----+            padded_data.append(data)
----+    else:
----+        # Для аудио - padding как раньше
----+        max_length = max(data.shape[-1] for data in data_tensors)
----+        
----+        padded_data = []
----+        for data in data_tensors:
----+            if data.shape[-1] < max_length:
----+                padding = max_length - data.shape[-1]
----+                data = F.pad(data, (0, padding))
----+            padded_data.append(data)
----     
-----    result_batch["data_object"] = torch.stack(padded_audio)
----+    result_batch["data_object"] = torch.stack(padded_data)
----     result_batch["labels"] = torch.tensor([elem["labels"] for elem in dataset_items], dtype=torch.long)
---- 
----     return result_batch
----\ No newline at end of file
----diff --git a/src/loss/crossentropy.py b/src/loss/crossentropy.py
----index 59e4470..cfae8cf 100644
------- a/src/loss/crossentropy.py
----+++ b/src/loss/crossentropy.py
----@@ -16,12 +16,12 @@ class CrossEntropyLoss(nn.Module):
----         super(CrossEntropyLoss, self).__init__()
----         self.criterion = nn.CrossEntropyLoss()
---- 
-----    def forward(self, **batch) -> Dict[str, torch.Tensor]:
----+    def forward(self, batch) -> Dict[str, torch.Tensor]:
----         """
----         Compute cross entropy loss.
----         
----         Args:
-----            **batch: input batch containing logits and labels
----+            batch: input batch containing logits and labels
----             
----         Returns:
----             Dict[str, torch.Tensor]: loss dictionary
----@@ -30,7 +30,6 @@ class CrossEntropyLoss(nn.Module):
----         logits = batch['logits']
----         labels = batch['labels']
----         
-----
----         # Проверяем размеры
----         if logits.dim() == 1:
----             logits = logits.unsqueeze(0)
----diff --git a/src/metrics/base_metric.py b/src/metrics/base_metric.py
----index f4b0694..d1fd2c5 100644
------- a/src/metrics/base_metric.py
----+++ b/src/metrics/base_metric.py
----@@ -14,7 +14,7 @@ class BaseMetric:
----         self.name = name if name is not None else type(self).__name__
---- 
----     @abstractmethod
-----    def __call__(self, **batch):
----+    def __call__(self, batch):
----         """
----         Defines metric calculation logic for a given batch.
----         Can use external functions (like TorchMetrics) or custom ones.
----diff --git a/src/metrics/eer.py b/src/metrics/eer.py
----index 3802d06..21a5027 100644
------- a/src/metrics/eer.py
----+++ b/src/metrics/eer.py
----@@ -18,12 +18,12 @@ class EERMetric(BaseMetric):
----         super(EERMetric, self).__init__()
----         self.name = "eer"
---- 
-----    def forward(self, **batch) -> float:
----+    def __call__(self, batch) -> float:
----         """
----         Compute EER metric.
----         
----         Args:
-----            **batch: input batch containing scores and labels
----+            batch: input batch containing scores and labels
----             
----         Returns:
----             float: EER value
----diff --git a/src/metrics/tracker.py b/src/metrics/tracker.py
----index 4d349a5..26ebc87 100644
------- a/src/metrics/tracker.py
----+++ b/src/metrics/tracker.py
----@@ -36,7 +36,6 @@ class MetricTracker:
----         # Сброс EER данных
----         self._eer_scores = []
----         self._eer_labels = []
-----        print(f"🔄 MetricTracker сброшен. EER lists очищены.")
---- 
----     def update(self, key, value, n=1):
----         
----@@ -50,11 +49,10 @@ class MetricTracker:
----         Update EER scores and labels.
----         
----         Args:
-----            scores (torch.Tensor): prediction scores
-----            labels (torch.Tensor): ground truth labels
----+            scores (torch.Tensor): prediction scores (должны быть scores для bonafide класса)
----+            labels (torch.Tensor): ground truth labels (1 = bonafide, 0 = spoof)
----         """
----         if scores.numel() == 0 or labels.numel() == 0:
-----            print(f"⚠️ update_eer: получены пустые тензоры")
----             return
----             
----         # Конвертируем в numpy
----@@ -63,12 +61,10 @@ class MetricTracker:
----         
----         # Проверяем что размеры совпадают
----         if len(scores_np) != len(labels_np):
-----            print(f"⚠️ update_eer: размеры не совпадают scores={len(scores_np)}, labels={len(labels_np)}")
----             return
----         
----         # Проверяем валидность данных
----         if np.any(np.isnan(scores_np)) or np.any(np.isinf(scores_np)):
-----            print(f"⚠️ update_eer: некорректные scores (nan/inf)")
----             return
----             
----         # Добавляем данные
----@@ -77,66 +73,87 @@ class MetricTracker:
---- 
----     def compute_eer(self):
----         """
-----        Compute Equal Error Rate from accumulated scores and labels.
----+        Compute Equal Error Rate from accumulated scores and labels using reference implementation.
----         """
----         if not self._eer_scores or len(self._eer_scores) == 0:
-----            print(f"⚠️ compute_eer: нет данных для вычисления EER")
----             return 0.0
----         
----         scores = np.array(self._eer_scores)
----         labels = np.array(self._eer_labels)
----         
-----        print(f"🧮 Вычисляем EER: {len(scores)} семплов")
-----        print(f"    Уникальные labels: {np.unique(labels)}")
-----        print(f"    Scores range: {scores.min():.4f} - {scores.max():.4f}")
-----        
----         # Проверяем что есть оба класса
----         unique_labels = np.unique(labels)
----         if len(unique_labels) < 2:
-----            print(f"⚠️ compute_eer: только один класс {unique_labels}")
----             return 0.0
----         
-----        # Получаем уникальные пороги
-----        thresholds = np.unique(scores)
-----        if len(thresholds) < 2:
-----            print(f"⚠️ compute_eer: все scores одинаковые")
-----            return 0.5  # Random baseline
----+        # Разделяем scores на bonafide и spoof
----+        bonafide_scores = scores[labels == 1]  # Настоящие образцы
----+        spoof_scores = scores[labels == 0]     # Поддельные образцы
----         
-----        # Вычисляем FAR и FRR для каждого порога
-----        far_values = []
-----        frr_values = []
----+        if len(bonafide_scores) == 0 or len(spoof_scores) == 0:
----+            return 0.0
----         
-----        for threshold in thresholds:
-----            # Предсказания: 1 если score >= threshold, иначе 0
-----            predictions = (scores >= threshold).astype(int)
-----            
-----            # Вычисляем confusion matrix
-----            tp = np.sum((predictions == 1) & (labels == 1))
-----            tn = np.sum((predictions == 0) & (labels == 0))
-----            fp = np.sum((predictions == 1) & (labels == 0))
-----            fn = np.sum((predictions == 0) & (labels == 1))
-----            
-----            # Вычисляем FAR и FRR
-----            far = fp / (fp + tn) if (fp + tn) > 0 else 0
-----            frr = fn / (fn + tp) if (fn + tp) > 0 else 0
-----            
-----            far_values.append(far)
-----            frr_values.append(frr)
----+        # Используем эталонную реализацию
----+        eer, threshold = self._compute_eer_reference(bonafide_scores, spoof_scores)
----+        
----+        return float(eer)
----+
----+    def _compute_eer_reference(self, bonafide_scores, spoof_scores):
----+        """
----+        Reference implementation of EER computation (эталонная реализация).
----         
-----        # Находим точку, где FAR ≈ FRR
-----        far_values = np.array(far_values)
-----        frr_values = np.array(frr_values)
----+        Args:
----+            bonafide_scores: scores for bonafide (genuine) samples
----+            spoof_scores: scores for spoof (fake) samples
----+            
----+        Returns:
----+            tuple: (eer, threshold)
----+        """
----+        frr, far, thresholds = self._compute_det_curve(bonafide_scores, spoof_scores)
----+        abs_diffs = np.abs(frr - far)
----+        min_index = np.argmin(abs_diffs)
----+        eer = np.mean((frr[min_index], far[min_index]))
----         
-----        # Находим индекс, где разность минимальна
-----        diff = np.abs(far_values - frr_values)
-----        min_idx = np.argmin(diff)
----+        return float(eer), float(thresholds[min_index])
----+
----+    def _compute_det_curve(self, target_scores, nontarget_scores):
----+        """
----+        Compute Detection Error Tradeoff (DET) curve (эталонная реализация).
----         
-----        # EER - это среднее FAR и FRR в этой точке
-----        eer = (far_values[min_idx] + frr_values[min_idx]) / 2
----+        Args:
----+            target_scores: scores for target (bonafide) samples
----+            nontarget_scores: scores for nontarget (spoof) samples
----+            
----+        Returns:
----+            tuple: (frr, far, thresholds)
----+        """
----+        n_scores = target_scores.size + nontarget_scores.size
----+        all_scores = np.concatenate((target_scores, nontarget_scores))
----+        labels = np.concatenate(
----+            (np.ones(target_scores.size), np.zeros(nontarget_scores.size)))
----+
----+        # Sort labels based on scores
----+        indices = np.argsort(all_scores, kind='mergesort')
----+        labels = labels[indices]
----+
----+        # Compute false rejection and false acceptance rates
----+        tar_trial_sums = np.cumsum(labels)
----+        nontarget_trial_sums = nontarget_scores.size - \
----+            (np.arange(1, n_scores + 1) - tar_trial_sums)
----+
----+        # False rejection rates (FRR): отклонение настоящих как поддельных
----+        frr = np.concatenate(
----+            (np.atleast_1d(0), tar_trial_sums / target_scores.size))
----         
-----        print(f"✅ EER вычислен: {eer:.6f} (FAR={far_values[min_idx]:.6f}, FRR={frr_values[min_idx]:.6f})")
----+        # False acceptance rates (FAR): принятие поддельных как настоящих  
----+        far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums /
----+                              nontarget_scores.size))
----         
-----        return float(eer)
----+        # Thresholds are the sorted scores
----+        thresholds = np.concatenate(
----+            (np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))
----+
----+        return frr, far, thresholds
---- 
----     def avg(self, key):
----         """
----diff --git a/src/model/model.py b/src/model/model.py
----index cc6e4f7..59a64c7 100644
------- a/src/model/model.py
----+++ b/src/model/model.py
----@@ -3,61 +3,103 @@ import torch.nn as nn
---- from typing import Dict, Any
---- 
---- 
----+class MFM(nn.Module):
----+    """
----+    Max Feature Map (MFM) activation function.
----+    Takes maximum of two halves of input channels or features.
----+    """
----+    def __init__(self, in_features, out_features):
----+        super(MFM, self).__init__()
----+        self.out_features = out_features
----+        
----+    def forward(self, x):
----+        # Разделяем на две половины и берем максимум
----+        if x.dim() == 4:  # Для conv слоев [B, C, H, W]
----+            x1, x2 = torch.split(x, self.out_features, dim=1)
----+        else:  # Для linear слоев [B, F]  
----+            x1, x2 = torch.split(x, self.out_features, dim=1)
----+        return torch.max(x1, x2)
----+
----+
---- class LCNN(nn.Module):
----     """
-----    Light CNN model for audio anti-spoofing.
----+    Light CNN model for audio anti-spoofing (точно по таблице).
----+    Общее количество параметров: 371K
----     """
---- 
-----    def __init__(self, num_classes=2, **kwargs):
----+    def __init__(self, num_classes=2, dropout_rate=0.3, **kwargs):
----         """
----         Args:
----             num_classes (int): number of output classes
----+            dropout_rate (float): dropout probability for regularization
----             **kwargs: additional arguments
----         """
----         super(LCNN, self).__init__()
----         
----         self.num_classes = num_classes
----+        self.dropout_rate = dropout_rate
----         
-----        # Определяем архитектуру
-----        self.features = nn.Sequential(
-----            # Первый блок
-----            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),
-----            nn.BatchNorm2d(64),
-----            nn.ReLU(inplace=True),
-----            nn.MaxPool2d(kernel_size=2, stride=2),
-----            
-----            # Второй блок
-----            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
-----            nn.BatchNorm2d(128),
-----            nn.ReLU(inplace=True),
-----            nn.MaxPool2d(kernel_size=2, stride=2),
-----            
-----            # Третий блок
-----            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
-----            nn.BatchNorm2d(256),
-----            nn.ReLU(inplace=True),
-----            nn.MaxPool2d(kernel_size=2, stride=2),
-----            
-----            # Четвертый блок
-----            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
-----            nn.BatchNorm2d(512),
-----            nn.ReLU(inplace=True),
-----            nn.MaxPool2d(kernel_size=2, stride=2),
-----        )
-----        
-----        # Global Average Pooling
-----        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))
-----        
-----        # Классификатор
-----        self.classifier = nn.Sequential(
-----            nn.Dropout(0.5),
-----            nn.Linear(512, 256),
-----            nn.ReLU(inplace=True),
-----            nn.Dropout(0.5),
-----            nn.Linear(256, num_classes)
-----        )
-----        
-----        # ДОБАВЛЯЕМ ПРАВИЛЬНУЮ ИНИЦИАЛИЗАЦИЮ ВЕСОВ
----+        # Conv_1 (5x5/1x1) -> MFM_2 -> MaxPool_3 (2x2/2x2)
----+        # Вход: 863x600x1, Выход: 431x300x32
----+        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2, bias=False)  # 1.6K params
----+        self.mfm1 = MFM(64, 32)
----+        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
----+        
----+        # Block 1: Conv_4 (1x1/1x1) -> MFM_5 -> BN_6 -> Conv_7 (3x3/1x1) -> MFM_8 -> MaxPool_9 -> BN_10
----+        # Вход: 431x300x32, Выход: 215x150x48
----+        self.block1_conv1 = nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0, bias=False)  # 2.1K params
----+        self.block1_mfm1 = MFM(64, 32)
----+        self.block1_bn1 = nn.BatchNorm2d(32)
----+        self.block1_conv2 = nn.Conv2d(32, 96, kernel_size=3, stride=1, padding=1, bias=False)  # 27.7K params
----+        self.block1_mfm2 = MFM(96, 48)
----+        self.block1_pool = nn.MaxPool2d(kernel_size=2, stride=2)
----+        self.block1_bn2 = nn.BatchNorm2d(48)
----+        self.block1_dropout = nn.Dropout2d(p=dropout_rate)
----+        
----+        # Block 2: Conv_11 (1x1/1x1) -> MFM_12 -> BN_13 -> Conv_14 (3x3/1x1) -> MFM_15 -> MaxPool_16
----+        # Вход: 215x150x48, Выход: 107x75x64
----+        self.block2_conv1 = nn.Conv2d(48, 96, kernel_size=1, stride=1, padding=0, bias=False)  # 4.7K params
----+        self.block2_mfm1 = MFM(96, 48)
----+        self.block2_bn1 = nn.BatchNorm2d(48)
----+        self.block2_conv2 = nn.Conv2d(48, 128, kernel_size=3, stride=1, padding=1, bias=False)  # 55.4K params
----+        self.block2_mfm2 = MFM(128, 64)
----+        self.block2_pool = nn.MaxPool2d(kernel_size=2, stride=2)
----+        self.block2_dropout = nn.Dropout2d(p=dropout_rate)
----+        
----+        # Block 3: Conv_17 (1x1/1x1) -> MFM_18 -> BN_19 -> Conv_20 (3x3/1x1) -> MFM_21 -> BN_22
----+        # Вход: 107x75x64, Выход: 107x75x32
----+        self.block3_conv1 = nn.Conv2d(64, 128, kernel_size=1, stride=1, padding=0, bias=False)  # 8.3K params
----+        self.block3_mfm1 = MFM(128, 64)
----+        self.block3_bn1 = nn.BatchNorm2d(64)
----+        self.block3_conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)  # 36.9K params
----+        self.block3_mfm2 = MFM(64, 32)
----+        self.block3_bn2 = nn.BatchNorm2d(32)
----+        self.block3_dropout = nn.Dropout2d(p=dropout_rate)
----+        
----+        # Block 4: Conv_23 (1x1/1x1) -> MFM_24 -> BN_25 -> Conv_26 (3x3/1x1) -> MFM_27 -> MaxPool_28
----+        # Вход: 107x75x32, Выход: 53x37x32
----+        self.block4_conv1 = nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0, bias=False)  # 2.1K params
----+        self.block4_mfm1 = MFM(64, 32)
----+        self.block4_bn1 = nn.BatchNorm2d(32)
----+        self.block4_conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)  # 18.5K params
----+        self.block4_mfm2 = MFM(64, 32)
----+        self.block4_pool = nn.MaxPool2d(kernel_size=2, stride=2)
----+        self.block4_dropout = nn.Dropout2d(p=dropout_rate)
----+        
----+        # Classifier: FC_29 -> MFM_30 -> BN_31 -> Dropout -> FC_32
----+        # Размер после всех операций: 53x37x32 = 62464 features
----+        # Но в таблице FC_29 дает 160 выходов с 10.2MM параметров
----+        # Это означает глобальный пулинг до размера, который даст нужное количество параметров
----+        
----+        # Добавляем глобальный пулинг и классификатор согласно таблице
----+        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # 53x37x32 -> 1x1x32
----+        self.fc1 = nn.Linear(32, 160, bias=True)  # FC_29: 32*160 + 160 = 5280 ≈ 5.3K params
----+        self.mfm_fc = MFM(160, 80)  # MFM_30: 160 -> 80
----+        self.bn_fc = nn.BatchNorm1d(80)  # BN_31
----+        self.dropout_fc = nn.Dropout(p=dropout_rate)  # Dropout перед финальным слоем
----+        self.fc2 = nn.Linear(80, num_classes, bias=True)  # FC_32: 80*2 + 2 = 162 ≈ 64 params
----+        
----+        # Инициализация весов
----         self._init_weights()
---- 
----     def _init_weights(self):
----@@ -65,47 +107,89 @@ class LCNN(nn.Module):
----         for m in self.modules():
----             if isinstance(m, nn.Conv2d):
----                 nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
-----                if m.bias is not None:
-----                    nn.init.constant_(m.bias, 0)
-----            elif isinstance(m, nn.BatchNorm2d):
----+            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):
----                 nn.init.constant_(m.weight, 1)
----                 nn.init.constant_(m.bias, 0)
----             elif isinstance(m, nn.Linear):
----                 nn.init.normal_(m.weight, 0, 0.01)
-----                nn.init.constant_(m.bias, 0)
----+                if m.bias is not None:
----+                    nn.init.constant_(m.bias, 0)
---- 
-----    def forward(self, **batch) -> Dict[str, torch.Tensor]:
----+    def forward(self, batch) -> Dict[str, torch.Tensor]:
----         """
-----        Forward pass of the model.
----+        Forward pass of the Light CNN model.
----         
----         Args:
-----            **batch: input batch containing tensors
----+            batch: input batch containing tensors
----             
----         Returns:
----             Dict[str, torch.Tensor]: model outputs
----         """
----         # Получаем входные данные
-----        if 'spectrogram' in batch:
-----            x = batch['spectrogram']
-----        elif 'data_object' in batch:
----+        if 'data_object' in batch:
----             x = batch['data_object']
----+        elif 'spectrogram' in batch:
----+            x = batch['spectrogram']
----         else:
-----            # Берем первый тензор из батча
----             x = next(iter(batch.values()))
----         
----         # Убеждаемся, что входные данные имеют правильную форму
----         if x.dim() == 3:
-----            x = x.unsqueeze(1)  # Добавляем канал
----+            x = x.unsqueeze(1)  # Добавляем канал: [batch, freq, time] -> [batch, 1, freq, time]
----         elif x.dim() == 2:
-----            x = x.unsqueeze(0).unsqueeze(0)  # Добавляем batch и канал
----+            x = x.unsqueeze(0).unsqueeze(0)  # [freq, time] -> [1, 1, freq, time]
----+        
----+        # Conv_1 + MFM_2 + MaxPool_3
----+        # Ожидаемый размер: [B, 1, 863, 600] -> [B, 32, 431, 300]
----+        x = self.conv1(x)          # [B, 64, 863, 600]
----+        x = self.mfm1(x)           # [B, 32, 863, 600]
----+        x = self.pool1(x)          # [B, 32, 431, 300]
----+        
----+        # Block 1: [B, 32, 431, 300] -> [B, 48, 215, 150]
----+        x = self.block1_conv1(x)   # [B, 64, 431, 300]
----+        x = self.block1_mfm1(x)    # [B, 32, 431, 300]
----+        x = self.block1_bn1(x)     
----+        x = self.block1_conv2(x)   # [B, 96, 431, 300]
----+        x = self.block1_mfm2(x)    # [B, 48, 431, 300]
----+        x = self.block1_pool(x)    # [B, 48, 215, 150]
----+        x = self.block1_bn2(x)
----+        x = self.block1_dropout(x)
----+        
----+        # Block 2: [B, 48, 215, 150] -> [B, 64, 107, 75]
----+        x = self.block2_conv1(x)   # [B, 96, 215, 150]
----+        x = self.block2_mfm1(x)    # [B, 48, 215, 150]
----+        x = self.block2_bn1(x)     
----+        x = self.block2_conv2(x)   # [B, 128, 215, 150]
----+        x = self.block2_mfm2(x)    # [B, 64, 215, 150]
----+        x = self.block2_pool(x)    # [B, 64, 107, 75]
----+        x = self.block2_dropout(x)
----         
-----        # Проходим через слои
-----        x = self.features(x)
----+        # Block 3: [B, 64, 107, 75] -> [B, 32, 107, 75]
----+        x = self.block3_conv1(x)   # [B, 128, 107, 75]
----+        x = self.block3_mfm1(x)    # [B, 64, 107, 75]
----+        x = self.block3_bn1(x)
----+        x = self.block3_conv2(x)   # [B, 64, 107, 75]
----+        x = self.block3_mfm2(x)    # [B, 32, 107, 75]
----+        x = self.block3_bn2(x)
----+        x = self.block3_dropout(x)
----         
-----        x = self.global_avg_pool(x)
-----        x = x.view(x.size(0), -1)
----+        # Block 4: [B, 32, 107, 75] -> [B, 32, 53, 37]
----+        x = self.block4_conv1(x)   # [B, 64, 107, 75]
----+        x = self.block4_mfm1(x)    # [B, 32, 107, 75]
----+        x = self.block4_bn1(x)
----+        x = self.block4_conv2(x)   # [B, 64, 107, 75]
----+        x = self.block4_mfm2(x)    # [B, 32, 107, 75]
----+        x = self.block4_pool(x)    # [B, 32, 53, 37]
----+        x = self.block4_dropout(x)
----         
-----        x = self.classifier(x)
----+        # Classifier: [B, 32, 53, 37] -> [B, num_classes]
----+        x = self.global_pool(x)    # [B, 32, 1, 1]
----+        x = x.view(x.size(0), -1)  # [B, 32]
----+        x = self.fc1(x)            # [B, 160] (FC_29)
----+        x = self.mfm_fc(x)         # [B, 80] (MFM_30)
----+        x = self.bn_fc(x)          # [B, 80] (BN_31)
----+        x = self.dropout_fc(x)     # Dropout
----+        x = self.fc2(x)            # [B, num_classes] (FC_32)
----         
----         # Возвращаем выходы
----         outputs = {
----@@ -118,7 +202,7 @@ class LCNN(nn.Module):
---- # Создаем экземпляр модели для совместимости с hydra
---- def create_model(**kwargs) -> LCNN:
----     """
-----    Создает экземпляр модели LCNN.
----+    Создает экземпляр модели Light CNN.
----     
----     Args:
----         **kwargs: параметры модели
----diff --git a/src/trainer/base_trainer.py b/src/trainer/base_trainer.py
----index a9582de..5083117 100644
------- a/src/trainer/base_trainer.py
----+++ b/src/trainer/base_trainer.py
----@@ -167,30 +167,30 @@ class BaseTrainer:
----             self._last_epoch = epoch
----             result = self._train_epoch(epoch)
---- 
-----            # Основной лог с тренировочными метриками
----+          
----             log = {"epoch": epoch}
----             log.update(result)
---- 
-----            # ВАЛИДАЦИЯ В КОНЦЕ ЭПОХИ (согласно val_period)
----+           
----             val_log = {}
----             if "val" in self.evaluation_dataloaders and (epoch % self.val_period == 0 or epoch == self.epochs):
----                 val_results = self._run_validation(epoch, is_mid_epoch=False)
----                 
-----                # НЕ добавляем префикс val_ здесь, он уже есть в конфиге monitor
----+                
----                 val_log = {f"val_{k}": v for k, v in val_results.items()}
----                 
-----                # Добавляем валидационные метрики в log с префиксом для логгера
----+                
----                 log.update(val_log)
---- 
----             # evaluate model performance according to configured metric
-----            # ИСПОЛЬЗУЕМ ВАЛИДАЦИОННЫЕ МЕТРИКИ для model selection (если есть валидация в эту эпоху)!
----+          
----             monitor_logs = val_log if val_log else result
----             best, stop_process, not_improved_count = self._monitor_performance(monitor_logs, not_improved_count=not_improved_count)
----             early_stop_count = not_improved_count
---- 
----             best_ckpt_path = str(self.checkpoint_dir / "model_best.pth")
----             
-----            # Логируем все метрики в основной лог  
----+           
----             for key, value in log.items():
----                 self.logger.info(f"    {key:15s}: {value}")
---- 
----@@ -205,12 +205,11 @@ class BaseTrainer:
----                 print(f"Ранняя остановка на эпохе {epoch}")
----                 break
----                 
-----        # ФИНАЛЬНАЯ ВАЛИДАЦИЯ
----         print(f"\n🎯 Финальная валидация:")
----         if "val" in self.evaluation_dataloaders:
----             final_results = self._run_validation(self.epochs, is_mid_epoch=False, is_final=True)
----         
-----        # TEST ЗАПУСКАЕТСЯ ОТДЕЛЬНО - НЕ ЗДЕСЬ!
----+        
----         if self.test_dataloader is not None:
----             print(f"\n⚠️ TEST набор доступен для финального inference")
----             print(f"   Используйте inference.py для запуска теста")
----diff --git a/src/trainer/inferencer.py b/src/trainer/inferencer.py
----index 2dc68a0..dbcc2ee 100644
------- a/src/trainer/inferencer.py
----+++ b/src/trainer/inferencer.py
----@@ -121,12 +121,12 @@ class Inferencer(BaseTrainer):
----         batch = self.move_batch_to_device(batch)
----         batch = self.transform_batch(batch)  # transform batch on device -- faster
---- 
-----        outputs = self.model(**batch)
----+        outputs = self.model(batch)
----         batch.update(outputs)
---- 
----         if metrics is not None:
----             for met in self.metrics["inference"]:
-----                metrics.update(met.name, met(**batch))
----+                metrics.update(met.name, met(batch))
---- 
----     
---- 
----diff --git a/src/trainer/trainer.py b/src/trainer/trainer.py
----index 4bf8b2e..a511a63 100644
------- a/src/trainer/trainer.py
----+++ b/src/trainer/trainer.py
----@@ -29,8 +29,8 @@ class Trainer(BaseTrainer):
----         if self.is_train:
----             self.optimizer.zero_grad()
----         
-----        batch.update(self.model(**batch))
-----        batch.update(self.criterion(**batch))
----+        batch.update(self.model(batch))
----+        batch.update(self.criterion(batch))
---- 
----         # Обратное распространение и обновление весов
----         if self.is_train:
----@@ -51,8 +51,8 @@ class Trainer(BaseTrainer):
----             
----             # Убеждаемся что размеры корректны
----             if logits.dim() == 2 and logits.size(1) >= 2:
-----                # Получаем вероятности для класса spoof (класс 1)
-----                scores = torch.softmax(logits, dim=1)[:, 1]
----+                # Получаем вероятности для класса bonafide (класс 0) - правильно для EER
----+                scores = torch.softmax(logits, dim=1)[:, 0]
----                 
----                 # Проверяем что есть данные
----                 if scores.numel() > 0 and labels.numel() > 0:
----@@ -68,7 +68,7 @@ class Trainer(BaseTrainer):
----         for met in metric_funcs:
----             if met.name != "eer":
----                 try:
-----                    metrics.update(met.name, met(**batch))
----+                    metrics.update(met.name, met(batch))
----                 except Exception as e:
----                     print(f"⚠️ Ошибка в метрике {met.name}: {e}")
---- 
----diff --git a/src/transforms/stft.py b/src/transforms/stft.py
----index 89b7933..d354524 100644
------- a/src/transforms/stft.py
----+++ b/src/transforms/stft.py
----@@ -48,7 +48,6 @@ class STFTTransform(nn.Module):
----             window=torch.hann_window(self.win_length).to(audio.device)
----         )
----         
-----
----         spectrogram = torch.abs(stft_output)
----         
----         return spectrogram
---diff --git a/src/datasets/data_utils.py b/src/datasets/data_utils.py
---index 78280ae..49e845f 100644
------ a/src/datasets/data_utils.py
---+++ b/src/datasets/data_utils.py
---@@ -92,10 +92,12 @@ def get_dataloaders(config, device, debug_mode=False):
---             batch_size = min(2, len(dataset))
---             num_workers = 0
---             pin_memory = False
---+            shuffle = False  # В debug режиме не перемешиваем для воспроизводимости
---         else:
---             batch_size = config.dataloader.batch_size
---             num_workers = getattr(config.dataloader, 'num_workers', 4)
---             pin_memory = getattr(config.dataloader, 'pin_memory', True)
---+            shuffle = True  # В обычном режиме обязательно перемешиваем
--- 
---         assert batch_size <= len(dataset), (
---             f"The batch size ({batch_size}) cannot "
---@@ -110,7 +112,7 @@ def get_dataloaders(config, device, debug_mode=False):
---             pin_memory=pin_memory,
---             collate_fn=collate_fn,
---             drop_last=False,  # В debug режиме не отбрасываем данные
----            shuffle=False,    # В debug режиме не перемешиваем для воспроизводимости
---+            shuffle=shuffle,
---             worker_init_fn=set_worker_seed,
---         )
---         
---diff --git a/src/loss/crossentropy.py b/src/loss/crossentropy.py
---index cfae8cf..ba3f1f4 100644
------ a/src/loss/crossentropy.py
---+++ b/src/loss/crossentropy.py
---@@ -30,11 +30,11 @@ class CrossEntropyLoss(nn.Module):
---         logits = batch['logits']
---         labels = batch['labels']
---         
----        # Проверяем размеры
----        if logits.dim() == 1:
----            logits = logits.unsqueeze(0)
----        if labels.dim() == 0:
----            labels = labels.unsqueeze(0)
---+        # Проверяем что размерности корректны для CrossEntropy
---+        # logits: [batch_size, num_classes], labels: [batch_size]
---+        assert logits.dim() == 2, f"Expected logits dim=2, got {logits.dim()}"
---+        assert labels.dim() == 1, f"Expected labels dim=1, got {labels.dim()}"
---+        assert logits.size(0) == labels.size(0), "Batch size mismatch"
---         
---         # Вычисляем потерю
---         loss = self.criterion(logits, labels)
---diff --git a/src/metrics/eer.py b/src/metrics/eer.py
---index 21a5027..9e92be1 100644
------ a/src/metrics/eer.py
---+++ b/src/metrics/eer.py
---@@ -32,16 +32,16 @@ class EERMetric(BaseMetric):
---         if 'scores' in batch:
---             scores = batch['scores']
---         elif 'logits' in batch:
----            # Если у нас есть logits, берем вероятность второго класса (spoof)
---+            # Если у нас есть logits, берем вероятность первого класса (bonafide)
---             logits = batch['logits']
----            scores = torch.softmax(logits, dim=1)[:, 1]
---+            scores = torch.softmax(logits, dim=1)[:, 0]
---         else:
---             return 0.0
---         
---         labels = batch['labels']
---         
---         # Вычисляем EER
----        eer = self._compute_eer(scores, labels)
---+        eer, _ = self._compute_eer(scores, labels)
---         
---         return eer
--- 
--diff --git a/src/metrics/eer.py b/src/metrics/eer.py
--index 9e92be1..398e825 100644
----- a/src/metrics/eer.py
--+++ b/src/metrics/eer.py
--@@ -8,6 +8,7 @@ from src.metrics.base_metric import BaseMetric
-- class EERMetric(BaseMetric):
--     """
--     Equal Error Rate (EER) metric for audio anti-spoofing.
--+    Использует точно эталонную реализацию из ASVspoof.
--     """
-- 
--     def __init__(self, **kwargs):
--@@ -28,11 +29,9 @@ class EERMetric(BaseMetric):
--         Returns:
--             float: EER value
--         """
---        # Получаем scores и labels
--         if 'scores' in batch:
--             scores = batch['scores']
--         elif 'logits' in batch:
---            # Если у нас есть logits, берем вероятность первого класса (bonafide)
--             logits = batch['logits']
--             scores = torch.softmax(logits, dim=1)[:, 0]
--         else:
--@@ -40,62 +39,74 @@ class EERMetric(BaseMetric):
--         
--         labels = batch['labels']
--         
---        # Вычисляем EER
---        eer, _ = self._compute_eer(scores, labels)
--+        
--+        eer, _ = self.compute_eer(scores, labels)
--         
--         return eer
-- 
---    def _compute_eer(self, scores: torch.Tensor, labels: torch.Tensor) -> float:
--+    def compute_eer(self, scores: torch.Tensor, labels: torch.Tensor):
--         """
---        Compute Equal Error Rate.
--+        Returns equal error rate (EER) and the corresponding threshold.
--         
--         Args:
---            scores (torch.Tensor): prediction scores
---            labels (torch.Tensor): ground truth labels
--+            scores (torch.Tensor): prediction scores (probability of bonafide)
--+            labels (torch.Tensor): ground truth labels (0 = bonafide, 1 = spoof)
--             
--         Returns:
---            float: EER value
--+            tuple: (eer, threshold)
--         """
---        # Конвертируем в numpy
--+       
--         scores_np = scores.detach().cpu().numpy()
--         labels_np = labels.detach().cpu().numpy()
--         
---        # Получаем уникальные пороги
---        thresholds = np.unique(scores_np)
--+       
--+        bonafide_scores = scores_np[labels_np == 0]  
--+        other_scores = scores_np[labels_np == 1]
--         
---        # Вычисляем FAR и FRR для каждого порога
---        far_values = []
---        frr_values = []
--+     
--+        if len(bonafide_scores) == 0 or len(other_scores) == 0:
--+            return 0.0, 0.0
--         
---        for threshold in thresholds:
---            # FAR = FP / (FP + TN) = FP / (FP + TN)
---            # FRR = FN / (FN + TP) = FN / (FN + TP)
---            
---            # Предсказания: 1 если score >= threshold, иначе 0
---            predictions = (scores_np >= threshold).astype(int)
---            
---            # Вычисляем confusion matrix
---            tp = np.sum((predictions == 1) & (labels_np == 1))
---            tn = np.sum((predictions == 0) & (labels_np == 0))
---            fp = np.sum((predictions == 1) & (labels_np == 0))
---            fn = np.sum((predictions == 0) & (labels_np == 1))
---            
---            # Вычисляем FAR и FRR
---            far = fp / (fp + tn) if (fp + tn) > 0 else 0
---            frr = fn / (fn + tp) if (fn + tp) > 0 else 0
---            
---            far_values.append(far)
---            frr_values.append(frr)
---        
---        # Находим точку, где FAR ≈ FRR
---        far_values = np.array(far_values)
---        frr_values = np.array(frr_values)
--+       
--+        frr, far, thresholds = self.compute_det_curve(bonafide_scores, other_scores)
--+        abs_diffs = np.abs(frr - far)
--+        min_index = np.argmin(abs_diffs)
--+        eer = np.mean((frr[min_index], far[min_index]))
--         
---        # Находим индекс, где разность минимальна
---        diff = np.abs(far_values - frr_values)
---        min_idx = np.argmin(diff)
---        
---        # EER - это среднее FAR и FRR в этой точке
---        eer = (far_values[min_idx] + frr_values[min_idx]) / 2
--+        return float(eer), float(thresholds[min_index])
--+
--+    def compute_det_curve(self, target_scores, nontarget_scores):
--+        """
--+        Точная копия эталонной реализации compute_det_curve.
--         
---        return float(eer)
--\ No newline at end of file
--+        Args:
--+            target_scores: scores for bonafide samples  
--+            nontarget_scores: scores for spoof samples
--+            
--+        Returns:
--+            tuple: (frr, far, thresholds)
--+        """
--+        n_scores = target_scores.size + nontarget_scores.size
--+        all_scores = np.concatenate((target_scores, nontarget_scores))
--+        labels = np.concatenate(
--+            (np.ones(target_scores.size), np.zeros(nontarget_scores.size)))
--+
--+        # Sort labels based on scores
--+        indices = np.argsort(all_scores, kind='mergesort')
--+        labels = labels[indices]
--+
--+        # Compute false rejection and false acceptance rates
--+        tar_trial_sums = np.cumsum(labels)
--+        nontarget_trial_sums = nontarget_scores.size - \
--+            (np.arange(1, n_scores + 1) - tar_trial_sums)
--+
--+        # false rejection rates
--+        frr = np.concatenate(
--+            (np.atleast_1d(0), tar_trial_sums / target_scores.size))
--+        far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums /
--+                              nontarget_scores.size))  # false acceptance rates
--+        # Thresholds are the sorted scores
--+        thresholds = np.concatenate(
--+            (np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))
--+
--+        return frr, far, thresholds
--\ No newline at end of file
--diff --git a/src/metrics/tracker.py b/src/metrics/tracker.py
--index 26ebc87..a17ea85 100644
----- a/src/metrics/tracker.py
--+++ b/src/metrics/tracker.py
--@@ -21,10 +21,6 @@ class MetricTracker:
--         self.writer = writer
--         self._data = pd.DataFrame(index=keys, columns=["total", "counts", "average"])
--         self.reset()
---        
---        
---        self._eer_scores = []
---        self._eer_labels = []
-- 
--     def reset(self):
--         """
--@@ -32,128 +28,19 @@ class MetricTracker:
--         """
--         for col in self._data.columns:
--             self._data[col].values[:] = 0
---        
---        # Сброс EER данных
---        self._eer_scores = []
---        self._eer_labels = []
-- 
--     def update(self, key, value, n=1):
---        
---
---        self._data.loc[key, "total"] += value * n
---        self._data.loc[key, "counts"] += n
---        self._data.loc[key, "average"] = self._data.total[key] / self._data.counts[key]
---
---    def update_eer(self, scores, labels):
---        """
---        Update EER scores and labels.
---        
---        Args:
---            scores (torch.Tensor): prediction scores (должны быть scores для bonafide класса)
---            labels (torch.Tensor): ground truth labels (1 = bonafide, 0 = spoof)
---        """
---        if scores.numel() == 0 or labels.numel() == 0:
---            return
---            
---        # Конвертируем в numpy
---        scores_np = scores.detach().cpu().numpy().flatten()
---        labels_np = labels.detach().cpu().numpy().flatten()
---        
---        # Проверяем что размеры совпадают
---        if len(scores_np) != len(labels_np):
---            return
---        
---        # Проверяем валидность данных
---        if np.any(np.isnan(scores_np)) or np.any(np.isinf(scores_np)):
---            return
---            
---        # Добавляем данные
---        self._eer_scores.extend(scores_np)
---        self._eer_labels.extend(labels_np)
---
---    def compute_eer(self):
---        """
---        Compute Equal Error Rate from accumulated scores and labels using reference implementation.
---        """
---        if not self._eer_scores or len(self._eer_scores) == 0:
---            return 0.0
---        
---        scores = np.array(self._eer_scores)
---        labels = np.array(self._eer_labels)
---        
---        # Проверяем что есть оба класса
---        unique_labels = np.unique(labels)
---        if len(unique_labels) < 2:
---            return 0.0
---        
---        # Разделяем scores на bonafide и spoof
---        bonafide_scores = scores[labels == 1]  # Настоящие образцы
---        spoof_scores = scores[labels == 0]     # Поддельные образцы
---        
---        if len(bonafide_scores) == 0 or len(spoof_scores) == 0:
---            return 0.0
---        
---        # Используем эталонную реализацию
---        eer, threshold = self._compute_eer_reference(bonafide_scores, spoof_scores)
---        
---        return float(eer)
---
---    def _compute_eer_reference(self, bonafide_scores, spoof_scores):
--         """
---        Reference implementation of EER computation (эталонная реализация).
--+        Update metric with new value.
--         
--         Args:
---            bonafide_scores: scores for bonafide (genuine) samples
---            spoof_scores: scores for spoof (fake) samples
---            
---        Returns:
---            tuple: (eer, threshold)
--+            key (str): metric name
--+            value (float): metric value  
--+            n (int): number of samples
--         """
---        frr, far, thresholds = self._compute_det_curve(bonafide_scores, spoof_scores)
---        abs_diffs = np.abs(frr - far)
---        min_index = np.argmin(abs_diffs)
---        eer = np.mean((frr[min_index], far[min_index]))
---        
---        return float(eer), float(thresholds[min_index])
---
---    def _compute_det_curve(self, target_scores, nontarget_scores):
---        """
---        Compute Detection Error Tradeoff (DET) curve (эталонная реализация).
---        
---        Args:
---            target_scores: scores for target (bonafide) samples
---            nontarget_scores: scores for nontarget (spoof) samples
---            
---        Returns:
---            tuple: (frr, far, thresholds)
---        """
---        n_scores = target_scores.size + nontarget_scores.size
---        all_scores = np.concatenate((target_scores, nontarget_scores))
---        labels = np.concatenate(
---            (np.ones(target_scores.size), np.zeros(nontarget_scores.size)))
---
---        # Sort labels based on scores
---        indices = np.argsort(all_scores, kind='mergesort')
---        labels = labels[indices]
---
---        # Compute false rejection and false acceptance rates
---        tar_trial_sums = np.cumsum(labels)
---        nontarget_trial_sums = nontarget_scores.size - \
---            (np.arange(1, n_scores + 1) - tar_trial_sums)
---
---        # False rejection rates (FRR): отклонение настоящих как поддельных
---        frr = np.concatenate(
---            (np.atleast_1d(0), tar_trial_sums / target_scores.size))
---        
---        # False acceptance rates (FAR): принятие поддельных как настоящих  
---        far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums /
---                              nontarget_scores.size))
---        
---        # Thresholds are the sorted scores
---        thresholds = np.concatenate(
---            (np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))
---
---        return frr, far, thresholds
--+        self._data.loc[key, "total"] += value * n
--+        self._data.loc[key, "counts"] += n
--+        self._data.loc[key, "average"] = self._data.total[key] / self._data.counts[key]
-- 
--     def avg(self, key):
--         """
--@@ -164,8 +51,6 @@ class MetricTracker:
--         Returns:
--             average_value (float): average value for the metric.
--         """
---        if key == "eer":
---            return self.compute_eer()
--         return self._data.average[key]
-- 
--     def result(self):
--@@ -176,10 +61,7 @@ class MetricTracker:
--             average_metrics (dict): dict, containing average metrics
--                 for each metric name.
--         """
---        result = dict(self._data.average)
---        # Всегда включаем EER в результат
---        result['eer'] = self.compute_eer()
---        return result
--+        return dict(self._data.average)
-- 
--     def keys(self):
--         """
--@@ -188,7 +70,4 @@ class MetricTracker:
--         Returns:
--             metric_keys (Index): all metric names in the table.
--         """
---        keys = list(self._data.total.keys())
---        if self._eer_scores:
---            keys.append('eer')
---        return keys
--\ No newline at end of file
--+        return list(self._data.total.keys())
--\ No newline at end of file
--diff --git a/src/trainer/trainer.py b/src/trainer/trainer.py
--index a511a63..c167fa4 100644
----- a/src/trainer/trainer.py
--+++ b/src/trainer/trainer.py
--@@ -44,33 +44,13 @@ class Trainer(BaseTrainer):
--         for loss_name in self.config.writer.loss_names:
--             metrics.update(loss_name, batch[loss_name].item())
-- 
---        # ИСПРАВЛЕННОЕ ВЫЧИСЛЕНИЕ EER
---        if "logits" in batch and "labels" in batch:
---            logits = batch["logits"]
---            labels = batch["labels"]
---            
---            # Убеждаемся что размеры корректны
---            if logits.dim() == 2 and logits.size(1) >= 2:
---                # Получаем вероятности для класса bonafide (класс 0) - правильно для EER
---                scores = torch.softmax(logits, dim=1)[:, 0]
---                
---                # Проверяем что есть данные
---                if scores.numel() > 0 and labels.numel() > 0:
---                    metrics.update_eer(scores, labels)
---                else:
---                    print(f"⚠️ Пустые данные для EER: scores.numel()={scores.numel()}, labels.numel()={labels.numel()}")
---            else:
---                print(f"⚠️ Неправильные размеры logits: {logits.shape}")
---        else:
---            print(f"⚠️ Отсутствуют необходимые ключи: logits={('logits' in batch)}, labels={('labels' in batch)}")
---
---        # Update other metrics
--+        # Update all metrics (включая EER) через metric_funcs
--         for met in metric_funcs:
---            if met.name != "eer":
---                try:
---                    metrics.update(met.name, met(batch))
---                except Exception as e:
---                    print(f"⚠️ Ошибка в метрике {met.name}: {e}")
--+            try:
--+                metrics.update(met.name, met(batch))
--+            except Exception as e:
--+                # Молча игнорируем ошибки в метриках
--+                pass
-- 
--         return batch
-- 
-diff --git a/src/configs/transforms/default.yaml b/src/configs/transforms/default.yaml
-index c450e63..199ccff 100644
---- a/src/configs/transforms/default.yaml
-+++ b/src/configs/transforms/default.yaml
-@@ -1,31 +1,30 @@
- instance_transforms:
--  data_object: ${transforms.stft}
-+  data_object: ${transforms.lfcc}
- 
--stft:
--  _target_: src.transforms.stft.STFTTransform
--  n_fft: 1724  # Для получения 863 freq bins (1724//2 + 1 = 863)
--  hop_length: 256  # Для лучшего временного разрешения
--  win_length: 1724
-+lfcc:
-+  _target_: src.transforms.lfcc.LFCCTransform
-+  sample_rate: 16000
-+  n_fft: 512           # 512-point FFT как в статье
-+  hop_length: 160      # 10ms frame shift at 16kHz
-+  win_length: 320      # 20ms frame length at 16kHz  
-+  n_filter: 20         # 20 linear triangular filters
-+  n_lfcc: 20           # 20 cepstral coefficients
-+  use_deltas: true     # static + delta + delta-delta = 60-dim
- 
- batch_transforms:
-   train:
-     data_object:
-       _target_: torch.nn.Sequential
-       _args_:
--        # Логарифмирование спектрограммы - критически важно для аудио
--        - _target_: src.transforms.stft.LogTransform
--          eps: 1e-6
--        # Нормализация логарифмированных значений
-+        # Нормализация LFCC признаков (60-мерных)
-         - _target_: src.transforms.normalize.Normalize
--          mean: [-4.0]  # Подходящее для log-спектрограмм  
--          std: [4.0]    # Подходящее стандартное отклонение
-+          mean: [0.0]  # Подходящее для LFCC признаков  
-+          std: [1.0]   # Стандартная нормализация
-   inference:
-     data_object:
-       _target_: torch.nn.Sequential
-       _args_:
-         # Те же трансформации для inference
--        - _target_: src.transforms.stft.LogTransform
--          eps: 1e-6
-         - _target_: src.transforms.normalize.Normalize
--          mean: [-4.0]
--          std: [4.0]
-\ No newline at end of file
-+          mean: [0.0]
-+          std: [1.0]
-\ No newline at end of file
-diff --git a/src/datasets/mydataset.py b/src/datasets/mydataset.py
-index 72984e0..a1e875e 100644
---- a/src/datasets/mydataset.py
-+++ b/src/datasets/mydataset.py
-@@ -81,8 +81,8 @@ class AudioSpoofingDataset(BaseDataset):
-             return item_data
-             
-         except Exception as e:
--            # Return zero tensor as fallback
--            fallback_waveform = torch.zeros(1, 16000)  # 1 second of silence at 16kHz
-+            # Return zero tensor as fallback - увеличиваем до 4 секунд
-+            fallback_waveform = torch.zeros(1, 64000)  # 4 seconds of silence at 16kHz
-             print(f"⚠️ Ошибка загрузки аудио {audio_path}: {e}")
-             return {
-                 "data_object": fallback_waveform,
-diff --git a/src/model/__init__.py b/src/model/__init__.py
-index d5cd956..b6c101b 100644
---- a/src/model/__init__.py
-+++ b/src/model/__init__.py
-@@ -1 +1 @@
--from src.model.model import LCNN
-\ No newline at end of file
-+from src.model.model import LCNN, LCNN_LSTM_Sum
-\ No newline at end of file
-diff --git a/src/model/model.py b/src/model/model.py
-index 59a64c7..421cc5f 100644
---- a/src/model/model.py
-+++ b/src/model/model.py
-@@ -13,10 +13,9 @@ class MFM(nn.Module):
-         self.out_features = out_features
-         
-     def forward(self, x):
--        # Разделяем на две половины и берем максимум
--        if x.dim() == 4:  # Для conv слоев [B, C, H, W]
-+        if x.dim() == 4:
-             x1, x2 = torch.split(x, self.out_features, dim=1)
--        else:  # Для linear слоев [B, F]  
-+        else:
-             x1, x2 = torch.split(x, self.out_features, dim=1)
-         return torch.max(x1, x2)
- 
-@@ -31,184 +30,325 @@ class LCNN(nn.Module):
-         """
-         Args:
-             num_classes (int): number of output classes
--            dropout_rate (float): dropout probability for regularization
--            **kwargs: additional arguments
-+            dropout_rate (float): dropout probability
-         """
-         super(LCNN, self).__init__()
-         
--        self.num_classes = num_classes
--        self.dropout_rate = dropout_rate
--        
--        # Conv_1 (5x5/1x1) -> MFM_2 -> MaxPool_3 (2x2/2x2)
--        # Вход: 863x600x1, Выход: 431x300x32
--        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2, bias=False)  # 1.6K params
-+        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)
-         self.mfm1 = MFM(64, 32)
-         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
-         
--        # Block 1: Conv_4 (1x1/1x1) -> MFM_5 -> BN_6 -> Conv_7 (3x3/1x1) -> MFM_8 -> MaxPool_9 -> BN_10
--        # Вход: 431x300x32, Выход: 215x150x48
--        self.block1_conv1 = nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0, bias=False)  # 2.1K params
-+        self.block1_conv1 = nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0, bias=False)
-         self.block1_mfm1 = MFM(64, 32)
-         self.block1_bn1 = nn.BatchNorm2d(32)
--        self.block1_conv2 = nn.Conv2d(32, 96, kernel_size=3, stride=1, padding=1, bias=False)  # 27.7K params
-+        self.block1_conv2 = nn.Conv2d(32, 96, kernel_size=3, stride=1, padding=1, bias=False)
-         self.block1_mfm2 = MFM(96, 48)
-         self.block1_pool = nn.MaxPool2d(kernel_size=2, stride=2)
-         self.block1_bn2 = nn.BatchNorm2d(48)
--        self.block1_dropout = nn.Dropout2d(p=dropout_rate)
-         
--        # Block 2: Conv_11 (1x1/1x1) -> MFM_12 -> BN_13 -> Conv_14 (3x3/1x1) -> MFM_15 -> MaxPool_16
--        # Вход: 215x150x48, Выход: 107x75x64
--        self.block2_conv1 = nn.Conv2d(48, 96, kernel_size=1, stride=1, padding=0, bias=False)  # 4.7K params
-+        self.block2_conv1 = nn.Conv2d(48, 96, kernel_size=1, stride=1, padding=0, bias=False)
-         self.block2_mfm1 = MFM(96, 48)
-         self.block2_bn1 = nn.BatchNorm2d(48)
--        self.block2_conv2 = nn.Conv2d(48, 128, kernel_size=3, stride=1, padding=1, bias=False)  # 55.4K params
-+        self.block2_conv2 = nn.Conv2d(48, 128, kernel_size=3, stride=1, padding=1, bias=False)
-         self.block2_mfm2 = MFM(128, 64)
-         self.block2_pool = nn.MaxPool2d(kernel_size=2, stride=2)
--        self.block2_dropout = nn.Dropout2d(p=dropout_rate)
-         
--        # Block 3: Conv_17 (1x1/1x1) -> MFM_18 -> BN_19 -> Conv_20 (3x3/1x1) -> MFM_21 -> BN_22
--        # Вход: 107x75x64, Выход: 107x75x32
--        self.block3_conv1 = nn.Conv2d(64, 128, kernel_size=1, stride=1, padding=0, bias=False)  # 8.3K params
-+        self.block3_conv1 = nn.Conv2d(64, 128, kernel_size=1, stride=1, padding=0, bias=False)
-         self.block3_mfm1 = MFM(128, 64)
-         self.block3_bn1 = nn.BatchNorm2d(64)
--        self.block3_conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)  # 36.9K params
-+        self.block3_conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)
-         self.block3_mfm2 = MFM(64, 32)
-         self.block3_bn2 = nn.BatchNorm2d(32)
--        self.block3_dropout = nn.Dropout2d(p=dropout_rate)
-         
--        # Block 4: Conv_23 (1x1/1x1) -> MFM_24 -> BN_25 -> Conv_26 (3x3/1x1) -> MFM_27 -> MaxPool_28
--        # Вход: 107x75x32, Выход: 53x37x32
--        self.block4_conv1 = nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0, bias=False)  # 2.1K params
-+        self.block4_conv1 = nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0, bias=False)
-         self.block4_mfm1 = MFM(64, 32)
-         self.block4_bn1 = nn.BatchNorm2d(32)
--        self.block4_conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)  # 18.5K params
-+        self.block4_conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)
-         self.block4_mfm2 = MFM(64, 32)
-         self.block4_pool = nn.MaxPool2d(kernel_size=2, stride=2)
--        self.block4_dropout = nn.Dropout2d(p=dropout_rate)
--        
--        # Classifier: FC_29 -> MFM_30 -> BN_31 -> Dropout -> FC_32
--        # Размер после всех операций: 53x37x32 = 62464 features
--        # Но в таблице FC_29 дает 160 выходов с 10.2MM параметров
--        # Это означает глобальный пулинг до размера, который даст нужное количество параметров
--        
--        # Добавляем глобальный пулинг и классификатор согласно таблице
--        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # 53x37x32 -> 1x1x32
--        self.fc1 = nn.Linear(32, 160, bias=True)  # FC_29: 32*160 + 160 = 5280 ≈ 5.3K params
--        self.mfm_fc = MFM(160, 80)  # MFM_30: 160 -> 80
--        self.bn_fc = nn.BatchNorm1d(80)  # BN_31
--        self.dropout_fc = nn.Dropout(p=dropout_rate)  # Dropout перед финальным слоем
--        self.fc2 = nn.Linear(80, num_classes, bias=True)  # FC_32: 80*2 + 2 = 162 ≈ 64 params
--        
--        # Инициализация весов
-+        
-+        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))
-+        self.fc1 = nn.Linear(32, 160, bias=True)
-+        self.mfm_fc = MFM(160, 80)
-+        self.bn_fc = nn.BatchNorm1d(80)
-+        self.dropout_fc = nn.Dropout(p=dropout_rate)
-+        self.fc2 = nn.Linear(80, num_classes, bias=True)
-+        
-         self._init_weights()
- 
-     def _init_weights(self):
--        """Инициализация весов модели"""
-+        """
-+        Initialize weights using Xavier/Glorot initialization.
-+        """
-         for m in self.modules():
-             if isinstance(m, nn.Conv2d):
--                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
--            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):
--                nn.init.constant_(m.weight, 1)
--                nn.init.constant_(m.bias, 0)
-+                nn.init.xavier_normal_(m.weight)
-             elif isinstance(m, nn.Linear):
--                nn.init.normal_(m.weight, 0, 0.01)
--                if m.bias is not None:
--                    nn.init.constant_(m.bias, 0)
-+                nn.init.xavier_normal_(m.weight)
- 
-     def forward(self, batch) -> Dict[str, torch.Tensor]:
-         """
-         Forward pass of the Light CNN model.
-         
-         Args:
--            batch: input batch containing tensors
-+            batch: input batch containing tensors or direct tensor
-             
-         Returns:
-             Dict[str, torch.Tensor]: model outputs
-         """
--        # Получаем входные данные
--        if 'data_object' in batch:
--            x = batch['data_object']
--        elif 'spectrogram' in batch:
--            x = batch['spectrogram']
-+        if isinstance(batch, dict):
-+            if 'data_object' in batch:
-+                x = batch['data_object']
-+            elif 'spectrogram' in batch:
-+                x = batch['spectrogram']
-+            else:
-+                x = next(iter(batch.values()))
-         else:
--            x = next(iter(batch.values()))
-+            x = batch
-         
--        # Убеждаемся, что входные данные имеют правильную форму
-         if x.dim() == 3:
--            x = x.unsqueeze(1)  # Добавляем канал: [batch, freq, time] -> [batch, 1, freq, time]
-+            x = x.unsqueeze(1)
-         elif x.dim() == 2:
--            x = x.unsqueeze(0).unsqueeze(0)  # [freq, time] -> [1, 1, freq, time]
--        
--        # Conv_1 + MFM_2 + MaxPool_3
--        # Ожидаемый размер: [B, 1, 863, 600] -> [B, 32, 431, 300]
--        x = self.conv1(x)          # [B, 64, 863, 600]
--        x = self.mfm1(x)           # [B, 32, 863, 600]
--        x = self.pool1(x)          # [B, 32, 431, 300]
--        
--        # Block 1: [B, 32, 431, 300] -> [B, 48, 215, 150]
--        x = self.block1_conv1(x)   # [B, 64, 431, 300]
--        x = self.block1_mfm1(x)    # [B, 32, 431, 300]
--        x = self.block1_bn1(x)     
--        x = self.block1_conv2(x)   # [B, 96, 431, 300]
--        x = self.block1_mfm2(x)    # [B, 48, 431, 300]
--        x = self.block1_pool(x)    # [B, 48, 215, 150]
-+            x = x.unsqueeze(0).unsqueeze(0)
-+        
-+        x = self.conv1(x)
-+        x = self.mfm1(x)
-+        x = self.pool1(x)
-+        
-+        x = self.block1_conv1(x)
-+        x = self.block1_mfm1(x)
-+        x = self.block1_bn1(x)
-+        x = self.block1_conv2(x)
-+        x = self.block1_mfm2(x)
-+        x = self.block1_pool(x)
-         x = self.block1_bn2(x)
--        x = self.block1_dropout(x)
--        
--        # Block 2: [B, 48, 215, 150] -> [B, 64, 107, 75]
--        x = self.block2_conv1(x)   # [B, 96, 215, 150]
--        x = self.block2_mfm1(x)    # [B, 48, 215, 150]
--        x = self.block2_bn1(x)     
--        x = self.block2_conv2(x)   # [B, 128, 215, 150]
--        x = self.block2_mfm2(x)    # [B, 64, 215, 150]
--        x = self.block2_pool(x)    # [B, 64, 107, 75]
--        x = self.block2_dropout(x)
--        
--        # Block 3: [B, 64, 107, 75] -> [B, 32, 107, 75]
--        x = self.block3_conv1(x)   # [B, 128, 107, 75]
--        x = self.block3_mfm1(x)    # [B, 64, 107, 75]
-+        
-+        x = self.block2_conv1(x)
-+        x = self.block2_mfm1(x)
-+        x = self.block2_bn1(x)
-+        x = self.block2_conv2(x)
-+        x = self.block2_mfm2(x)
-+        x = self.block2_pool(x)
-+        
-+        x = self.block3_conv1(x)
-+        x = self.block3_mfm1(x)
-         x = self.block3_bn1(x)
--        x = self.block3_conv2(x)   # [B, 64, 107, 75]
--        x = self.block3_mfm2(x)    # [B, 32, 107, 75]
-+        x = self.block3_conv2(x)
-+        x = self.block3_mfm2(x)
-         x = self.block3_bn2(x)
--        x = self.block3_dropout(x)
-         
--        # Block 4: [B, 32, 107, 75] -> [B, 32, 53, 37]
--        x = self.block4_conv1(x)   # [B, 64, 107, 75]
--        x = self.block4_mfm1(x)    # [B, 32, 107, 75]
-+        x = self.block4_conv1(x)
-+        x = self.block4_mfm1(x)
-         x = self.block4_bn1(x)
--        x = self.block4_conv2(x)   # [B, 64, 107, 75]
--        x = self.block4_mfm2(x)    # [B, 32, 107, 75]
--        x = self.block4_pool(x)    # [B, 32, 53, 37]
--        x = self.block4_dropout(x)
--        
--        # Classifier: [B, 32, 53, 37] -> [B, num_classes]
--        x = self.global_pool(x)    # [B, 32, 1, 1]
--        x = x.view(x.size(0), -1)  # [B, 32]
--        x = self.fc1(x)            # [B, 160] (FC_29)
--        x = self.mfm_fc(x)         # [B, 80] (MFM_30)
--        x = self.bn_fc(x)          # [B, 80] (BN_31)
--        x = self.dropout_fc(x)     # Dropout
--        x = self.fc2(x)            # [B, num_classes] (FC_32)
--        
--        # Возвращаем выходы
--        outputs = {
--            'logits': x
--        }
-+        x = self.block4_conv2(x)
-+        x = self.block4_mfm2(x)
-+        x = self.block4_pool(x)
-+        
-+        x = self.global_pool(x)
-+        x = x.view(x.size(0), -1)
-+        x = self.fc1(x)
-+        x = self.mfm_fc(x)
-+        x = self.bn_fc(x)
-+        x = self.dropout_fc(x)
-+        x = self.fc2(x)
-         
--        return outputs
-+        return {
-+            "logits": x
-+        }
- 
- 
--# Создаем экземпляр модели для совместимости с hydra
--def create_model(**kwargs) -> LCNN:
-+class LCNN_LSTM_Sum(nn.Module):
-+    """
-+    LCNN-LSTM-sum архитектура из статьи:
-+    - Та же CNN часть как в LCNN
-+    - 2 Bi-LSTM слоя с skip connection
-+    - Average pooling
-+    - FC слой
-     """
--    Создает экземпляр модели Light CNN.
-     
--    Args:
--        **kwargs: параметры модели
-+    def __init__(self, num_classes=2, dropout_rate=0.3, **kwargs):
-+        """
-+        Args:
-+            num_classes (int): number of output classes
-+            dropout_rate (float): dropout probability
-+        """
-+        super(LCNN_LSTM_Sum, self).__init__()
-         
--    Returns:
--        LCNN: экземпляр модели
--    """
--    model = LCNN(**kwargs)
--    return model
-\ No newline at end of file
-+        # === CNN ЧАСТЬ (точно такая же как в LCNN) ===
-+        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)
-+        self.mfm1 = MFM(64, 32)
-+        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
-+        
-+        self.block1_conv1 = nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0, bias=False)
-+        self.block1_mfm1 = MFM(64, 32)
-+        self.block1_bn1 = nn.BatchNorm2d(32)
-+        self.block1_conv2 = nn.Conv2d(32, 96, kernel_size=3, stride=1, padding=1, bias=False)
-+        self.block1_mfm2 = MFM(96, 48)
-+        self.block1_pool = nn.MaxPool2d(kernel_size=2, stride=2)
-+        self.block1_bn2 = nn.BatchNorm2d(48)
-+        
-+        self.block2_conv1 = nn.Conv2d(48, 96, kernel_size=1, stride=1, padding=0, bias=False)
-+        self.block2_mfm1 = MFM(96, 48)
-+        self.block2_bn1 = nn.BatchNorm2d(48)
-+        self.block2_conv2 = nn.Conv2d(48, 128, kernel_size=3, stride=1, padding=1, bias=False)
-+        self.block2_mfm2 = MFM(128, 64)
-+        self.block2_pool = nn.MaxPool2d(kernel_size=2, stride=2)
-+        
-+        self.block3_conv1 = nn.Conv2d(64, 128, kernel_size=1, stride=1, padding=0, bias=False)
-+        self.block3_mfm1 = MFM(128, 64)
-+        self.block3_bn1 = nn.BatchNorm2d(64)
-+        self.block3_conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)
-+        self.block3_mfm2 = MFM(64, 32)
-+        self.block3_bn2 = nn.BatchNorm2d(32)
-+        
-+        self.block4_conv1 = nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0, bias=False)
-+        self.block4_mfm1 = MFM(64, 32)
-+        self.block4_bn1 = nn.BatchNorm2d(32)
-+        self.block4_conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False)
-+        self.block4_mfm2 = MFM(64, 32)
-+        self.block4_pool = nn.MaxPool2d(kernel_size=2, stride=2)
-+        
-+        # === LSTM ЧАСТЬ (заменяет global_pool + FC) ===
-+        # После CNN: [B, 32, H, W] -> нужно reshape для LSTM
-+        # Размер hidden_size равен выходу CNN (32 канала * высота после всех pooling)
-+        
-+        # Первый Bi-LSTM слой
-+        self.lstm1 = nn.LSTM(
-+            input_size=32,  # 32 канала с CNN
-+            hidden_size=32,  # размер равен выходу CNN части
-+            num_layers=1,
-+            batch_first=True,
-+            bidirectional=True,
-+            dropout=0.0
-+        )
-+        
-+        # Второй Bi-LSTM слой  
-+        self.lstm2 = nn.LSTM(
-+            input_size=64,  # 32*2 от bidirectional
-+            hidden_size=32,  # размер равен выходу CNN части
-+            num_layers=1, 
-+            batch_first=True,
-+            bidirectional=True,
-+            dropout=0.0
-+        )
-+        
-+        # Average pooling по временной размерности
-+        self.avg_pool = nn.AdaptiveAvgPool1d(1)
-+        
-+        # Финальный FC слой
-+        self.fc = nn.Linear(64, num_classes)  # 64 = 32*2 от bidirectional LSTM2
-+        self.dropout = nn.Dropout(p=dropout_rate)
-+        
-+        self._init_weights()
-+    
-+    def _init_weights(self):
-+        """
-+        Initialize weights using Xavier/Glorot initialization.
-+        """
-+        for m in self.modules():
-+            if isinstance(m, nn.Conv2d):
-+                nn.init.xavier_normal_(m.weight)
-+            elif isinstance(m, nn.Linear):
-+                nn.init.xavier_normal_(m.weight)
-+            elif isinstance(m, nn.LSTM):
-+                for name, param in m.named_parameters():
-+                    if 'weight_ih' in name:
-+                        nn.init.xavier_normal_(param.data)
-+                    elif 'weight_hh' in name:
-+                        nn.init.orthogonal_(param.data)
-+                    elif 'bias' in name:
-+                        param.data.fill_(0)
-+    
-+    def forward(self, batch) -> Dict[str, torch.Tensor]:
-+        """
-+        Forward pass of LCNN-LSTM-sum model.
-+        
-+        Args:
-+            batch: input batch containing tensors or direct tensor
-+            
-+        Returns:
-+            Dict[str, torch.Tensor]: model outputs
-+        """
-+        if isinstance(batch, dict):
-+            if 'data_object' in batch:
-+                x = batch['data_object']
-+            elif 'spectrogram' in batch:
-+                x = batch['spectrogram']
-+            else:
-+                x = next(iter(batch.values()))
-+        else:
-+            x = batch
-+        
-+        if x.dim() == 3:
-+            x = x.unsqueeze(1)
-+        elif x.dim() == 2:
-+            x = x.unsqueeze(0).unsqueeze(0)
-+        
-+        # === CNN FEATURE EXTRACTION ===
-+        x = self.conv1(x)
-+        x = self.mfm1(x)
-+        x = self.pool1(x)
-+        
-+        x = self.block1_conv1(x)
-+        x = self.block1_mfm1(x)
-+        x = self.block1_bn1(x)
-+        x = self.block1_conv2(x)
-+        x = self.block1_mfm2(x)
-+        x = self.block1_pool(x)
-+        x = self.block1_bn2(x)
-+        
-+        x = self.block2_conv1(x)
-+        x = self.block2_mfm1(x)
-+        x = self.block2_bn1(x)
-+        x = self.block2_conv2(x)
-+        x = self.block2_mfm2(x)
-+        x = self.block2_pool(x)
-+        
-+        x = self.block3_conv1(x)
-+        x = self.block3_mfm1(x)
-+        x = self.block3_bn1(x)
-+        x = self.block3_conv2(x)
-+        x = self.block3_mfm2(x)
-+        x = self.block3_bn2(x)
-+        
-+        x = self.block4_conv1(x)
-+        x = self.block4_mfm1(x)
-+        x = self.block4_bn1(x)
-+        x = self.block4_conv2(x)
-+        x = self.block4_mfm2(x)
-+        x = self.block4_pool(x)
-+        
-+        # x shape: [B, 32, H, W]
-+        
-+        # === RESHAPE ДЛЯ LSTM ===
-+        # Объединяем высоту и ширину в временную размерность
-+        B, C, H, W = x.size()
-+        x = x.permute(0, 2, 3, 1)  # [B, H, W, C]
-+        x = x.contiguous().view(B, H * W, C)  # [B, seq_len, features]
-+        
-+        # === ДВА BI-LSTM СЛОЯ С SKIP CONNECTION ===
-+        # Первый LSTM
-+        lstm1_out, _ = self.lstm1(x)  # [B, seq_len, 64]
-+        
-+        # Второй LSTM с skip connection
-+        lstm2_out, _ = self.lstm2(lstm1_out)  # [B, seq_len, 64]
-+        
-+        # Skip connection: суммируем выходы LSTM1 и LSTM2
-+        skip_out = lstm1_out + lstm2_out  # [B, seq_len, 64]
-+        
-+        # === AVERAGE POOLING ===
-+        # Транспонируем для adaptive pooling: [B, 64, seq_len]
-+        skip_out = skip_out.transpose(1, 2)  # [B, 64, seq_len]
-+        pooled = self.avg_pool(skip_out)  # [B, 64, 1]
-+        pooled = pooled.squeeze(-1)  # [B, 64]
-+        
-+        # === FINAL CLASSIFICATION ===
-+        x = self.dropout(pooled)
-+        x = self.fc(x)  # [B, num_classes]
-+        
-+        return {
-+            "logits": x
-+        }
-+
-+
-+model = LCNN()
-\ No newline at end of file
-diff --git a/src/trainer/base_trainer.py b/src/trainer/base_trainer.py
-index 5083117..96566db 100644
---- a/src/trainer/base_trainer.py
-+++ b/src/trainer/base_trainer.py
-@@ -3,7 +3,6 @@ from abc import abstractmethod
- import torch
- from numpy import inf
- from torch.nn.utils import clip_grad_norm_
--from tqdm.auto import tqdm
- 
- from src.datasets.data_utils import inf_loop
- from src.metrics.tracker import MetricTracker
-@@ -83,26 +82,23 @@ class BaseTrainer:
-             self.epoch_len = epoch_len
- 
-         self.evaluation_dataloaders = {
--            k: v for k, v in dataloaders.items() if k == "val"  # ТОЛЬКО val, НЕ test!
-+            k: v for k, v in dataloaders.items() if k != "train"
-         }
--        
--        # test dataloader отдельно - только для финального inference
--        self.test_dataloader = dataloaders.get("test", None)
- 
--       
-+        # define epochs
-         self._last_epoch = 0  # required for saving on interruption
-         self.start_epoch = 1
-         self.epochs = self.cfg_trainer.n_epochs
- 
--      
-+        # configuration to monitor model performance and save best
- 
-         self.save_period = (
-             self.cfg_trainer.save_period
--        )  
--        self.val_period = self.cfg_trainer.get("val_period", 1)
-+        )  # checkpoint each save_period epochs
-         self.monitor = self.cfg_trainer.get(
-             "monitor", "off"
--        )  
-+        )  # format: "mnt_mode mnt_metric"
-+
-         if self.monitor == "off":
-             self.mnt_mode = "off"
-             self.mnt_best = 0
-@@ -115,13 +111,14 @@ class BaseTrainer:
-             if self.early_stop <= 0:
-                 self.early_stop = inf
- 
--     
-+        # setup visualization writer instance
-         self.writer = writer
- 
--       
-+        # define metrics
-         self.metrics = metrics
-         self.train_metrics = MetricTracker(
-             *self.config.writer.loss_names,
-+            "grad_norm",
-             *[m.name for m in self.metrics["train"]],
-             writer=self.writer,
-         )
-@@ -131,6 +128,7 @@ class BaseTrainer:
-             writer=self.writer,
-         )
- 
-+        # define checkpoint dir and init everything if required
- 
-         self.checkpoint_dir = (
-             ROOT_PATH / config.trainer.save_dir / config.writer.run_name
-@@ -167,54 +165,25 @@ class BaseTrainer:
-             self._last_epoch = epoch
-             result = self._train_epoch(epoch)
- 
--          
--            log = {"epoch": epoch}
--            log.update(result)
--
--           
--            val_log = {}
--            if "val" in self.evaluation_dataloaders and (epoch % self.val_period == 0 or epoch == self.epochs):
--                val_results = self._run_validation(epoch, is_mid_epoch=False)
--                
--                
--                val_log = {f"val_{k}": v for k, v in val_results.items()}
--                
--                
--                log.update(val_log)
-+            # save logged information into logs dict
-+            logs = {"epoch": epoch}
-+            logs.update(result)
- 
--            # evaluate model performance according to configured metric
--          
--            monitor_logs = val_log if val_log else result
--            best, stop_process, not_improved_count = self._monitor_performance(monitor_logs, not_improved_count=not_improved_count)
--            early_stop_count = not_improved_count
--
--            best_ckpt_path = str(self.checkpoint_dir / "model_best.pth")
--            
--           
--            for key, value in log.items():
-+            # print logged information to the screen
-+            for key, value in logs.items():
-                 self.logger.info(f"    {key:15s}: {value}")
- 
--            if epoch % self.save_period == 0:
--                self._save_checkpoint(epoch, save_best=False, only_best=False)
-+            # evaluate model performance according to configured metric,
-+            # save best checkpoint as model_best
-+            best, stop_process, not_improved_count = self._monitor_performance(
-+                logs, not_improved_count
-+            )
- 
--            if early_stop_count == 0:
--                print(f"Сохранение лучшей модели: {best_ckpt_path}")
--                self._save_checkpoint(epoch, save_best=True, only_best=True)
-+            if epoch % self.save_period == 0 or best:
-+                self._save_checkpoint(epoch, save_best=best, only_best=True)
- 
--            if early_stop_count >= self.config.trainer.get("early_stop", float("inf")):
--                print(f"Ранняя остановка на эпохе {epoch}")
-+            if stop_process:  # early_stop
-                 break
--                
--        print(f"\n🎯 Финальная валидация:")
--        if "val" in self.evaluation_dataloaders:
--            final_results = self._run_validation(self.epochs, is_mid_epoch=False, is_final=True)
--        
--        
--        if self.test_dataloader is not None:
--            print(f"\n⚠️ TEST набор доступен для финального inference")
--            print(f"   Используйте inference.py для запуска теста")
--        
--        print(f"\n✅ ОБУЧЕНИЕ ЗАВЕРШЕНО!")
- 
-     def _train_epoch(self, epoch):
-         """
-@@ -232,87 +201,89 @@ class BaseTrainer:
-         self.train_metrics.reset()
-         self.writer.set_step((epoch - 1) * self.epoch_len)
-         self.writer.add_scalar("epoch", epoch)
--        for batch_idx, batch in enumerate(
--            tqdm(self.train_dataloader, desc="train", total=self.epoch_len)
--        ):
-+        
-+        print(f"\n🚀 Эпоха {epoch}/{self.epochs} | Батчей: {self.epoch_len}")
-+        
-+        # Для накопления метрик за log_step батчей
-+        step_losses = []
-+        step_eers = []
-+        
-+        for batch_idx, batch in enumerate(self.train_dataloader):
-             try:
-                 batch = self.process_batch(
-                     batch,
-                     metrics=self.train_metrics,
--                    metric_funcs=self.metrics["train"],
-                 )
-             except torch.cuda.OutOfMemoryError as e:
-                 if self.skip_oom:
-                     self.logger.warning("OOM on batch. Skipping batch.")
--                    torch.cuda.empty_cache()  
-+                    torch.cuda.empty_cache()  # free some memory
-                     continue
-                 else:
-                     raise e
- 
-+            self.train_metrics.update("grad_norm", self._get_grad_norm())
- 
--
--         
--            if batch_idx % self.log_step == 0:
-+            # Накапливаем метрики для текущего batch
-+            if "loss" in batch:
-+                step_losses.append(batch["loss"].item())
-+            
-+            # Обновляем полоску прогресса каждый батч
-+            progress = int(((batch_idx + 1) / self.epoch_len) * 100)
-+            filled = int(progress / 5)  # 20 блоков для 100%
-+            bar = "█" * filled + "░" * (20 - filled)
-+            print(f"\r🚀 Эпоха {epoch} [{bar}] {progress}% ({batch_idx + 1}/{self.epoch_len})", end="")
-+
-+            # Логируем и выводим статистику каждые log_step батчей
-+            if (batch_idx + 1) % self.log_step == 0:
-                 self.writer.set_step((epoch - 1) * self.epoch_len + batch_idx)
--                print(f"  🏋️ Эпоха {epoch} {self._progress(batch_idx)} - текущий batch_loss: {batch['loss'].item():.6f}")
--                self.logger.debug(
--                    "Train Epoch: {} {} Loss: {:.6f}".format(
--                        epoch, self._progress(batch_idx), batch["loss"].item()
--                    )
--                )
-                 self.writer.add_scalar(
-                     "learning rate", self.lr_scheduler.get_last_lr()[0]
-                 )
-                 self._log_scalars(self.train_metrics)
-                 self._log_batch(batch_idx, batch)
--                # we don't want to reset train metrics at the start of every epoch
--                # because we are interested in recent train metrics
--                last_train_metrics = self.train_metrics.result()
-                 
--                # Выводим текущие метрики в консоль каждые 50 батчей
--                print(f"  📊 Текущие метрики (шаг {batch_idx}):")
--                if "loss" in last_train_metrics:
--                    print(f"    train_loss: {last_train_metrics['loss']:.6f}")
--                if "eer" in last_train_metrics:
--                    print(f"    train_eer: {last_train_metrics['eer']:.6f}")
--                for metric_name, metric_value in last_train_metrics.items():
--                    if metric_name not in ["loss", "eer"]:
--                        print(f"    train_{metric_name}: {metric_value:.6f}")
-+                # Получаем текущие метрики
-+                current_metrics = self.train_metrics.result()
-+                if "eer" in current_metrics:
-+                    step_eers.append(current_metrics["eer"])
-                 
--                self.train_metrics.reset()
-+                # Вычисляем средние за последние log_step батчей
-+                avg_loss = sum(step_losses[-self.log_step:]) / len(step_losses[-self.log_step:]) if step_losses else 0
-+                avg_eer = sum(step_eers[-1:]) / len(step_eers[-1:]) if step_eers else 0
-                 
--            # ВАЛИДАЦИЯ В СЕРЕДИНЕ ЭПОХИ (на половине эпохи)
--            mid_epoch_step = self.epoch_len // 2
--            if (batch_idx > 0 and 
--                batch_idx == mid_epoch_step and 
--                "val" in self.evaluation_dataloaders):
--                print(f"\n🔄 Переключение на валидацию в середине эпохи...")
--                self._run_validation(epoch, step=batch_idx, is_mid_epoch=True)
--                print(f"🔄 Возврат к обучению...")
--                # Возвращаем модель в режим обучения
--                self.model.train()
--                self.is_train = True
-+                # Выводим статистику
-+                print(f"\n📊 Статистика за батчи {max(0, batch_idx + 1 - self.log_step)}-{batch_idx + 1}:")
-+                print(f"    💥 Средний Loss: {avg_loss:.6f}")
-+                if avg_eer > 0:
-+                    print(f"    📈 EER: {avg_eer:.6f}")
-                 
-+                self.train_metrics.reset()
-             if batch_idx + 1 >= self.epoch_len:
-                 break
--
--        train_results = last_train_metrics
--        print(f"\n🏋️ Тренировочные метрики эпохи {epoch}:")
--        # Выводим loss первым, потом остальные метрики
--        if "loss" in train_results:
--            print(f"    train_loss: {train_results['loss']:.6f}")
--        for metric_name, metric_value in train_results.items():
--            if metric_name != "loss":  # loss уже вывели
--                print(f"    train_{metric_name}: {metric_value:.6f}")
--        print(f"   ✅ Эпоха обучения завершена")
-         
--        if self.writer is not None:
--            self.writer.set_step(epoch, "train")
--            for metric_name, metric_value in train_results.items():
--                self.writer.add_scalar(f"train_{metric_name}_epoch", metric_value)
-+        # Final progress bar at 100%
-+        print(f"\r🚀 Эпоха {epoch} [████████████████████] 100% ({self.epoch_len}/{self.epoch_len}) ✅")
-+        
-+        # Финальная статистика за всю эпоху
-+        if step_losses:
-+            epoch_avg_loss = sum(step_losses) / len(step_losses)
-+            print(f"📈 Итоги эпохи {epoch}:")
-+            print(f"    💥 Средний Loss за эпоху: {epoch_avg_loss:.6f}")
-+            if step_eers:
-+                epoch_avg_eer = sum(step_eers) / len(step_eers)
-+                print(f"    📊 Средний EER за эпоху: {epoch_avg_eer:.6f}")
-+        
-+        print(f"✅ Эпоха {epoch} завершена!")
-+
-+        logs = self.train_metrics.result()
- 
--        # ⬅️ Возвращаем словарь с метриками эпохи
--        return train_results
-+        # Run val/test
-+        for part, dataloader in self.evaluation_dataloaders.items():
-+            val_logs = self._evaluation_epoch(epoch, part, dataloader)
-+            logs.update(**{f"{part}_{name}": value for name, value in val_logs.items()})
-+
-+        return logs
- 
-     def _evaluation_epoch(self, epoch, part, dataloader):
-         """
-@@ -328,91 +299,40 @@ class BaseTrainer:
-         self.is_train = False
-         self.model.eval()
-         self.evaluation_metrics.reset()
-+        print(f"\n🔍 Валидация на {part}...")
-         with torch.no_grad():
--            for batch_idx, batch in tqdm(
--                enumerate(dataloader),
--                desc=part,
--                total=len(dataloader),
--            ):
-+            total_batches = len(dataloader)
-+            for batch_idx, batch in enumerate(dataloader):
-+                # Простой прогресс без излишнего вывода
-+                progress = int(((batch_idx + 1) / total_batches) * 100)
-+                print(f"\r  🔍 Валидация: {progress}% ({batch_idx + 1}/{total_batches})", end="")
-                 batch = self.process_batch(
-                     batch,
-                     metrics=self.evaluation_metrics,
--                    metric_funcs=self.metrics["inference"],
-                 )
--            # Логирование по шагам валидации убрано - происходит в _run_validation
--            # с правильными префиксами и step значениями
-+            
-+            # Final validation progress
-+            print(f"\r  🔍 Валидация: 100% ({total_batches}/{total_batches}) ✅")
-+            
-+            self.writer.set_step(epoch * self.epoch_len, part)
-+            self._log_scalars(self.evaluation_metrics)
-             self._log_batch(
-                 batch_idx, batch, part
--            )  # log only the last batch during inference
--
--        return self.evaluation_metrics.result()
-+            )
- 
--    def _run_validation(self, epoch, step=None, is_mid_epoch=False, is_final=False):
--        """
--        Запуск валидации с корректным логированием.
-+        eval_results = self.evaluation_metrics.result()
-         
--        Args:
--            epoch (int): номер эпохи
--            step (int, optional): номер шага (для валидации в середине эпохи)
--            is_mid_epoch (bool): True если валидация в середине эпохи
--            is_final (bool): True если финальная валидация
--        Returns:
--            val_results (dict): результаты валидации
--        """
--        if "val" not in self.evaluation_dataloaders:
--            return {}
--            
--        # Определяем тип валидации для логирования
--        if is_final:
--            validation_type = "финальная"
--        elif is_mid_epoch:
--            validation_type = "в середине эпохи"
--        else:
--            validation_type = "в конце эпохи"
--            
--        step_info = f" (шаг {step})" if step is not None else ""
--        
--        print(f"\n📊 Валидация {validation_type} {epoch}{step_info}:")
--        
--        val_dataloader = self.evaluation_dataloaders["val"]
--        print(f"   📂 Количество валидационных батчей: {len(val_dataloader)}")
--        
--        val_results = self._evaluation_epoch(epoch, "val", val_dataloader)
--        
--        # Выводим метрики валидации в консоль
--        if is_final:
--            print(f"🎯 Финальные результаты валидации:")
--        else:
--            print(f"📊 Результаты валидации эпохи {epoch}{step_info}:")
--        
--        # Выводим loss первым, потом остальные метрики
--        if "loss" in val_results:
--            print(f"    val_loss: {val_results['loss']:.6f}")
--        for metric_name, metric_value in val_results.items():
--            if metric_name != "loss":  # loss уже вывели
--                print(f"    val_{metric_name}: {metric_value:.6f}")
--        
--        print(f"   ✅ Валидация завершена")
--        
--        # Логируем в writer с правильными префиксами
--        if self.writer is not None:
--            if is_final:
--                # Финальная валидация
--                self.writer.set_step(epoch, "val")
--                for metric_name, metric_value in val_results.items():
--                    self.writer.add_scalar(f"val_{metric_name}_final", metric_value)
--            elif is_mid_epoch and step is not None:
--                # Валидация в середине эпохи - логируем по шагу
--                self.writer.set_step((epoch - 1) * self.epoch_len + step, "val")
--                for metric_name, metric_value in val_results.items():
--                    self.writer.add_scalar(f"val_{metric_name}_mid_epoch", metric_value)
--            else:
--                # Валидация в конце эпохи - логируем по эпохе
--                self.writer.set_step(epoch, "val")
--                for metric_name, metric_value in val_results.items():
--                    self.writer.add_scalar(f"val_{metric_name}_epoch", metric_value)
--        
--        return val_results
-+        # Print validation results nicely
-+        print(f"📈 Результаты валидации {part}:")
-+        if "loss" in eval_results:
-+            print(f"    Val Loss: {eval_results['loss']:.6f}")
-+        if "eer" in eval_results:
-+            print(f"    Val EER: {eval_results['eer']:.6f}")
-+        for metric_name, metric_value in eval_results.items():
-+            if metric_name not in ["loss", "eer"]:
-+                print(f"    Val {metric_name}: {metric_value:.6f}")
-+
-+        return eval_results
- 
-     def _monitor_performance(self, logs, not_improved_count):
-         """
-@@ -497,14 +417,13 @@ class BaseTrainer:
-                 the dataloader (possibly transformed via batch transform).
-         """
-         # do batch transforms on device
--        if self.batch_transforms is not None:
--            transform_type = "train" if self.is_train else "inference"
--            transforms = self.batch_transforms.get(transform_type)
--            if transforms is not None:
--                for transform_name in transforms.keys():
--                    batch[transform_name] = transforms[transform_name](
--                        batch[transform_name]
--                    )
-+        transform_type = "train" if self.is_train else "inference"
-+        transforms = self.batch_transforms.get(transform_type)
-+        if transforms is not None:
-+            for transform_name in transforms.keys():
-+                batch[transform_name] = transforms[transform_name](
-+                    batch[transform_name]
-+                )
-         return batch
- 
-     def _clip_grad_norm(self):
-@@ -675,7 +594,7 @@ class BaseTrainer:
-             pretrained_path (str): path to the model state dict.
-         """
-         pretrained_path = str(pretrained_path)
--        if hasattr(self, "logger"):  # to support both trainer and inferencer
-+        if hasattr(self, "logger"):
-             self.logger.info(f"Loading model weights from: {pretrained_path} ...")
-         else:
-             print(f"Loading model weights from: {pretrained_path} ...")
-diff --git a/src/trainer/trainer.py b/src/trainer/trainer.py
-index c167fa4..7f803de 100644
---- a/src/trainer/trainer.py
-+++ b/src/trainer/trainer.py
-@@ -1,38 +1,49 @@
-+import torch
- from src.metrics.tracker import MetricTracker
- from src.trainer.base_trainer import BaseTrainer
--import torch
-+
- 
- class Trainer(BaseTrainer):
-     """
-     Trainer class. Defines the logic of batch logging and processing.
-     """
- 
--    def process_batch(self, batch, metrics: MetricTracker, metric_funcs):
-+    def process_batch(self, batch, metrics: MetricTracker, metric_funcs=None):
-         """
--        Run batch through the model, compute metrics, and update the tracker.
-+        Run batch through the model, compute metrics, compute loss,
-+        and do training step (during training stage).
-+
-+        The function expects that criterion aggregates all losses
-+        (if there are many) into a single one defined in the 'loss' key.
- 
-         Args:
-             batch (dict): dict-based batch containing the data from
-                 the dataloader.
--            metrics (MetricTracker): tracker that aggregates metrics
--                over the dataset.
--            metric_funcs (list): functions that computes metrics.
--
-+            metrics (MetricTracker): MetricTracker object that computes
-+                and aggregates the metrics. The metrics depend on the type of
-+                the partition (train or inference).
-         Returns:
-             batch (dict): dict-based batch containing the data from
--                the dataloader (possibly transformed via batch transform).
-+                the dataloader (possibly transformed via batch transform),
-+                model outputs, and losses.
-         """
-         batch = self.move_batch_to_device(batch)
-         batch = self.transform_batch(batch)
-+
-+        if metric_funcs is None:
-+            metric_funcs = self.metrics["inference"]
-+            if self.is_train:
-+                metric_funcs = self.metrics["train"]
-         
--        # Подготовка для обучения
-         if self.is_train:
-             self.optimizer.zero_grad()
--        
--        batch.update(self.model(batch))
--        batch.update(self.criterion(batch))
- 
--        # Обратное распространение и обновление весов
-+        outputs = self.model(batch)
-+        batch.update(outputs)
-+
-+        all_losses = self.criterion(batch)
-+        batch.update(all_losses)
-+
-         if self.is_train:
-             batch["loss"].backward()
-             self._clip_grad_norm()
-@@ -40,17 +51,11 @@ class Trainer(BaseTrainer):
-             if self.lr_scheduler is not None:
-                 self.lr_scheduler.step()
- 
--        # Update loss metrics
-         for loss_name in self.config.writer.loss_names:
-             metrics.update(loss_name, batch[loss_name].item())
- 
--        # Update all metrics (включая EER) через metric_funcs
-         for met in metric_funcs:
--            try:
--                metrics.update(met.name, met(batch))
--            except Exception as e:
--                # Молча игнорируем ошибки в метриках
--                pass
-+            metrics.update(met.name, met(batch))
- 
-         return batch
- 
-@@ -58,5 +63,12 @@ class Trainer(BaseTrainer):
-         """
-         Log data from batch. Calls self.writer.add_* to log data
-         to the experiment tracker.
-+
-+        Args:
-+            batch_idx (int): index of the current batch.
-+            batch (dict): dict-based batch after going through
-+                the 'process_batch' function.
-+            mode (str): train or inference. Defines which logging
-+                rules to apply.
-         """
-         pass
-\ No newline at end of file
-diff --git a/src/transforms/__init__.py b/src/transforms/__init__.py
-index 65cd072..3619b06 100644
---- a/src/transforms/__init__.py
-+++ b/src/transforms/__init__.py
-@@ -1,3 +1,4 @@
- from src.transforms.normalize import Normalize
- from src.transforms.scale import RandomScale1D
--from src.transforms.stft import STFTTransform, MelSpectrogramTransform, LogTransform
-\ No newline at end of file
-+from src.transforms.stft import STFTTransform, MelSpectrogramTransform, LogTransform
-+from src.transforms.lfcc import LFCCTransform
-\ No newline at end of file
